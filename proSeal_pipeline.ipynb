{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEqxe9Oh3C2K"
      },
      "source": [
        "# **RINGED SEAL OBJECT DETECCION MODELS PIPELINE-GUIDELINE**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5i68et6S3a5d"
      },
      "source": [
        "# **1. Connect to Google Drive**\n",
        "\n",
        "In my case, all datasets where link to my Google Drive.\n",
        "\n",
        "If your datasets is located in your pc, you just need to uploaded directly to Google Colab.\n",
        "\n",
        "If you are working locally, skip these steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN8ZbXoe4Inr",
        "outputId": "ead68f36-37a1-477d-9813-b6aadd49fb05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_xGNah73svf"
      },
      "source": [
        "# 1.1 Import dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vovQty0AK8Gg",
        "outputId": "1db7143b-a0b7-454a-bb25-96927ab1a97f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 16\n",
            "-rw------- 1 root root  236 Aug  4 16:42 data.yaml\n",
            "drwx------ 3 root root 4096 Aug  4 16:45 hard_negatives\n",
            "-rw------- 1 root root  948 Aug  4 16:42 README.roboflow.txt\n",
            "drwx------ 4 root root 4096 Aug  4 16:43 train\n"
          ]
        }
      ],
      "source": [
        "################################IMPORTAR EL dataset entero a colab UNA VEZ TIENES LA ESTRUCTURA  ####################################################\n",
        "####################################################################################\n",
        "\n",
        "\n",
        "# Copiar el archivo data.yaml desde Drive a la ruta deseada en Colab\n",
        "!cp -r \"/content/drive/MyDrive/Seed_final/23_24_25/seed_plus_90_plus_z\" \"/content/dataset\"\n",
        "\n",
        "# Verificar que se copi√≥ correctamente\n",
        "!ls -l \"/content/dataset\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-8KOjSy71cx"
      },
      "source": [
        "# **2. Divide the dataset**\n",
        "\n",
        "The chosen proportion is :\n",
        "\n",
        "train: 70%\n",
        "\n",
        "Valid: 15 %\n",
        "\n",
        "Test : 15%\n",
        "\n",
        "These percentages are customizables.\n",
        "\n",
        "The division works adding 70 % os positives and 70 % of negatives to train set. Same process to other sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCiXz4ho7z2q",
        "outputId": "dbddd27e-1913-4321-e194-064bcbf21c1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ Total im√°genes: 830\n",
            "‚úÖ Positivas: 620\n",
            "‚≠ï Negativas: 210\n",
            "\n",
            "‚úÖ Divisi√≥n completada con √©xito:\n",
            "üìÅ TRAIN: 581 im√°genes ‚Üí 434 positivas / 147 negativas\n",
            "üìÅ VALID: 124 im√°genes ‚Üí 93 positivas / 31 negativas\n",
            "üìÅ TEST : 125 im√°genes ‚Üí 93 positivas / 32 negativas\n",
            "üìÑ Archivo data.yaml copiado a: /content/mi_dataset_split\n",
            "üìÅ Copiando carpeta de hard negatives a: /content/mi_dataset_split/hard_negatives\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# =============================\n",
        "# CONFIGURACI√ìN PERSONALIZABLE\n",
        "# =============================\n",
        "\n",
        "INPUT_IMAGES_DIR = \"/content/dataset/train/images\"\n",
        "INPUT_LABELS_DIR = \"/content/dataset/train/labels\"\n",
        "OUTPUT_BASE_DIR = \"/content/mi_dataset_split\"\n",
        "\n",
        "INPUT_YAML_PATH = \"/content/dataset/data.yaml\"\n",
        "\n",
        "\n",
        "SPLIT_RATIOS = {\n",
        "    \"train\": 0.70,\n",
        "    \"valid\": 0.15,\n",
        "    \"test\":  0.15\n",
        "}\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "# =============================\n",
        "# FUNCIONES AUXILIARES\n",
        "# =============================\n",
        "\n",
        "def is_positive(txt_path):\n",
        "    if not os.path.exists(txt_path):\n",
        "        return False\n",
        "    with open(txt_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) >= 1 and parts[0].isdigit():\n",
        "                return True  # Hay una clase ‚Üí es positiva\n",
        "    return False\n",
        "\n",
        "def split_list(items, ratios):\n",
        "    random.shuffle(items)\n",
        "    n = len(items)\n",
        "    n_train = int(n * ratios[\"train\"])\n",
        "    n_valid = int(n * ratios[\"valid\"])\n",
        "    return items[:n_train], items[n_train:n_train + n_valid], items[n_train + n_valid:]\n",
        "\n",
        "def move_data_yaml_to_output(source_path, dest_dir):\n",
        "    if not os.path.exists(source_path):\n",
        "        print(f\"‚ùå No se encontr√≥ el archivo data.yaml en: {source_path}\")\n",
        "        return\n",
        "    os.makedirs(dest_dir, exist_ok=True)\n",
        "    shutil.copy2(source_path, os.path.join(dest_dir, \"data.yaml\"))\n",
        "    print(f\"üìÑ Archivo data.yaml copiado a: {dest_dir}\")\n",
        "\n",
        "# =============================\n",
        "# FUNCI√ìN PRINCIPAL\n",
        "# =============================\n",
        "\n",
        "def split_dataset():\n",
        "    for split in SPLIT_RATIOS:\n",
        "        os.makedirs(os.path.join(OUTPUT_BASE_DIR, split, \"images\"), exist_ok=True)\n",
        "        os.makedirs(os.path.join(OUTPUT_BASE_DIR, split, \"labels\"), exist_ok=True)\n",
        "\n",
        "    all_images = [f for f in os.listdir(INPUT_IMAGES_DIR) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
        "    all_images.sort()\n",
        "\n",
        "    positives, negatives = [], []\n",
        "    for img_name in all_images:\n",
        "        txt_name = os.path.splitext(img_name)[0] + \".txt\"\n",
        "        txt_path = os.path.join(INPUT_LABELS_DIR, txt_name)\n",
        "        if is_positive(txt_path):\n",
        "            positives.append(img_name)\n",
        "        else:\n",
        "            negatives.append(img_name)\n",
        "\n",
        "    print(f\"üì¶ Total im√°genes: {len(all_images)}\")\n",
        "    print(f\"‚úÖ Positivas: {len(positives)}\")\n",
        "    print(f\"‚≠ï Negativas: {len(negatives)}\")\n",
        "\n",
        "    random.seed(SEED)\n",
        "\n",
        "    pos_train, pos_valid, pos_test = split_list(positives, SPLIT_RATIOS)\n",
        "    neg_train, neg_valid, neg_test = split_list(negatives, SPLIT_RATIOS)\n",
        "\n",
        "    split_sets = {\n",
        "        \"train\": {\"images\": pos_train + neg_train, \"positives\": pos_train, \"negatives\": neg_train},\n",
        "        \"valid\": {\"images\": pos_valid + neg_valid, \"positives\": pos_valid, \"negatives\": neg_valid},\n",
        "        \"test\":  {\"images\": pos_test + neg_test,   \"positives\": pos_test,  \"negatives\": neg_test}\n",
        "    }\n",
        "\n",
        "    for split, data in split_sets.items():\n",
        "        for img_name in data[\"images\"]:\n",
        "            src_img = os.path.join(INPUT_IMAGES_DIR, img_name)\n",
        "            dst_img = os.path.join(OUTPUT_BASE_DIR, split, \"images\", img_name)\n",
        "            shutil.copy2(src_img, dst_img)\n",
        "\n",
        "            txt_name = os.path.splitext(img_name)[0] + \".txt\"\n",
        "            src_lbl = os.path.join(INPUT_LABELS_DIR, txt_name)\n",
        "            dst_lbl = os.path.join(OUTPUT_BASE_DIR, split, \"labels\", txt_name)\n",
        "\n",
        "            if os.path.exists(src_lbl):\n",
        "                shutil.copy2(src_lbl, dst_lbl)\n",
        "            else:\n",
        "                open(dst_lbl, \"w\").close()\n",
        "\n",
        "    print(\"\\n‚úÖ Divisi√≥n completada con √©xito:\")\n",
        "    for s in [\"train\", \"valid\", \"test\"]:\n",
        "        total = len(split_sets[s][\"images\"])\n",
        "        pos = len(split_sets[s][\"positives\"])\n",
        "        neg = len(split_sets[s][\"negatives\"])\n",
        "        print(f\"üìÅ {s.upper():<5}: {total} im√°genes ‚Üí {pos} positivas / {neg} negativas\")\n",
        "\n",
        "    # Copiar data.yaml al directorio final\n",
        "    move_data_yaml_to_output(INPUT_YAML_PATH, OUTPUT_BASE_DIR)\n",
        "\n",
        "     # Copiar carpeta de hard negatives si existe\n",
        "    hard_neg_src = \"/content/dataset/hard_negatives\"\n",
        "    hard_neg_dst = os.path.join(OUTPUT_BASE_DIR, \"hard_negatives\")\n",
        "    if os.path.exists(hard_neg_src):\n",
        "        print(f\"üìÅ Copiando carpeta de hard negatives a: {hard_neg_dst}\")\n",
        "        shutil.copytree(hard_neg_src, hard_neg_dst, dirs_exist_ok=True)\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No se encontr√≥ la carpeta de hard negatives. Se omite copia.\")\n",
        "\n",
        "# =============================\n",
        "# EJECUTAR\n",
        "# =============================\n",
        "\n",
        "split_dataset()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDjQP5gX4Q3K"
      },
      "source": [
        "# 2.1 Save the divided datasets, if desired"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI6QefUsYayU",
        "outputId": "201374c4-1e5e-4bbe-8dd9-b8e55bd5594e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mi_dataset_split  seed_2025_plus_90_and_2022_and90_2022\n"
          ]
        }
      ],
      "source": [
        "# 10. Guardar los resultados del experimento\n",
        "\n",
        "# Define la carpeta de destino en Google Drive\n",
        "dest_folder = \"/content/drive/MyDrive/Seed_final/25\"\n",
        "!mkdir -p \"{dest_folder}\"  # El comando mkdir -p crea esa carpeta (y cualquier subcarpeta necesaria) si no existe.\n",
        "\n",
        "# Copia la carpeta de resultados (ajusta el nombre seg√∫n el que se haya generado)\n",
        "!cp -r \"/content/mi_dataset_split\" \"{dest_folder}/\"  # Copiar los resultados del modelo en drive\n",
        "\n",
        "# Comprueba que se copiaron los archivos (opcional)\n",
        "!ls \"{dest_folder}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZF9JNg84We3"
      },
      "source": [
        "# **3. Pipeline for preparing the dataset prior to training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGpm-hzr4fAc"
      },
      "source": [
        "# 3.1 Import and install required libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOgX0jeE4JGC",
        "outputId": "393cb2a5-4541-4c66-ee96-140ed8942df0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (2.0.8)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations) (1.16.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations) (2.11.7)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.11/dist-packages (from albumentations) (0.0.24)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations) (3.12.5)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations) (6.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python-headless albumentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3ICdMdC4yfq"
      },
      "source": [
        "# 3.2 Run the pipeline\n",
        "\n",
        "Customizable parameters:\n",
        "\n",
        "- Tile size\n",
        "- Overlap\n",
        "- Positive / negative Proportion in the final sets (train, valid, test)\n",
        "- Augmentation process for positive images in train\n",
        "- Number of augmented images per positive image\n",
        "- Presence of hard negatives\n",
        "- Percentage of hard negatives to normal negaives in each set\n",
        "- Percentaje of each set regarding the total ( once again, train 70%, valid 15 %, test 15%)\n",
        "- Specific final number of tiles in the valid and test set (for the amplification evaluation on miniSeal test set)\n",
        "- Input and output directories\n",
        "- Clean intermediate tiles generated throughout the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUklJbJfdAxn",
        "outputId": "6dbb5d63-f802-4d02-e2d9-7282541cb465"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîÑ Convirtiendo etiquetas de TRAIN...\n",
            "‚úÖ [TRAIN] Conversi√≥n de etiquetas completada.\n",
            "\n",
            "üì¶ Procesando tiling para TRAIN...\n",
            "‚úÖ TRAIN: 749 tiles positivos, 54587 negativos (generados inicialmente).\n",
            "\n",
            "üîÑ Convirtiendo etiquetas de VALID...\n",
            "‚úÖ [VALID] Conversi√≥n de etiquetas completada.\n",
            "\n",
            "üì¶ Procesando tiling para VALID...\n",
            "‚úÖ VALID: 170 tiles positivos, 11630 negativos (generados inicialmente).\n",
            "\n",
            "üîÑ Convirtiendo etiquetas de TEST...\n",
            "‚úÖ [TEST] Conversi√≥n de etiquetas completada.\n",
            "\n",
            "üì¶ Procesando tiling para TEST...\n",
            "‚úÖ TEST: 170 tiles positivos, 11734 negativos (generados inicialmente).\n",
            "\n",
            "üß© Procesando TILES de negativos forzados (falsos positivos)...\n",
            "‚úÖ TILES de negativos forzados completados: 32416 tiles generados.\n",
            "\n",
            "üîç Verificaci√≥n TILES negativos forzados:\n",
            "üñºÔ∏è  Tiles: 32416\n",
            "üìÑ Etiquetas (vac√≠as): 32416\n",
            "\n",
            "‚ú® Iniciando aumentaci√≥n de datos para positivos de TRAIN...\n",
            "Error aplicando aumentaci√≥n en DSC01236_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.a8b8901a06dcfee367bd01a5abbfb5dd_tile_89.jpg: Expected x_min for bbox [-4.9965456e-07  3.8964200e-01  1.2454500e-02  4.2567801e-01\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -4.996545612812042e-07.\n",
            "Error aplicando aumentaci√≥n en DSC01236_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.a8b8901a06dcfee367bd01a5abbfb5dd_tile_89.jpg: Expected x_min for bbox [-4.9965456e-07  3.8964200e-01  1.2454500e-02  4.2567801e-01\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -4.996545612812042e-07.\n",
            "Error aplicando aumentaci√≥n en DSC01236_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.a8b8901a06dcfee367bd01a5abbfb5dd_tile_89.jpg: Expected x_min for bbox [-4.9965456e-07  3.8964200e-01  1.2454500e-02  4.2567801e-01\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -4.996545612812042e-07.\n",
            "Error aplicando aumentaci√≥n en DSC01236_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.a8b8901a06dcfee367bd01a5abbfb5dd_tile_89.jpg: Expected x_min for bbox [-4.9965456e-07  3.8964200e-01  1.2454500e-02  4.2567801e-01\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -4.996545612812042e-07.\n",
            "Error aplicando aumentaci√≥n en DSC01236_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.a8b8901a06dcfee367bd01a5abbfb5dd_tile_89.jpg: Expected x_min for bbox [-4.9965456e-07  3.8964200e-01  1.2454500e-02  4.2567801e-01\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -4.996545612812042e-07.\n",
            "Error aplicando aumentaci√≥n en DSC01236_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.a8b8901a06dcfee367bd01a5abbfb5dd_tile_89.jpg: Expected x_min for bbox [-4.9965456e-07  3.8964200e-01  1.2454500e-02  4.2567801e-01\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -4.996545612812042e-07.\n",
            "Error aplicando aumentaci√≥n en DSC00099_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.bf472b00087f1593d0189893b3e30dab_tile_73.jpg: Expected x_min for bbox [-5.0105155e-07  7.7146202e-01  4.9218498e-02  8.0505604e-01\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.010515451431274e-07.\n",
            "Error aplicando aumentaci√≥n en DSC00099_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.bf472b00087f1593d0189893b3e30dab_tile_73.jpg: Expected x_min for bbox [-5.0105155e-07  7.7146202e-01  4.9218498e-02  8.0505604e-01\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.010515451431274e-07.\n",
            "Error aplicando aumentaci√≥n en DSC00099_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.bf472b00087f1593d0189893b3e30dab_tile_73.jpg: Expected x_min for bbox [-5.0105155e-07  7.7146202e-01  4.9218498e-02  8.0505604e-01\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.010515451431274e-07.\n",
            "Error aplicando aumentaci√≥n en DSC00099_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.bf472b00087f1593d0189893b3e30dab_tile_73.jpg: Expected x_min for bbox [-5.0105155e-07  7.7146202e-01  4.9218498e-02  8.0505604e-01\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.010515451431274e-07.\n",
            "Error aplicando aumentaci√≥n en DSC00099_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.bf472b00087f1593d0189893b3e30dab_tile_73.jpg: Expected x_min for bbox [-5.0105155e-07  7.7146202e-01  4.9218498e-02  8.0505604e-01\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.010515451431274e-07.\n",
            "Error aplicando aumentaci√≥n en DSC00099_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.bf472b00087f1593d0189893b3e30dab_tile_73.jpg: Expected x_min for bbox [-5.0105155e-07  7.7146202e-01  4.9218498e-02  8.0505604e-01\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.010515451431274e-07.\n",
            "Error aplicando aumentaci√≥n en DJI_0534_JPG.rf.86a90ce8e10f43b2ea24f5715ad45220_tile_43.jpg: Expected x_min for bbox [-5.0012022e-07  3.7819999e-01  1.9374501e-02  4.1108400e-01\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DJI_0534_JPG.rf.86a90ce8e10f43b2ea24f5715ad45220_tile_43.jpg: Expected x_min for bbox [-5.0012022e-07  3.7819999e-01  1.9374501e-02  4.1108400e-01\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DJI_0534_JPG.rf.86a90ce8e10f43b2ea24f5715ad45220_tile_43.jpg: Expected x_min for bbox [-5.0012022e-07  3.7819999e-01  1.9374501e-02  4.1108400e-01\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DJI_0534_JPG.rf.86a90ce8e10f43b2ea24f5715ad45220_tile_43.jpg: Expected x_min for bbox [-5.0012022e-07  3.7819999e-01  1.9374501e-02  4.1108400e-01\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DJI_0534_JPG.rf.86a90ce8e10f43b2ea24f5715ad45220_tile_43.jpg: Expected x_min for bbox [-5.0012022e-07  3.7819999e-01  1.9374501e-02  4.1108400e-01\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DJI_0534_JPG.rf.86a90ce8e10f43b2ea24f5715ad45220_tile_43.jpg: Expected x_min for bbox [-5.0012022e-07  3.7819999e-01  1.9374501e-02  4.1108400e-01\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC08339_2_JPG.rf.7f2600085f702c8d9b76de440658fbf6_tile_76.jpg: Expected y_min for bbox [ 9.2593747e-01 -5.0012022e-07  9.6390647e-01  1.0468500e-02\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC08339_2_JPG.rf.7f2600085f702c8d9b76de440658fbf6_tile_76.jpg: Expected y_min for bbox [ 9.2593747e-01 -5.0012022e-07  9.6390647e-01  1.0468500e-02\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC08339_2_JPG.rf.7f2600085f702c8d9b76de440658fbf6_tile_76.jpg: Expected y_min for bbox [ 9.2593747e-01 -5.0012022e-07  9.6390647e-01  1.0468500e-02\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC08339_2_JPG.rf.7f2600085f702c8d9b76de440658fbf6_tile_76.jpg: Expected y_min for bbox [ 9.2593747e-01 -5.0012022e-07  9.6390647e-01  1.0468500e-02\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC08339_2_JPG.rf.7f2600085f702c8d9b76de440658fbf6_tile_76.jpg: Expected y_min for bbox [ 9.2593747e-01 -5.0012022e-07  9.6390647e-01  1.0468500e-02\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC08339_2_JPG.rf.7f2600085f702c8d9b76de440658fbf6_tile_76.jpg: Expected y_min for bbox [ 9.2593747e-01 -5.0012022e-07  9.6390647e-01  1.0468500e-02\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC07929_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.a1c08eac97dbd0a432e175c8eac42bb2_tile_31.jpg: Expected y_min for bbox [ 9.0403146e-01 -5.0012022e-07  9.5840651e-01  1.5824500e-02\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC07929_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.a1c08eac97dbd0a432e175c8eac42bb2_tile_31.jpg: Expected y_min for bbox [ 9.0403146e-01 -5.0012022e-07  9.5840651e-01  1.5824500e-02\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC07929_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.a1c08eac97dbd0a432e175c8eac42bb2_tile_31.jpg: Expected y_min for bbox [ 9.0403146e-01 -5.0012022e-07  9.5840651e-01  1.5824500e-02\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC07929_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.a1c08eac97dbd0a432e175c8eac42bb2_tile_31.jpg: Expected y_min for bbox [ 9.0403146e-01 -5.0012022e-07  9.5840651e-01  1.5824500e-02\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC07929_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.a1c08eac97dbd0a432e175c8eac42bb2_tile_31.jpg: Expected y_min for bbox [ 9.0403146e-01 -5.0012022e-07  9.5840651e-01  1.5824500e-02\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC07929_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.a1c08eac97dbd0a432e175c8eac42bb2_tile_31.jpg: Expected y_min for bbox [ 9.0403146e-01 -5.0012022e-07  9.5840651e-01  1.5824500e-02\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC07929_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.a1c08eac97dbd0a432e175c8eac42bb2_tile_32.jpg: Expected y_min for bbox [ 1.040315e-01 -5.001202e-07  1.584065e-01  1.582450e-02  0.000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC07929_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.a1c08eac97dbd0a432e175c8eac42bb2_tile_32.jpg: Expected y_min for bbox [ 1.040315e-01 -5.001202e-07  1.584065e-01  1.582450e-02  0.000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC07929_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.a1c08eac97dbd0a432e175c8eac42bb2_tile_32.jpg: Expected y_min for bbox [ 1.040315e-01 -5.001202e-07  1.584065e-01  1.582450e-02  0.000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC07929_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.a1c08eac97dbd0a432e175c8eac42bb2_tile_32.jpg: Expected y_min for bbox [ 1.040315e-01 -5.001202e-07  1.584065e-01  1.582450e-02  0.000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC07929_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.a1c08eac97dbd0a432e175c8eac42bb2_tile_32.jpg: Expected y_min for bbox [ 1.040315e-01 -5.001202e-07  1.584065e-01  1.582450e-02  0.000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC07929_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.a1c08eac97dbd0a432e175c8eac42bb2_tile_32.jpg: Expected y_min for bbox [ 1.040315e-01 -5.001202e-07  1.584065e-01  1.582450e-02  0.000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC08339_2_JPG.rf.7f2600085f702c8d9b76de440658fbf6_tile_77.jpg: Expected y_min for bbox [ 1.259375e-01 -5.001202e-07  1.639065e-01  1.046850e-02  0.000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC08339_2_JPG.rf.7f2600085f702c8d9b76de440658fbf6_tile_77.jpg: Expected y_min for bbox [ 1.259375e-01 -5.001202e-07  1.639065e-01  1.046850e-02  0.000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC08339_2_JPG.rf.7f2600085f702c8d9b76de440658fbf6_tile_77.jpg: Expected y_min for bbox [ 1.259375e-01 -5.001202e-07  1.639065e-01  1.046850e-02  0.000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC08339_2_JPG.rf.7f2600085f702c8d9b76de440658fbf6_tile_77.jpg: Expected y_min for bbox [ 1.259375e-01 -5.001202e-07  1.639065e-01  1.046850e-02  0.000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC08339_2_JPG.rf.7f2600085f702c8d9b76de440658fbf6_tile_77.jpg: Expected y_min for bbox [ 1.259375e-01 -5.001202e-07  1.639065e-01  1.046850e-02  0.000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC08339_2_JPG.rf.7f2600085f702c8d9b76de440658fbf6_tile_77.jpg: Expected y_min for bbox [ 1.259375e-01 -5.001202e-07  1.639065e-01  1.046850e-02  0.000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC00499_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.9c61f296361384269cddc6350eb9342f_tile_57.jpg: Expected x_min for bbox [-5.001202e-07  4.122690e-01  2.880450e-02  4.979350e-01  0.000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC00499_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.9c61f296361384269cddc6350eb9342f_tile_57.jpg: Expected x_min for bbox [-5.001202e-07  4.122690e-01  2.880450e-02  4.979350e-01  0.000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC00499_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.9c61f296361384269cddc6350eb9342f_tile_57.jpg: Expected x_min for bbox [-5.001202e-07  4.122690e-01  2.880450e-02  4.979350e-01  0.000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC00499_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.9c61f296361384269cddc6350eb9342f_tile_57.jpg: Expected x_min for bbox [-5.001202e-07  4.122690e-01  2.880450e-02  4.979350e-01  0.000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC00499_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.9c61f296361384269cddc6350eb9342f_tile_57.jpg: Expected x_min for bbox [-5.001202e-07  4.122690e-01  2.880450e-02  4.979350e-01  0.000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC00499_JPG-X-Amz-Algorithm-AWS4-HMAC-SHA256.rf.9c61f296361384269cddc6350eb9342f_tile_57.jpg: Expected x_min for bbox [-5.001202e-07  4.122690e-01  2.880450e-02  4.979350e-01  0.000000e+00] to be in the range [0.0, 1.0], got -5.00120222568512e-07.\n",
            "Error aplicando aumentaci√≥n en DSC09244_JPG.rf.a36805b53d500abce5f3e409cf2fb422_tile_10.jpg: Expected x_min for bbox [-5.0105155e-07  5.3064203e-01  3.7104502e-02  5.6207800e-01\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.010515451431274e-07.\n",
            "Error aplicando aumentaci√≥n en DSC09244_JPG.rf.a36805b53d500abce5f3e409cf2fb422_tile_10.jpg: Expected x_min for bbox [-5.0105155e-07  5.3064203e-01  3.7104502e-02  5.6207800e-01\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.010515451431274e-07.\n",
            "Error aplicando aumentaci√≥n en DSC09244_JPG.rf.a36805b53d500abce5f3e409cf2fb422_tile_10.jpg: Expected x_min for bbox [-5.0105155e-07  5.3064203e-01  3.7104502e-02  5.6207800e-01\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.010515451431274e-07.\n",
            "Error aplicando aumentaci√≥n en DSC09244_JPG.rf.a36805b53d500abce5f3e409cf2fb422_tile_10.jpg: Expected x_min for bbox [-5.0105155e-07  5.3064203e-01  3.7104502e-02  5.6207800e-01\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.010515451431274e-07.\n",
            "Error aplicando aumentaci√≥n en DSC09244_JPG.rf.a36805b53d500abce5f3e409cf2fb422_tile_10.jpg: Expected x_min for bbox [-5.0105155e-07  5.3064203e-01  3.7104502e-02  5.6207800e-01\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.010515451431274e-07.\n",
            "Error aplicando aumentaci√≥n en DSC09244_JPG.rf.a36805b53d500abce5f3e409cf2fb422_tile_10.jpg: Expected x_min for bbox [-5.0105155e-07  5.3064203e-01  3.7104502e-02  5.6207800e-01\n",
            "  0.0000000e+00] to be in the range [0.0, 1.0], got -5.010515451431274e-07.\n",
            "‚úÖ Aumentaci√≥n completada para positivos de TRAIN.\n",
            "\n",
            "üîÑ Preparando negativos para TRAIN...\n",
            "   [TRAIN]: Positivos: 5189. Negativos iniciales necesarios para 1:8 de pos: 41512.\n",
            "   [TRAIN]: Copiando 5189 tiles positivos a la selecci√≥n final.\n",
            "   [TRAIN]: Intentando a√±adir 12453 hard negatives (30% del total necesario).\n",
            "   [TRAIN]: Hard negatives a√±adidos: 12453\n",
            "   [TRAIN]: A√±adiendo 29059 negativos normales.\n",
            "‚úÖ TRAIN: Negativos preparados. Contenido inicial en '/content/mi_dataset_split/train/tiles/final_selection/images' y '/content/mi_dataset_split/train/tiles/negatives_rest/images'.\n",
            "\n",
            "üîÑ Preparando negativos para VALID...\n",
            "   [VALID]: Copiando 170 tiles positivos a la selecci√≥n final.\n",
            "   [VALID]: Moviendo todos los negativos a 'negatives_rest' para rebalanceo posterior.\n",
            "‚úÖ VALID: Negativos preparados. Contenido inicial en '/content/mi_dataset_split/valid/tiles/final_selection/images' y '/content/mi_dataset_split/valid/tiles/negatives_rest/images'.\n",
            "\n",
            "üîÑ Preparando negativos para TEST...\n",
            "   [TEST]: Copiando 170 tiles positivos a la selecci√≥n final.\n",
            "   [TEST]: Moviendo todos los negativos a 'negatives_rest' para rebalanceo posterior.\n",
            "‚úÖ TEST: Negativos preparados. Contenido inicial en '/content/mi_dataset_split/test/tiles/final_selection/images' y '/content/mi_dataset_split/test/tiles/negatives_rest/images'.\n",
            "\n",
            "‚öñÔ∏è Iniciando rebalanceo de los splits VALID y TEST...\n",
            "üìä Tama√±o final del set TRAIN: 46701 im√°genes.\n",
            "üéØ Tama√±o total deseado del dataset: 66716 im√°genes (TRAIN 46701 / 70%).\n",
            "üéØ Tama√±o objetivo para VALID (proporcional): 10007 im√°genes (15% del total).\n",
            "üéØ Tama√±o objetivo para TEST (proporcional): 10007 im√°genes (15% del total).\n",
            "   Ajuste por redondeo: VALID target ajustado a 10008\n",
            "\n",
            "‚öôÔ∏è Ajustando el split VALID con objetivo de 10008 im√°genes...\n",
            "   VALID: Positivos actuales (ya en final_selection): 170\n",
            "   VALID: Negativos totales necesarios para el objetivo (10008 total - 170 pos): 9838\n",
            "   VALID: Hard negatives deseados (10% del total de negativos): 983\n",
            "   VALID: Hard negatives a√±adidos: 983\n",
            "   VALID: A√±adiendo 8855 negativos normales adicionales de 'negatives_rest'.\n",
            "   ‚úÖ VALID: Ajuste de negativos completado. Total final para exportaci√≥n: 10008 im√°genes.\n",
            "\n",
            "‚öôÔ∏è Ajustando el split TEST con objetivo de 10007 im√°genes...\n",
            "   TEST: Positivos actuales (ya en final_selection): 170\n",
            "   TEST: Negativos totales necesarios para el objetivo (10007 total - 170 pos): 9837\n",
            "   TEST: Hard negatives deseados (10% del total de negativos): 983\n",
            "   TEST: Hard negatives a√±adidos: 983\n",
            "   TEST: A√±adiendo 8854 negativos normales adicionales de 'negatives_rest'.\n",
            "   ‚úÖ TEST: Ajuste de negativos completado. Total final para exportaci√≥n: 10007 im√°genes.\n",
            "\n",
            "üìä RESUMEN FINAL DE TILES (Antes de la exportaci√≥n final)\n",
            "\n",
            "üìÅ TRAIN\n",
            "Total en final_selection: 46701 im√°genes | 46701 etiquetas\n",
            "En negatives_rest (sobrantes): 25528 im√°genes | 25528 etiquetas\n",
            "\n",
            "üìÅ VALID\n",
            "Total en final_selection: 10008 im√°genes | 10008 etiquetas\n",
            "En negatives_rest (sobrantes): 2775 im√°genes | 2775 etiquetas\n",
            "\n",
            "üìÅ TEST\n",
            "Total en final_selection: 10007 im√°genes | 10007 etiquetas\n",
            "En negatives_rest (sobrantes): 2880 im√°genes | 2880 etiquetas\n",
            "\n",
            "üì¶ Iniciando export final para entrenamiento YOLOv8...\n",
            "\n",
            "üîÑ Procesando TRAIN...\n",
            "‚úÖ TRAIN: 46701 im√°genes, 46701 labels exportados.\n",
            "üîÑ Procesando VALID...\n",
            "‚úÖ VALID: 10008 im√°genes, 10008 labels exportados.\n",
            "üîÑ Procesando TEST...\n",
            "‚úÖ TEST: 10007 im√°genes, 10007 labels exportados.\n",
            "\n",
            "üöÄ Export final completo en: /content/export_yolov8\n",
            "‚úÖ 'data.yaml' copiado a: /content/export_yolov8/data.yaml\n",
            "‚úÖ Resumen de tiles descartados actualizado en: /content/export_yolov8/errors/tiles_descartados.txt\n",
            "\n",
            "üìä PROPORCI√ìN FINAL DE IM√ÅGENES POR CONJUNTO:\n",
            "TRAIN : 46701 im√°genes (70.00%)\n",
            "VALID : 10008 im√°genes (15.00%)\n",
            "TEST  : 10007 im√°genes (15.00%)\n",
            "TOTAL: 66716 im√°genes\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import albumentations as A\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Fijar la semilla para reproducibilidad\n",
        "SEED = 42\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# --- CONFIGURACI√ìN (editable) ---\n",
        "BASE_DATASET_DIR = \"/content/mi_dataset_split\"\n",
        "EXPORT_DIR = \"/content/export_yolov8\"\n",
        "IMAGE_EXTENSIONS = (\".jpg\", \".jpeg\", \".png\")\n",
        "\n",
        "# Par√°metros para tiling\n",
        "TILE_SIZE = 640\n",
        "OVERLAP = 128\n",
        "\n",
        "\n",
        "# Proporci√≥n deseada de positivos/negativos totales para el conjunto de TRAIN\n",
        "NEGATIVE_MULTIPLIER = 9  # esto asegura 1 positivo por cada 8 negativos, ratio 1:8 o 1/9\n",
        "\n",
        "APPLY_AUGMENTATION = True\n",
        "AUGMENTATIONS_MIN = 6\n",
        "AUGMENTATIONS_MAX = 6\n",
        "\n",
        "# Carpeta de hard negatives (falsos positivos extra√≠dos de una primera inferencia)\n",
        "FORCED_NEGATIVES_SUBFOLDER = \"hard_negatives\"\n",
        "\n",
        "# Porcentaje de hard negatives sobre el *total de negativos* para cada split.\n",
        "HARD_NEG_PERCENTAGE_TRAIN = 0.30\n",
        "HARD_NEG_PERCENTAGE_VALID = 0.10\n",
        "HARD_NEG_PERCENTAGE_TEST = 0.10\n",
        "\n",
        " #!!! NUEVAS VARIABLES DE CONFIGURACI√ìN PARA PORCENTAJES PROPORCIONALES !!!\n",
        "# Estos porcentajes se usar√°n SOLO si VALID_TARGET_COUNT o TEST_TARGET_COUNT son None.\n",
        "TRAIN_SET_PERCENTAGE = 0.70 # Porcentaje del dataset total para entrenamiento (0.70 = 70%)\n",
        "VALID_SET_PERCENTAGE = 0.15 # Porcentaje del dataset total para validaci√≥n (0.15 = 15%)\n",
        "TEST_SET_PERCENTAGE = 0.15  # Porcentaje del dataset total para test (0.15 = 15%)\n",
        "# !!! FIN NUEVAS VARIABLES DE CONFIGURACI√ìN PARA PORCENTAJES PROPORCIONALES !!!\n",
        "\n",
        "# !!! NUEVAS VARIABLES DE CONFIGURACI√ìN !!!\n",
        "#ESTO ES PARA AMPLIFICACION, CUANDO QUIERES QUE EL TEST SET Y VALID SET TENGAN MISMO NUMERO QUE MINISEAL PERO CON TRAIN DE MEDIUMSEAL\n",
        "# Si se establece un n√∫mero entero, se usar√° como el tama√±o fijo del split.\n",
        "# Si se deja en None, se calcular√° como el 15% del tama√±o final de TRAIN.\n",
        "VALID_TARGET_COUNT = None   # Ejemplo: 6000 para un tama√±o fijo de 6000 im√°genes para VALID  @ al PONER None, vale para los demas datasets!########################333\n",
        "TEST_TARGET_COUNT = None    # Ejemplo: None para que se calcule el 15% para TEST\n",
        "# !!! FIN NUEVAS VARIABLES DE CONFIGURACI√ìN !!!\n",
        "\n",
        "\n",
        "# Rutas para el data.yaml:\n",
        "INPUT_YAML_PATH = os.path.join(BASE_DATASET_DIR, \"data.yaml\")\n",
        "EXPORT_YAML_PATH = os.path.join(EXPORT_DIR, \"data.yaml\")\n",
        "\n",
        "# Control de limpieza de carpetas intermedias\n",
        "CLEAN_INTERMEDIATE = False\n",
        "\n",
        "# --- Fin de Configuraci√≥n ---\n",
        "\n",
        "# --- Funciones Auxiliares (mantienen el c√≥digo existente) ---\n",
        "def count_files(folder):\n",
        "    \"\"\"Cuenta el n√∫mero de archivos en una carpeta.\"\"\"\n",
        "    if not os.path.exists(folder):\n",
        "        return 0\n",
        "    return len([f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))])\n",
        "\n",
        "def polygon_to_bbox(coords):\n",
        "    \"\"\"\n",
        "    Convierte una lista de coordenadas de un pol√≠gono [x1, y1, x2, y2, ..., xN, yN]\n",
        "    a una bounding box en formato YOLO: (x_center, y_center, width, height).\n",
        "    \"\"\"\n",
        "    if not coords or len(coords) % 2 != 0:\n",
        "        return None\n",
        "    xs = coords[0::2]\n",
        "    ys = coords[1::2]\n",
        "    if not xs or not ys:\n",
        "        return None\n",
        "    x_min, x_max = min(xs), max(xs)\n",
        "    y_min, y_max = min(ys), max(ys)\n",
        "    return (x_min + x_max) / 2, (y_min + y_max) / 2, x_max - x_min, y_max - y_min\n",
        "\n",
        "def process_label_file(src_file, dst_file):\n",
        "    \"\"\"Procesa un archivo de etiqueta, convirtiendo pol√≠gonos a BBoxes si es necesario.\"\"\"\n",
        "    with open(src_file, 'r') as f_in:\n",
        "        lines = f_in.readlines()\n",
        "    new_lines = []\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()\n",
        "        if not parts:\n",
        "            continue\n",
        "        cls = parts[0]\n",
        "        try:\n",
        "            coords = list(map(float, parts[1:]))\n",
        "        except Exception as e:\n",
        "            print(f\"Error procesando coordenadas en {src_file}: {e}\")\n",
        "            continue\n",
        "\n",
        "        if len(coords) == 4:\n",
        "            # Ya en formato bbox (x_center, y_center, w, h)\n",
        "            new_line = f\"{cls} {' '.join(f'{c:.16f}' for c in coords)}\"\n",
        "        else:\n",
        "            bbox = polygon_to_bbox(coords)\n",
        "            if bbox is None:\n",
        "                print(f\"Warning: No se pudo convertir el pol√≠gono en {src_file}. L√≠nea saltada.\")\n",
        "                continue\n",
        "            x_center, y_center, width, height = bbox\n",
        "            new_line = f\"{cls} {x_center:.16f} {y_center:.16f} {width:.16f} {height:.16f}\"\n",
        "        new_lines.append(new_line)\n",
        "    with open(dst_file, 'w') as f_out:\n",
        "        for new_line in new_lines:\n",
        "            f_out.write(new_line + \"\\n\")\n",
        "\n",
        "def load_annotations(label_path, image_width, image_height):\n",
        "    \"\"\"Carga anotaciones YOLO de un archivo y las convierte a coordenadas absolutas.\"\"\"\n",
        "    annotations = []\n",
        "    if not os.path.exists(label_path):\n",
        "        return annotations\n",
        "    with open(label_path, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if not parts:\n",
        "                continue\n",
        "            cls = parts[0]\n",
        "            coords = list(map(float, parts[1:]))\n",
        "            # Asume formato YOLO: x_center, y_center, w, h (normalizado)\n",
        "            x_center, y_center, w, h = coords\n",
        "            x1 = (x_center - w/2) * image_width\n",
        "            y1 = (y_center - h/2) * image_height\n",
        "            x2 = (x_center + w/2) * image_width\n",
        "            y2 = (y_center + h/2) * image_height\n",
        "            annotations.append((cls, x1, y1, x2, y2))\n",
        "    return annotations\n",
        "\n",
        "def adjust_annotation_for_tile(annotation, tile_x, tile_y, tile_size):\n",
        "    \"\"\"\n",
        "    Ajusta una anotaci√≥n al sistema de coordenadas locales del tile y la normaliza.\n",
        "    Si la intersecci√≥n es insuficiente o el tama√±o es muy peque√±o, retorna None.\n",
        "    \"\"\"\n",
        "    cls, x1, y1, x2, y2 = annotation\n",
        "    inter_x1 = max(x1, tile_x)\n",
        "    inter_y1 = max(y1, tile_y)\n",
        "    inter_x2 = min(x2, tile_x + tile_size)\n",
        "    inter_y2 = min(y2, tile_y + tile_size)\n",
        "\n",
        "    if inter_x2 <= inter_x1 or inter_y2 <= inter_y1:\n",
        "        return None\n",
        "\n",
        "    local_x1 = inter_x1 - tile_x\n",
        "    local_y1 = inter_y1 - tile_y\n",
        "    local_x2 = inter_x2 - tile_x\n",
        "    local_y2 = inter_y2 - tile_y\n",
        "\n",
        "    w = local_x2 - local_x1\n",
        "    h = local_y2 - local_y1\n",
        "    x_center = local_x1 + w / 2\n",
        "    y_center = local_y1 + h / 2\n",
        "\n",
        "    # Normalizar al tama√±o del tile [0,1]\n",
        "    norm_x = max(0.0, min(1.0, x_center / tile_size))\n",
        "    norm_y = max(0.0, min(1.0, y_center / tile_size))\n",
        "    norm_w = max(0.0, min(1.0, w / tile_size))\n",
        "    norm_h = max(0.0, min(1.0, h / tile_size))\n",
        "\n",
        "    # Umbral m√≠nimo para evitar cajas insignificantes\n",
        "    MIN_SIZE_RATIO = 0.01\n",
        "    if norm_w < MIN_SIZE_RATIO or norm_h < MIN_SIZE_RATIO:\n",
        "        return None\n",
        "    return (cls, norm_x, norm_y, norm_w, norm_h)\n",
        "\n",
        "def read_yolo_labels(label_path):\n",
        "    \"\"\"Lee etiquetas YOLO de un archivo.\"\"\"\n",
        "    bboxes, classes = [], []\n",
        "    if os.path.exists(label_path):\n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) == 5:\n",
        "                    classes.append(parts[0])\n",
        "                    bboxes.append(list(map(float, parts[1:])))\n",
        "    return bboxes, classes\n",
        "\n",
        "def safe_copy(src_dir, dst_dir, extensions=None):\n",
        "    \"\"\"Copia archivos de forma segura, evitando sobrescrituras y filtrando por extensi√≥n.\"\"\"\n",
        "    copied = 0\n",
        "    if not os.path.exists(src_dir):\n",
        "        print(f\"Warning: Directorio de origen no encontrado: {src_dir}. Se omite la copia.\")\n",
        "        return 0\n",
        "\n",
        "    for fname in os.listdir(src_dir):\n",
        "        if extensions and not fname.lower().endswith(extensions):\n",
        "            continue\n",
        "        src = os.path.join(src_dir, fname)\n",
        "        dst = os.path.join(dst_dir, fname)\n",
        "\n",
        "        # Si el destino ya existe, renombra para evitar conflictos\n",
        "        if os.path.exists(dst):\n",
        "            base, ext = os.path.splitext(fname)\n",
        "            i = 1\n",
        "            while os.path.exists(os.path.join(dst_dir, f\"{base}_{i}{ext}\")):\n",
        "                i += 1\n",
        "            dst = os.path.join(dst_dir, f\"{base}_{i}{ext}\")\n",
        "\n",
        "        shutil.copy2(src, dst)\n",
        "        copied += 1\n",
        "    return copied\n",
        "\n",
        "def select_and_copy_hard_negatives(num_needed, dest_img_dir, dest_lbl_dir,\n",
        "                                     global_hard_images_pool,\n",
        "                                     hard_negatives_used_tracker):\n",
        "    \"\"\"\n",
        "    Selecciona `num_needed` hard negatives del pool global que a√∫n no han sido usados\n",
        "    y los copia al directorio de destino.\n",
        "    Actualiza el tracker de hard negatives usados.\n",
        "    \"\"\"\n",
        "    added_count = 0\n",
        "    if num_needed <= 0 or not global_hard_images_pool:\n",
        "        return 0\n",
        "\n",
        "    available_hard = [f for f in global_hard_images_pool if f not in hard_negatives_used_tracker]\n",
        "\n",
        "    if not available_hard:\n",
        "        return 0\n",
        "\n",
        "    if num_needed > len(available_hard):\n",
        "        selected_to_add = available_hard\n",
        "    else:\n",
        "        random.seed(SEED)\n",
        "        selected_to_add = random.sample(available_hard, num_needed)\n",
        "\n",
        "    src_img_dir = os.path.join(BASE_DATASET_DIR, FORCED_NEGATIVES_SUBFOLDER, \"tiles\", \"images\")\n",
        "    src_lbl_dir = os.path.join(BASE_DATASET_DIR, FORCED_NEGATIVES_SUBFOLDER, \"tiles\", \"labels\")\n",
        "\n",
        "    for fname in selected_to_add:\n",
        "        lbl_name = os.path.splitext(fname)[0] + \".txt\"\n",
        "        shutil.copy2(os.path.join(src_img_dir, fname), os.path.join(dest_img_dir, fname))\n",
        "        shutil.copy2(os.path.join(src_lbl_dir, lbl_name), os.path.join(dest_lbl_dir, lbl_name))\n",
        "        hard_negatives_used_tracker.add(fname)\n",
        "        added_count += 1\n",
        "    return added_count\n",
        "\n",
        "\n",
        "# --- Pasos del Pipeline ---\n",
        "\n",
        "def process_all_labels_for_set(set_name):\n",
        "    \"\"\"Convierte todas las etiquetas de pol√≠gonos a bounding boxes para un set.\"\"\"\n",
        "    print(f\"\\nüîÑ Convirtiendo etiquetas de {set_name.upper()}...\")\n",
        "    src_dir = os.path.join(BASE_DATASET_DIR, set_name, \"labels\")\n",
        "    dst_dir = os.path.join(BASE_DATASET_DIR, set_name, \"bblabels\")\n",
        "    os.makedirs(dst_dir, exist_ok=True)\n",
        "    for filename in os.listdir(src_dir):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            process_label_file(os.path.join(src_dir, filename), os.path.join(dst_dir, filename))\n",
        "    print(f\"‚úÖ [{set_name.upper()}] Conversi√≥n de etiquetas completada.\")\n",
        "\n",
        "def tile_and_separate(image_path, label_path, out_pos_img, out_pos_lbl, out_neg_img, out_neg_lbl, split_name=\"unknown\"):\n",
        "    \"\"\"\n",
        "    Genera tiles de una imagen y sus anotaciones, separ√°ndolos en positivos (con objetos)\n",
        "    y negativos (sin objetos).\n",
        "    \"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"‚ùå No se pudo leer la imagen: {image_path}, se omite.\")\n",
        "        return 0, 0\n",
        "    orig_h, orig_w = image.shape[:2]\n",
        "    annotations = load_annotations(label_path, orig_w, orig_h)\n",
        "    step = TILE_SIZE - OVERLAP\n",
        "    count_pos, count_neg = 0, 0 # Initialize count_pos and count_neg\n",
        "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "    tile_idx = 0\n",
        "\n",
        "    log_dir = os.path.join(EXPORT_DIR, \"errors\")\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "    log_path = os.path.join(log_dir, \"tiles_descartados.txt\")\n",
        "    discard_entries = []\n",
        "\n",
        "    for y in range(0, orig_h, step):\n",
        "        for x in range(0, orig_w, step):\n",
        "            tile = image[y:min(y+TILE_SIZE, orig_h), x:min(x+TILE_SIZE, orig_w)]\n",
        "\n",
        "            # Rellenar tile si es m√°s peque√±o que TILE_SIZE\n",
        "            if tile.shape[0] < TILE_SIZE or tile.shape[1] < TILE_SIZE:\n",
        "                padded = np.zeros((TILE_SIZE, TILE_SIZE, 3), dtype=tile.dtype)\n",
        "                padded[0:tile.shape[0], 0:tile.shape[1]] = tile\n",
        "                tile = padded\n",
        "\n",
        "            tile_name = f\"{base_name}_tile_{tile_idx}.jpg\"\n",
        "            label_name = f\"{base_name}_tile_{tile_idx}.txt\"\n",
        "            tile_idx += 1\n",
        "\n",
        "            valid_annots = []\n",
        "            for ann in annotations:\n",
        "                result = adjust_annotation_for_tile(ann, x, y, TILE_SIZE)\n",
        "                if result:\n",
        "                    valid_annots.append(result)\n",
        "\n",
        "            if valid_annots:\n",
        "                # Tile positivo (contiene objetos)\n",
        "                cv2.imwrite(os.path.join(out_pos_img, tile_name), tile)\n",
        "                with open(os.path.join(out_pos_lbl, label_name), 'w') as f:\n",
        "                    for cls, xc, yc, w, h in valid_annots:\n",
        "                        f.write(f\"{cls} {xc:.6f} {yc:.6f} {w:.6f} {h:.6f}\\n\")\n",
        "                count_pos += 1\n",
        "            else:\n",
        "                # Tile negativo (no contiene objetos)\n",
        "                cv2.imwrite(os.path.join(out_neg_img, tile_name), tile)\n",
        "                open(os.path.join(out_neg_lbl, label_name), 'w').close()\n",
        "                count_neg += 1\n",
        "                discard_entries.append(\n",
        "                    f\"{tile_name} | de {base_name} @ x={x}, y={y} ‚Üí {len(annotations)} cajas totales, 0 v√°lidas.\"\n",
        "                )\n",
        "\n",
        "    if discard_entries:\n",
        "        with open(log_path, \"a\") as log:\n",
        "            log.write(f\"\\nüîπ TILES DESCARTADOS EN {split_name.upper()} (original: {base_name})\\n\")\n",
        "            log.write(\"-\" * 50 + \"\\n\")\n",
        "            for entry in discard_entries:\n",
        "                log.write(entry + \"\\n\")\n",
        "\n",
        "    return count_pos, count_neg # Corrected: return count_pos and count_neg\n",
        "\n",
        "def process_tiling_for_set(set_name):\n",
        "    \"\"\"Procesa el tiling para un set de datos (train, valid, test).\"\"\"\n",
        "    print(f\"\\nüì¶ Procesando tiling para {set_name.upper()}...\")\n",
        "    input_img_dir = os.path.join(BASE_DATASET_DIR, set_name, \"images\")\n",
        "    input_lbl_dir = os.path.join(BASE_DATASET_DIR, set_name, \"bblabels\")\n",
        "    pos_img = os.path.join(BASE_DATASET_DIR, set_name, \"tiles\", \"positives\", \"images\")\n",
        "    pos_lbl = os.path.join(BASE_DATASET_DIR, set_name, \"tiles\", \"positives\", \"labels\")\n",
        "    neg_img = os.path.join(BASE_DATASET_DIR, set_name, \"tiles\", \"negatives\", \"images\")\n",
        "    neg_lbl = os.path.join(BASE_DATASET_DIR, set_name, \"tiles\", \"negatives\", \"labels\")\n",
        "    os.makedirs(pos_img, exist_ok=True)\n",
        "    os.makedirs(pos_lbl, exist_ok=True)\n",
        "    os.makedirs(neg_img, exist_ok=True)\n",
        "    os.makedirs(neg_lbl, exist_ok=True)\n",
        "\n",
        "    image_files = [f for f in os.listdir(input_img_dir) if f.lower().endswith(IMAGE_EXTENSIONS)]\n",
        "    total_pos, total_neg = 0, 0\n",
        "    for img_file in image_files:\n",
        "        img_path = os.path.join(input_img_dir, img_file)\n",
        "        lbl_path = os.path.join(input_lbl_dir, os.path.splitext(img_file)[0] + \".txt\")\n",
        "        pos, neg = tile_and_separate(img_path, lbl_path, pos_img, pos_lbl, neg_img, neg_lbl, split_name=set_name.upper())\n",
        "        total_pos += pos\n",
        "        total_neg += neg\n",
        "    print(f\"‚úÖ {set_name.upper()}: {total_pos} tiles positivos, {total_neg} negativos (generados inicialmente).\")\n",
        "\n",
        "def process_forced_negatives_tiling():\n",
        "    \"\"\"Genera tiles de las im√°genes de 'hard_negatives' (falsos positivos de inferencia previa).\"\"\"\n",
        "    img_dir = os.path.join(BASE_DATASET_DIR, FORCED_NEGATIVES_SUBFOLDER, \"train\", \"images\")\n",
        "    lbl_dir = os.path.join(BASE_DATASET_DIR, FORCED_NEGATIVES_SUBFOLDER, \"train\", \"labels\")\n",
        "\n",
        "    if not os.path.exists(os.path.join(BASE_DATASET_DIR, FORCED_NEGATIVES_SUBFOLDER)):\n",
        "        print(f\"‚ö†Ô∏è Carpeta de negativos forzados '{FORCED_NEGATIVES_SUBFOLDER}' no encontrada en '{BASE_DATASET_DIR}'. Se omite este paso.\")\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(img_dir) or not os.path.exists(lbl_dir) or not any(f.lower().endswith(IMAGE_EXTENSIONS) for f in os.listdir(img_dir)):\n",
        "        print(f\"‚ö†Ô∏è No hay im√°genes en la carpeta de negativos forzados: {img_dir}. Se omite este paso.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nüß© Procesando TILES de negativos forzados (falsos positivos)...\")\n",
        "\n",
        "    out_img_dir = os.path.join(BASE_DATASET_DIR, FORCED_NEGATIVES_SUBFOLDER, \"tiles\", \"images\")\n",
        "    out_lbl_dir = os.path.join(BASE_DATASET_DIR, FORCED_NEGATIVES_SUBFOLDER, \"tiles\", \"labels\")\n",
        "    os.makedirs(out_img_dir, exist_ok=True)\n",
        "    os.makedirs(out_lbl_dir, exist_ok=True)\n",
        "\n",
        "    step = TILE_SIZE - OVERLAP\n",
        "    total_tiles = 0\n",
        "\n",
        "    for img_name in os.listdir(img_dir):\n",
        "        if not img_name.lower().endswith(IMAGE_EXTENSIONS):\n",
        "            continue\n",
        "\n",
        "        img_path = os.path.join(img_dir, img_name)\n",
        "        label_path = os.path.join(lbl_dir, os.path.splitext(img_name)[0] + \".txt\")\n",
        "\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is None:\n",
        "            print(f\"‚ùå No se pudo leer {img_name}, se omite.\")\n",
        "            continue\n",
        "\n",
        "        h, w = image.shape[:2]\n",
        "        base_name = os.path.splitext(img_name)[0]\n",
        "        tile_idx = 0\n",
        "\n",
        "        for y in range(0, h, step):\n",
        "            for x in range(0, w, step):\n",
        "                tile = image[y:min(y+TILE_SIZE, h), x:min(x+TILE_SIZE, w)]\n",
        "                if tile.shape[0] < TILE_SIZE or tile.shape[1] < TILE_SIZE:\n",
        "                    padded = np.zeros((TILE_SIZE, TILE_SIZE, 3), dtype=tile.dtype)\n",
        "                    padded[0:tile.shape[0], 0:tile.shape[1]] = tile\n",
        "                    tile = padded\n",
        "\n",
        "                tile_name = f\"{base_name}_tile_{tile_idx}.jpg\"\n",
        "                label_name = f\"{base_name}_tile_{tile_idx}.txt\"\n",
        "                cv2.imwrite(os.path.join(out_img_dir, tile_name), tile)\n",
        "\n",
        "                # For forced negatives, copy the existing label file (even if empty, usually they are)\n",
        "                shutil.copy2(label_path, os.path.join(out_lbl_dir, label_name))\n",
        "                tile_idx += 1\n",
        "\n",
        "        total_tiles += tile_idx\n",
        "\n",
        "    print(f\"‚úÖ TILES de negativos forzados completados: {total_tiles} tiles generados.\")\n",
        "\n",
        "def check_forced_tiles():\n",
        "    \"\"\"Verifica la cantidad de tiles de negativos forzados generados.\"\"\"\n",
        "    img_dir = os.path.join(BASE_DATASET_DIR, FORCED_NEGATIVES_SUBFOLDER, \"tiles\", \"images\")\n",
        "    lbl_dir = os.path.join(BASE_DATASET_DIR, FORCED_NEGATIVES_SUBFOLDER, \"tiles\", \"labels\")\n",
        "\n",
        "    n_img = count_files(img_dir) if os.path.exists(img_dir) else 0\n",
        "    n_lbl = count_files(lbl_dir) if os.path.exists(lbl_dir) else 0\n",
        "\n",
        "    print(f\"\\nüîç Verificaci√≥n TILES negativos forzados:\")\n",
        "    print(f\"üñºÔ∏è  Tiles: {n_img}\")\n",
        "    print(f\"üìÑ Etiquetas (vac√≠as): {n_lbl}\")\n",
        "\n",
        "# --- Data Augmentation ---\n",
        "transform_pipeline = A.Compose([\n",
        "    A.SomeOf([\n",
        "        A.HorizontalFlip(p=1.0),\n",
        "        A.Rotate(limit=(-5, 5), p=1.0),\n",
        "        A.Affine(shear=(-5, 5), p=1.0),\n",
        "        A.RandomBrightnessContrast(brightness_limit=(-0.05, 0.05), contrast_limit=(-0.05, 0.05), p=1.0),\n",
        "        A.Blur(blur_limit=5, p=1.0),\n",
        "        A.CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8)),\n",
        "        A.ToGray(p=0.01, num_output_channels=3, method='weighted_average'),\n",
        "    ], n=4, replace=True),\n",
        "    A.Resize(TILE_SIZE, TILE_SIZE)\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['labels']))\n",
        "\n",
        "def augment_positives():\n",
        "    \"\"\"Aumenta los tiles positivos del conjunto de entrenamiento.\"\"\"\n",
        "    input_img_dir = os.path.join(BASE_DATASET_DIR, \"train\", \"tiles\", \"positives\", \"images\")\n",
        "    input_lbl_dir = os.path.join(BASE_DATASET_DIR, \"train\", \"tiles\", \"positives\", \"labels\")\n",
        "    output_img_dir = os.path.join(BASE_DATASET_DIR, \"train\", \"tiles\", \"aug\", \"positives\", \"images\")\n",
        "    output_lbl_dir = os.path.join(BASE_DATASET_DIR, \"train\", \"tiles\", \"aug\", \"positives\", \"labels\")\n",
        "    os.makedirs(output_img_dir, exist_ok=True)\n",
        "    os.makedirs(output_lbl_dir, exist_ok=True)\n",
        "\n",
        "    print(\"\\n‚ú® Iniciando aumentaci√≥n de datos para positivos de TRAIN...\")\n",
        "\n",
        "    for filename in os.listdir(input_img_dir):\n",
        "        if not filename.lower().endswith(IMAGE_EXTENSIONS): continue\n",
        "        img_path = os.path.join(input_img_dir, filename)\n",
        "        label_path = os.path.join(input_lbl_dir, os.path.splitext(filename)[0] + \".txt\")\n",
        "\n",
        "        bboxes, classes = read_yolo_labels(label_path)\n",
        "\n",
        "        # Always copy the original positive image and its label\n",
        "        shutil.copy2(img_path, os.path.join(output_img_dir, filename))\n",
        "        shutil.copy2(label_path, os.path.join(output_lbl_dir, os.path.splitext(filename)[0] + \".txt\"))\n",
        "\n",
        "        # Only apply augmentation if there are bboxes\n",
        "        if len(bboxes) == 0:\n",
        "            continue\n",
        "\n",
        "        random.seed(SEED) # Ensure reproducibility of random number of augmentations\n",
        "        num_variants = random.randint(AUGMENTATIONS_MIN, AUGMENTATIONS_MAX)\n",
        "\n",
        "        for i in range(num_variants):\n",
        "            image_bgr = cv2.imread(img_path)\n",
        "            if image_bgr is None: continue\n",
        "            image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            try:\n",
        "                # Use a different seed for each augmentation variant\n",
        "                random.seed(SEED + i)\n",
        "                np.random.seed(SEED + i)\n",
        "\n",
        "                result = transform_pipeline(image=image_rgb, bboxes=bboxes, labels=classes)\n",
        "            except Exception as e:\n",
        "                print(f\"Error aplicando aumentaci√≥n en {filename}: {e}\"); continue\n",
        "\n",
        "            aug_img_rgb = result[\"image\"]\n",
        "            aug_bboxes = result[\"bboxes\"]\n",
        "            aug_labels = result[\"labels\"]\n",
        "\n",
        "            # Clipear las coordenadas de las bounding boxes para asegurar que est√©n dentro de [0.0, 1.0]\n",
        "            clipped_bboxes = []\n",
        "            for bbox in aug_bboxes:\n",
        "                clipped_bbox = [max(0.0, min(1.0, val)) for val in bbox]\n",
        "                clipped_bboxes.append(clipped_bbox)\n",
        "\n",
        "            aug_img_bgr = cv2.cvtColor(aug_img_rgb, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "            new_img_name = f\"{os.path.splitext(filename)[0]}_aug{i}.jpg\"\n",
        "            new_lbl_name = f\"{os.path.splitext(filename)[0]}_aug{i}.txt\"\n",
        "\n",
        "            cv2.imwrite(os.path.join(output_img_dir, new_img_name), aug_img_bgr)\n",
        "\n",
        "            with open(os.path.join(output_lbl_dir, new_lbl_name), 'w') as f:\n",
        "                for cls, bbox in zip(aug_labels, clipped_bboxes):\n",
        "                    f.write(f\"{cls} {bbox[0]:.6f} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f}\\n\")\n",
        "    print(\"‚úÖ Aumentaci√≥n completada para positivos de TRAIN.\")\n",
        "\n",
        "def split_negatives(set_name, global_hard_images_pool, hard_negatives_used_tracker):\n",
        "    \"\"\"\n",
        "    Gestiona la distribuci√≥n inicial de negativos y hard negatives para cada set.\n",
        "    Para TRAIN: selecciona hard negatives y normales y copia positivos.\n",
        "    Para VALID/TEST: mueve todos los negativos a 'negatives_rest' para el rebalanceo posterior.\n",
        "    \"\"\"\n",
        "    print(f\"\\nüîÑ Preparando negativos para {set_name.upper()}...\")\n",
        "\n",
        "    pos_img_source_dir = (os.path.join(BASE_DATASET_DIR, set_name, \"tiles\", \"aug\", \"positives\", \"images\")\n",
        "                            if APPLY_AUGMENTATION and set_name == \"train\"\n",
        "                            else os.path.join(BASE_DATASET_DIR, set_name, \"tiles\", \"positives\", \"images\"))\n",
        "    pos_lbl_source_dir = (os.path.join(BASE_DATASET_DIR, set_name, \"tiles\", \"aug\", \"positives\", \"labels\")\n",
        "                            if APPLY_AUGMENTATION and set_name == \"train\"\n",
        "                            else os.path.join(BASE_DATASET_DIR, set_name, \"tiles\", \"positives\", \"labels\"))\n",
        "\n",
        "    neg_img_source_dir = os.path.join(BASE_DATASET_DIR, set_name, \"tiles\", \"negatives\", \"images\")\n",
        "    neg_lbl_source_dir = os.path.join(BASE_DATASET_DIR, set_name, \"tiles\", \"negatives\", \"labels\")\n",
        "\n",
        "    dest_final_img = os.path.join(BASE_DATASET_DIR, set_name, \"tiles\", \"final_selection\", \"images\")\n",
        "    dest_final_lbl = os.path.join(BASE_DATASET_DIR, set_name, \"tiles\", \"final_selection\", \"labels\")\n",
        "    os.makedirs(dest_final_img, exist_ok=True)\n",
        "    os.makedirs(dest_final_lbl, exist_ok=True)\n",
        "\n",
        "    dest_rest_img = os.path.join(BASE_DATASET_DIR, set_name, \"tiles\", \"negatives_rest\", \"images\")\n",
        "    dest_rest_lbl = os.path.join(BASE_DATASET_DIR, set_name, \"tiles\", \"negatives_rest\", \"labels\")\n",
        "    os.makedirs(dest_rest_img, exist_ok=True)\n",
        "    os.makedirs(dest_rest_lbl, exist_ok=True)\n",
        "\n",
        "    num_pos = count_files(pos_img_source_dir)\n",
        "    all_neg_images_from_source = [f for f in os.listdir(neg_img_source_dir) if f.lower().endswith(IMAGE_EXTENSIONS)] if os.path.exists(neg_img_source_dir) else []\n",
        "\n",
        "    num_total_neg_needed_initial = max(0, NEGATIVE_MULTIPLIER * num_pos - num_pos)\n",
        "\n",
        "    # --- L√≥gica espec√≠fica para TRAIN ---\n",
        "    if set_name == \"train\":\n",
        "        hard_neg_percentage = HARD_NEG_PERCENTAGE_TRAIN\n",
        "        desired_hard_neg_count = int(num_total_neg_needed_initial * hard_neg_percentage)\n",
        "\n",
        "        print(f\"   [TRAIN]: Positivos: {num_pos}. Negativos iniciales necesarios para 1:{NEGATIVE_MULTIPLIER-1} de pos: {num_total_neg_needed_initial}.\")\n",
        "\n",
        "        # 1. Copiar los positivos (ya aumentados para TRAIN) a la carpeta final_selection\n",
        "        print(f\"   [TRAIN]: Copiando {num_pos} tiles positivos a la selecci√≥n final.\")\n",
        "        for fname in os.listdir(pos_img_source_dir):\n",
        "            if fname.lower().endswith(IMAGE_EXTENSIONS):\n",
        "                shutil.copy2(os.path.join(pos_img_source_dir, fname), os.path.join(dest_final_img, fname))\n",
        "                shutil.copy2(os.path.join(pos_lbl_source_dir, os.path.splitext(fname)[0] + \".txt\"), os.path.join(dest_final_lbl, os.path.splitext(fname)[0] + \".txt\"))\n",
        "\n",
        "        # 2. A√±adir hard negatives\n",
        "        if hard_neg_percentage > 0:\n",
        "            print(f\"   [TRAIN]: Intentando a√±adir {desired_hard_neg_count} hard negatives ({hard_neg_percentage*100:.0f}% del total necesario).\")\n",
        "            added_hard = select_and_copy_hard_negatives(\n",
        "                desired_hard_neg_count, dest_final_img, dest_final_lbl,\n",
        "                global_hard_images_pool, hard_negatives_used_tracker\n",
        "            )\n",
        "            print(f\"   [TRAIN]: Hard negatives a√±adidos: {added_hard}\")\n",
        "        else:\n",
        "            added_hard = 0\n",
        "            print(\"   [TRAIN]: Porcentaje de hard negatives es 0, no se a√±adir√°n.\")\n",
        "\n",
        "        total_negatives_for_train = max(0, num_pos * (NEGATIVE_MULTIPLIER - 1))\n",
        "        normals_to_add = max(0, total_negatives_for_train - added_hard)\n",
        "\n",
        "        available_normal_negatives = [f for f in all_neg_images_from_source if f not in hard_negatives_used_tracker]\n",
        "\n",
        "        if normals_to_add > 0 and available_normal_negatives:\n",
        "            random.seed(SEED)\n",
        "            selected_normal_for_train = random.sample(\n",
        "                available_normal_negatives, min(normals_to_add, len(available_normal_negatives))\n",
        "            )\n",
        "            print(f\"   [TRAIN]: A√±adiendo {len(selected_normal_for_train)} negativos normales.\")\n",
        "            for fname in selected_normal_for_train:\n",
        "                shutil.copy2(os.path.join(neg_img_source_dir, fname), os.path.join(dest_final_img, fname))\n",
        "                shutil.copy2(os.path.join(neg_lbl_source_dir, os.path.splitext(fname)[0] + \".txt\"), os.path.join(dest_final_lbl, os.path.splitext(fname)[0] + \".txt\"))\n",
        "                hard_negatives_used_tracker.add(fname) # Track normal negatives too, so they aren't used again.\n",
        "\n",
        "        remaining_negatives_after_train_selection = [f for f in all_neg_images_from_source if f not in hard_negatives_used_tracker]\n",
        "        for fname in remaining_negatives_after_train_selection:\n",
        "             shutil.copy2(os.path.join(neg_img_source_dir, fname), os.path.join(dest_rest_img, fname))\n",
        "             shutil.copy2(os.path.join(neg_lbl_source_dir, os.path.splitext(fname)[0] + \".txt\"), os.path.join(dest_rest_lbl, os.path.splitext(fname)[0] + \".txt\"))\n",
        "\n",
        "    # --- L√≥gica para VALID y TEST ---\n",
        "    else:\n",
        "        # Copiar los positivos a la carpeta final_selection\n",
        "        print(f\"   [{set_name.upper()}]: Copiando {num_pos} tiles positivos a la selecci√≥n final.\")\n",
        "        for fname in os.listdir(pos_img_source_dir):\n",
        "            if fname.lower().endswith(IMAGE_EXTENSIONS):\n",
        "                shutil.copy2(os.path.join(pos_img_source_dir, fname), os.path.join(dest_final_img, fname))\n",
        "                shutil.copy2(os.path.join(pos_lbl_source_dir, os.path.splitext(fname)[0] + \".txt\"), os.path.join(dest_final_lbl, os.path.splitext(fname)[0] + \".txt\"))\n",
        "\n",
        "        print(f\"   [{set_name.upper()}]: Moviendo todos los negativos a 'negatives_rest' para rebalanceo posterior.\")\n",
        "        for fname in all_neg_images_from_source:\n",
        "            shutil.copy2(os.path.join(neg_img_source_dir, fname), os.path.join(dest_rest_img, fname))\n",
        "            shutil.copy2(os.path.join(neg_lbl_source_dir, os.path.splitext(fname)[0] + \".txt\"), os.path.join(dest_rest_lbl, os.path.splitext(fname)[0] + \".txt\"))\n",
        "\n",
        "    if CLEAN_INTERMEDIATE:\n",
        "        # Make sure the paths exist before trying to remove them\n",
        "        if os.path.exists(neg_img_source_dir):\n",
        "            # Remove the parent directory 'negatives' which contains 'images' and 'labels'\n",
        "            shutil.rmtree(os.path.dirname(neg_img_source_dir))\n",
        "        if os.path.exists(pos_img_source_dir):\n",
        "            # Remove the parent directory 'positives' or 'aug/positives'\n",
        "            # Adjust path depending on augmentation being applied or not\n",
        "            if set_name == \"train\" and APPLY_AUGMENTATION:\n",
        "                shutil.rmtree(os.path.dirname(os.path.dirname(pos_img_source_dir))) # Removes 'aug' folder\n",
        "            else:\n",
        "                shutil.rmtree(os.path.dirname(pos_img_source_dir)) # Removes 'positives' folder\n",
        "\n",
        "    print(f\"‚úÖ {set_name.upper()}: Negativos preparados. Contenido inicial en '{dest_final_img}' y '{dest_rest_img}'.\")\n",
        "\n",
        "\n",
        "def rebalance_validation_test_splits(global_hard_images_pool, hard_negatives_used_tracker):\n",
        "    \"\"\"\n",
        "    Rebalancea los splits VALID y TEST para alcanzar las proporciones finales\n",
        "    o el n√∫mero de im√°genes deseado, incluyendo los porcentajes de hard negatives.\n",
        "    \"\"\"\n",
        "    print(\"\\n‚öñÔ∏è Iniciando rebalanceo de los splits VALID y TEST...\")\n",
        "\n",
        "    train_final_img_dir = os.path.join(BASE_DATASET_DIR, \"train\", \"tiles\", \"final_selection\", \"images\")\n",
        "    final_train_size = count_files(train_final_img_dir)\n",
        "\n",
        "    if final_train_size == 0:\n",
        "        print(\"‚ùå El set de TRAIN est√° vac√≠o o no se ha procesado correctamente. No se puede rebalancear VALID/TEST.\")\n",
        "        return\n",
        "\n",
        "    print(f\"üìä Tama√±o final del set TRAIN: {final_train_size} im√°genes.\")\n",
        "\n",
        "     # Calculate proportional targets if not explicitly set\n",
        "    # El tama√±o total del dataset se infiere de que TRAIN_SET_PERCENTAGE del total\n",
        "    # debe ser igual al final_train_size.\n",
        "    if TRAIN_SET_PERCENTAGE <= 0 or TRAIN_SET_PERCENTAGE > 1:\n",
        "        raise ValueError(\"TRAIN_SET_PERCENTAGE debe ser un valor entre 0 y 1.\")\n",
        "\n",
        "    total_dataset_target = round(final_train_size / TRAIN_SET_PERCENTAGE)\n",
        "    print(f\"üéØ Tama√±o total deseado del dataset: {total_dataset_target} im√°genes (TRAIN {final_train_size} / {TRAIN_SET_PERCENTAGE*100:.0f}%).\")\n",
        "\n",
        "    # Determine target size for VALID\n",
        "    if VALID_TARGET_COUNT is not None and isinstance(VALID_TARGET_COUNT, int) and VALID_TARGET_COUNT >= 0:\n",
        "        valid_target_size = VALID_TARGET_COUNT\n",
        "        print(f\"üéØ Tama√±o objetivo para VALID (fijo): {valid_target_size} im√°genes.\")\n",
        "    else:\n",
        "        # Usar el porcentaje configurable si no se ha fijado un tama√±o\n",
        "        valid_target_size = round(total_dataset_target * VALID_SET_PERCENTAGE)\n",
        "        print(f\"üéØ Tama√±o objetivo para VALID (proporcional): {valid_target_size} im√°genes ({VALID_SET_PERCENTAGE*100:.0f}% del total).\")\n",
        "\n",
        "    # Determine target size for TEST\n",
        "    if TEST_TARGET_COUNT is not None and isinstance(TEST_TARGET_COUNT, int) and TEST_TARGET_COUNT >= 0:\n",
        "        test_target_size = TEST_TARGET_COUNT\n",
        "        print(f\"üéØ Tama√±o objetivo para TEST (fijo): {test_target_size} im√°genes.\")\n",
        "    else:\n",
        "        # Usar el porcentaje configurable si no se ha fijado un tama√±o\n",
        "        test_target_size = round(total_dataset_target * TEST_SET_PERCENTAGE)\n",
        "        print(f\"üéØ Tama√±o objetivo para TEST (proporcional): {test_target_size} im√°genes ({TEST_SET_PERCENTAGE*100:.0f}% del total).\")\n",
        "\n",
        "\n",
        "    # Adjust VALID target if necessary due to rounding (only if proportional calculation was used for both)\n",
        "    # This adjustment is less critical if fixed counts are used, as we prioritize fixed counts.\n",
        "    # We still want the total to make sense if both are proportional.\n",
        "    if VALID_TARGET_COUNT is None and TEST_TARGET_COUNT is None:\n",
        "        if (final_train_size + valid_target_size + test_target_size) != total_dataset_target:\n",
        "            diff = total_dataset_target - (final_train_size + valid_target_size + test_target_size)\n",
        "            if diff != 0:\n",
        "                valid_target_size += diff # Adjust VALID to absorb rounding differences\n",
        "                print(f\"   Ajuste por redondeo: VALID target ajustado a {valid_target_size}\")\n",
        "\n",
        "\n",
        "    for split_name, target_size_config in [(\"valid\", VALID_TARGET_COUNT), (\"test\", TEST_TARGET_COUNT)]:\n",
        "        # Determine the actual target size for the current split based on config\n",
        "        target_size = target_size_config if target_size_config is not None else \\\n",
        "                      (valid_target_size if split_name == \"valid\" else test_target_size)\n",
        "\n",
        "        print(f\"\\n‚öôÔ∏è Ajustando el split {split_name.upper()} con objetivo de {target_size} im√°genes...\")\n",
        "\n",
        "        hard_neg_percentage = 0.0\n",
        "        if split_name == \"valid\":\n",
        "            hard_neg_percentage = HARD_NEG_PERCENTAGE_VALID\n",
        "        elif split_name == \"test\":\n",
        "            hard_neg_percentage = HARD_NEG_PERCENTAGE_TEST\n",
        "\n",
        "        dest_final_img = os.path.join(BASE_DATASET_DIR, split_name, \"tiles\", \"final_selection\", \"images\")\n",
        "        dest_final_lbl = os.path.join(BASE_DATASET_DIR, split_name, \"tiles\", \"final_selection\", \"labels\")\n",
        "\n",
        "        neg_rest_img_dir = os.path.join(BASE_DATASET_DIR, split_name, \"tiles\", \"negatives_rest\", \"images\")\n",
        "        neg_rest_lbl_dir = os.path.join(BASE_DATASET_DIR, split_name, \"tiles\", \"negatives_rest\", \"labels\")\n",
        "\n",
        "        # Get current positive count in final_selection (these were copied by split_negatives)\n",
        "        current_pos_count = 0\n",
        "        if os.path.exists(dest_final_img):\n",
        "            for fname in os.listdir(dest_final_img):\n",
        "                if not fname.lower().endswith(IMAGE_EXTENSIONS):\n",
        "                    continue\n",
        "\n",
        "                label_fname = os.path.splitext(fname)[0] + \".txt\"\n",
        "                label_path = os.path.join(dest_final_lbl, label_fname)\n",
        "\n",
        "                # A tile is considered \"positive\" if its label file exists and is not empty.\n",
        "                if os.path.exists(label_path) and os.path.getsize(label_path) > 0:\n",
        "                    current_pos_count += 1\n",
        "\n",
        "        print(f\"   {split_name.upper()}: Positivos actuales (ya en final_selection): {current_pos_count}\")\n",
        "\n",
        "        # Calculate how many total negatives are needed\n",
        "        total_negatives_needed = max(0, target_size - current_pos_count)\n",
        "        print(f\"   {split_name.upper()}: Negativos totales necesarios para el objetivo ({target_size} total - {current_pos_count} pos): {total_negatives_needed}\")\n",
        "\n",
        "        # Add hard negatives first\n",
        "        desired_hard_neg_count = int(total_negatives_needed * hard_neg_percentage)\n",
        "        added_hard_count = 0\n",
        "\n",
        "        if hard_neg_percentage > 0:\n",
        "            print(f\"   {split_name.upper()}: Hard negatives deseados ({hard_neg_percentage*100:.0f}% del total de negativos): {desired_hard_neg_count}\")\n",
        "            added_hard_count = select_and_copy_hard_negatives(\n",
        "                desired_hard_neg_count, dest_final_img, dest_final_lbl,\n",
        "                global_hard_images_pool, hard_negatives_used_tracker\n",
        "            )\n",
        "            print(f\"   {split_name.upper()}: Hard negatives a√±adidos: {added_hard_count}\")\n",
        "        else:\n",
        "            print(f\"   {split_name.upper()}: Porcentaje de hard negatives es 0, no se a√±adir√°n.\")\n",
        "\n",
        "        # Calculate how many normal negatives are still needed after adding hard negatives\n",
        "        current_total_count = count_files(dest_final_img)\n",
        "        normals_to_add = max(0, target_size - current_total_count)\n",
        "\n",
        "        all_rest_negatives_files = [f for f in os.listdir(neg_rest_img_dir) if f.lower().endswith(IMAGE_EXTENSIONS)] if os.path.exists(neg_rest_img_dir) else []\n",
        "\n",
        "        # Filter out negatives that have already been used by TRAIN or by the current split (hard or normal)\n",
        "        clean_rest_negatives_files = [f for f in all_rest_negatives_files if f not in hard_negatives_used_tracker]\n",
        "\n",
        "        if normals_to_add > 0:\n",
        "            if not clean_rest_negatives_files:\n",
        "                print(f\"   ‚ö†Ô∏è No hay negativos normales disponibles en '{neg_rest_img_dir}' para {split_name.upper()} para completar el objetivo.\")\n",
        "                print(f\"   {split_name.upper()}: Se pudo a√±adir {current_total_count - current_pos_count} negativos (hard+normal). Faltan {normals_to_add} para el objetivo.\")\n",
        "            else:\n",
        "                if normals_to_add > len(clean_rest_negatives_files):\n",
        "                    print(f\"   ‚ö†Ô∏è Solo hay {len(clean_rest_negatives_files)} negativos normales disponibles en 'negatives_rest' para {split_name.upper()}, pero se necesitan {normals_to_add}.\")\n",
        "                    files_to_move_normal = clean_rest_negatives_files\n",
        "                else:\n",
        "                    random.seed(SEED) # Ensure reproducibility for normal negative selection\n",
        "                    files_to_move_normal = random.sample(clean_rest_negatives_files, normals_to_add)\n",
        "\n",
        "                print(f\"   {split_name.upper()}: A√±adiendo {len(files_to_move_normal)} negativos normales adicionales de 'negatives_rest'.\")\n",
        "\n",
        "                for fname in files_to_move_normal:\n",
        "                    src_img_path = os.path.join(neg_rest_img_dir, fname)\n",
        "                    src_lbl_path = os.path.join(neg_rest_lbl_dir, os.path.splitext(fname)[0] + \".txt\")\n",
        "\n",
        "                    # Move, not copy, to ensure they are removed from 'negatives_rest'\n",
        "                    shutil.move(src_img_path, os.path.join(dest_final_img, fname))\n",
        "                    shutil.move(src_lbl_path, os.path.join(dest_final_lbl, os.path.splitext(fname)[0] + \".txt\"))\n",
        "                    hard_negatives_used_tracker.add(fname) # Track these as used too\n",
        "\n",
        "        if CLEAN_INTERMEDIATE:\n",
        "            # Check if the folder is empty before removing to prevent errors if already moved\n",
        "            if os.path.exists(neg_rest_img_dir) and not os.listdir(neg_rest_img_dir):\n",
        "                shutil.rmtree(os.path.dirname(neg_rest_img_dir)) # Removes 'negatives_rest' folder\n",
        "\n",
        "        print(f\"   ‚úÖ {split_name.upper()}: Ajuste de negativos completado. Total final para exportaci√≥n: {count_files(dest_final_img)} im√°genes.\")\n",
        "\n",
        "\n",
        "def summary():\n",
        "    \"\"\"Muestra un resumen de los tiles en las carpetas de selecci√≥n final.\"\"\"\n",
        "    print(\"\\nüìä RESUMEN FINAL DE TILES (Antes de la exportaci√≥n final)\")\n",
        "    for split in [\"train\", \"valid\", \"test\"]:\n",
        "        print(f\"\\nüìÅ {split.upper()}\")\n",
        "        base = os.path.join(BASE_DATASET_DIR, split, \"tiles\")\n",
        "        final_selection_img_dir = os.path.join(base, \"final_selection\", \"images\")\n",
        "        final_selection_lbl_dir = os.path.join(base, \"final_selection\", \"labels\")\n",
        "\n",
        "        img_count = count_files(final_selection_img_dir)\n",
        "        lbl_count = count_files(final_selection_lbl_dir)\n",
        "\n",
        "        print(f\"Total en final_selection: {img_count} im√°genes | {lbl_count} etiquetas\")\n",
        "\n",
        "        neg_rest_img_dir = os.path.join(base, \"negatives_rest\", \"images\")\n",
        "        neg_rest_lbl_dir = os.path.join(base, \"negatives_rest\", \"labels\")\n",
        "        rest_img_count = count_files(neg_rest_img_dir)\n",
        "        rest_lbl_count = count_files(neg_rest_lbl_dir)\n",
        "        if rest_img_count > 0:\n",
        "            print(f\"En negatives_rest (sobrantes): {rest_img_count} im√°genes | {rest_lbl_count} etiquetas\")\n",
        "\n",
        "\n",
        "def export_for_yolov8(base_dataset_dir, export_dir):\n",
        "    \"\"\"Copia los archivos de la selecci√≥n final a la estructura de exportaci√≥n YOLOv8.\"\"\"\n",
        "    sets = [\"train\", \"valid\", \"test\"]\n",
        "    os.makedirs(export_dir, exist_ok=True)\n",
        "\n",
        "    print(\"\\nüì¶ Iniciando export final para entrenamiento YOLOv8...\\n\")\n",
        "\n",
        "    for split in sets:\n",
        "        print(f\"üîÑ Procesando {split.upper()}...\")\n",
        "\n",
        "        split_dir = os.path.join(export_dir, split)\n",
        "        images_dir = os.path.join(split_dir, \"images\")\n",
        "        labels_dir = os.path.join(split_dir, \"labels\")\n",
        "        os.makedirs(images_dir, exist_ok=True)\n",
        "        os.makedirs(labels_dir, exist_ok=True)\n",
        "\n",
        "        src_data_img = os.path.join(base_dataset_dir, split, \"tiles\", \"final_selection\", \"images\")\n",
        "        src_data_lbl = os.path.join(base_dataset_dir, split, \"tiles\", \"final_selection\", \"labels\")\n",
        "\n",
        "        count_imgs = safe_copy(src_data_img, images_dir, IMAGE_EXTENSIONS)\n",
        "        count_lbls = safe_copy(src_data_lbl, labels_dir, (\".txt\",))\n",
        "\n",
        "        print(f\"‚úÖ {split.upper()}: {count_imgs} im√°genes, {count_lbls} labels exportados.\")\n",
        "\n",
        "    print(f\"\\nüöÄ Export final completo en: {export_dir}\")\n",
        "\n",
        "\n",
        "def summary_export():\n",
        "    \"\"\"Muestra un resumen de los archivos en el directorio de exportaci√≥n final.\"\"\"\n",
        "    print(\"\\nüì¶ EXPORT FINAL PARA YOLOv8\")\n",
        "    for split in [\"train\", \"valid\", \"test\"]:\n",
        "        exp_img = os.path.join(EXPORT_DIR, split, \"images\")\n",
        "        exp_lbl = os.path.join(EXPORT_DIR, split, \"labels\")\n",
        "        exp_img_count = count_files(exp_img)\n",
        "        exp_lbl_count = count_files(exp_lbl)\n",
        "        print(f\"{split.upper():<7}: {exp_img_count} im√°genes | {exp_lbl_count} etiquetas\")\n",
        "\n",
        "\n",
        "def move_data_yaml_to_export(source_path, dest_path):\n",
        "    \"\"\"Copia el archivo data.yaml al directorio de exportaci√≥n.\"\"\"\n",
        "    if not os.path.exists(source_path):\n",
        "        print(f\"‚ùå No se encontr√≥ el archivo de entrada: {source_path}\")\n",
        "        return\n",
        "    os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n",
        "    shutil.copy2(source_path, dest_path)\n",
        "    print(f\"‚úÖ 'data.yaml' copiado a: {dest_path}\")\n",
        "\n",
        "\n",
        "def fix_discard_summary(log_path):\n",
        "    \"\"\"Consolida y formatea el resumen de tiles descartados.\"\"\"\n",
        "    if not os.path.exists(log_path):\n",
        "        print(\"‚ö†Ô∏è No se encontr√≥ archivo de descartes.\")\n",
        "        return\n",
        "\n",
        "    resumen_por_split = {}\n",
        "    lines_to_write = []\n",
        "\n",
        "    with open(log_path, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    # Process lines to extract discarded counts per split\n",
        "    current_split = None\n",
        "    discard_count_for_current_split = 0\n",
        "    for line in lines:\n",
        "        if line.startswith(\"üîπ TILES DESCARTADOS EN\"):\n",
        "            # If we were tracking a previous split, save its count\n",
        "            if current_split is not None:\n",
        "                resumen_por_split[current_split] = resumen_por_split.get(current_split, 0) + discard_count_for_current_split\n",
        "\n",
        "            # Start tracking new split\n",
        "            split_name_start = line.find(\"EN \") + 3\n",
        "            split_name_end = line.find(\" (original:\", split_name_start)\n",
        "            current_split = line[split_name_start:split_name_end].strip()\n",
        "            discard_count_for_current_split = 0 # Reset count for the new split\n",
        "            lines_to_write.append(line) # Keep original line for context\n",
        "        elif line.strip() == \"-\" * 50:\n",
        "            lines_to_write.append(line) # Keep separator line\n",
        "        elif current_split is not None and line.strip() and not line.startswith((\"üîπ \", \"üì¶ \", \"üî∏ \", \"üßÆ \")):\n",
        "            discard_count_for_current_split += 1\n",
        "            lines_to_write.append(line) # Keep discarded tile entry\n",
        "        else:\n",
        "            # Lines not related to discarded tiles, or already processed summary lines\n",
        "            if not (line.startswith(\"üì¶ RESUMEN GLOBAL\") or\n",
        "                    line.startswith(\"üî∏ \") or\n",
        "                    line.startswith(\"üßÆ \")):\n",
        "                lines_to_write.append(line) # Keep other relevant lines\n",
        "\n",
        "    # Add the last split's count if loop finishes\n",
        "    if current_split is not None:\n",
        "        resumen_por_split[current_split] = resumen_por_split.get(current_split, 0) + discard_count_for_current_split\n",
        "\n",
        "    # Append the consolidated summary to the lines\n",
        "    lines_to_write.append(\"\\nüì¶ RESUMEN GLOBAL DE TILES DESCARTADOS\\n\")\n",
        "    lines_to_write.append(\"=\".ljust(50, \"=\") + \"\\n\")\n",
        "\n",
        "    total_global = 0\n",
        "    for split, count in resumen_por_split.items():\n",
        "        lines_to_write.append(f\"üî∏ {split}: {count} tiles descartados\\n\")\n",
        "        total_global += count\n",
        "    lines_to_write.append(f\"\\nüßÆ TOTAL GLOBAL DE TILES DESCARTADOS: {total_global}\\n\")\n",
        "\n",
        "    with open(log_path, \"w\") as f:\n",
        "        f.writelines(lines_to_write)\n",
        "    print(f\"‚úÖ Resumen de tiles descartados actualizado en: {log_path}\")\n",
        "\n",
        "def contar_imagenes_y_proporciones(export_dir):\n",
        "    \"\"\"Calcula y muestra la proporci√≥n final de im√°genes en cada conjunto exportado.\"\"\"\n",
        "    sets = [\"train\", \"valid\", \"test\"]\n",
        "    conteo = {}\n",
        "    total = 0\n",
        "\n",
        "    print(\"\\nüìä PROPORCI√ìN FINAL DE IM√ÅGENES POR CONJUNTO:\")\n",
        "    for split in sets:\n",
        "        images_dir = os.path.join(export_dir, split, \"images\")\n",
        "        if not os.path.exists(images_dir):\n",
        "            print(f\"‚ö†Ô∏è No existe la carpeta: {images_dir}\")\n",
        "            conteo[split] = 0\n",
        "            continue\n",
        "        n = len([f for f in os.listdir(images_dir) if f.lower().endswith(IMAGE_EXTENSIONS)])\n",
        "        conteo[split] = n\n",
        "        total += n\n",
        "\n",
        "    for split in sets:\n",
        "        porcentaje = (conteo[split] / total * 100) if total > 0 else 0\n",
        "        print(f\"{split.upper():<6}: {conteo[split]} im√°genes ({porcentaje:.2f}%)\")\n",
        "    print(f\"TOTAL: {total} im√°genes\")\n",
        "\n",
        "\n",
        "# --- MAIN PIPELINE: ejecuta todo en orden ---\n",
        "def run_full_pipeline():\n",
        "    # --- Limpiar directorio de exportaci√≥n si existe ---\n",
        "    if os.path.exists(EXPORT_DIR):\n",
        "        print(f\"\\nüóëÔ∏è Limpiando directorio de exportaci√≥n existente: {EXPORT_DIR}\")\n",
        "        shutil.rmtree(EXPORT_DIR)\n",
        "    os.makedirs(EXPORT_DIR, exist_ok=True)\n",
        "    # --- Fin de limpieza ---\n",
        "\n",
        "    # Paso 1: Convertir labels de pol√≠gono a BBoxes y Tiling inicial\n",
        "    for split in [\"train\", \"valid\", \"test\"]:\n",
        "        process_all_labels_for_set(split)\n",
        "        process_tiling_for_set(split)\n",
        "\n",
        "    # Paso 2: Procesar los hard negatives (si la carpeta existe)\n",
        "    process_forced_negatives_tiling()\n",
        "    global_hard_tiles_img_dir = os.path.join(BASE_DATASET_DIR, FORCED_NEGATIVES_SUBFOLDER, \"tiles\", \"images\")\n",
        "    global_hard_images_pool = [f for f in os.listdir(global_hard_tiles_img_dir) if f.lower().endswith(IMAGE_EXTENSIONS)] if os.path.exists(global_hard_tiles_img_dir) else []\n",
        "    # This set will track ALL hard/normal negatives that have been copied to 'final_selection' across ALL splits\n",
        "    hard_negatives_used_tracker = set()\n",
        "    check_forced_tiles()\n",
        "\n",
        "    # Paso 3: Aumentaci√≥n de datos para los positivos de TRAIN\n",
        "    if APPLY_AUGMENTATION:\n",
        "        augment_positives()\n",
        "\n",
        "    # Paso 4: Selecci√≥n de negativos para cada split (y copia de positivos a final_selection para todos los splits)\n",
        "    # NOTA CLAVE: La funci√≥n `split_negatives` ahora copia los positivos a `final_selection`\n",
        "    # Esto asegura que el recuento para TRAIN sea preciso.\n",
        "    for split in [\"train\", \"valid\", \"test\"]:\n",
        "        split_negatives(split, global_hard_images_pool, hard_negatives_used_tracker)\n",
        "\n",
        "    # Paso 5: Rebalanceo final para VALID y TEST\n",
        "    rebalance_validation_test_splits(global_hard_images_pool, hard_negatives_used_tracker)\n",
        "\n",
        "    # Paso 6: Resumen de los datos preparados antes de exportar\n",
        "    summary()\n",
        "\n",
        "    # Paso 7: Exportar los datos desde las carpetas 'final_selection'\n",
        "    export_for_yolov8(BASE_DATASET_DIR, EXPORT_DIR)\n",
        "\n",
        "    # Paso 8: Mover el archivo data.yaml\n",
        "    move_data_yaml_to_export(INPUT_YAML_PATH, EXPORT_YAML_PATH)\n",
        "\n",
        "    # Paso 9: Consolidar y limpiar el log de descartes\n",
        "    fix_discard_summary(os.path.join(EXPORT_DIR, \"errors\", \"tiles_descartados.txt\"))\n",
        "\n",
        "    # Paso 10: Contar y mostrar proporciones finales\n",
        "    contar_imagenes_y_proporciones(EXPORT_DIR)\n",
        "\n",
        "\n",
        "# --- Ejecutar el Pipeline Completo ---\n",
        "if __name__ == \"__main__\":\n",
        "    run_full_pipeline()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5g64kya6Y03"
      },
      "source": [
        "# **4. Install and import Ultralytics library for training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDS7eDgfxSzR",
        "outputId": "c90e995e-bd9c-499c-d631-42e059ee406a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "Setup complete ‚úÖ (12 CPUs, 83.5 GB RAM, 62.1/235.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "#0. En Colab, primero instala los paquetes y monta tu Drive:  Instalar las librer√≠as necesarias\n",
        "!pip install ultralytics wandb  # Esto instalar√° ultralytics y wandb (torch y torchvision generalmente ya vienen instalados en Colab)\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "300CcRnS6eLc"
      },
      "source": [
        "# 4.1 Install chosen YOLO version model and size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QIb53oSQxWka"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 9. Ejecutar el entrenamiento de YOLOv8\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Carga el modelo (en este ejemplo, YOLOv8s)\n",
        "model = YOLO(\"yolov8s.pt\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B3RLj7B6nsf"
      },
      "source": [
        "# 4.2 Train the chosen model and chose hyperparameter for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Omdda2F1Uy62",
        "outputId": "0e5da13e-6840-4b10-859b-9292477a9ac7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/content/export_yolov8/data.yaml, degrees=10, deterministic=True, device=0, dfl=1.75, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=120, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.3, format=torchscript, fraction=1.0, freeze=None, half=True, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1, multi_scale=False, name=seals2, nbs=64, nms=False, opset=None, optimize=False, optimizer=adamw, overlap_mask=True, patience=13, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=ProSeal, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=ProSeal/seals2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=4, warmup_momentum=0.8, weight_decay=0.002, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
            "Model summary: 129 layers, 11,135,987 parameters, 11,135,971 gradients, 28.6 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1015.8¬±496.4 MB/s, size: 36.0 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/export_yolov8/train/labels... 46701 images, 41546 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46701/46701 [00:21<00:00, 2220.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/export_yolov8/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 783.8¬±321.6 MB/s, size: 30.1 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/export_yolov8/valid/labels... 10008 images, 9838 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10008/10008 [00:04<00:00, 2216.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/export_yolov8/valid/labels.cache\n",
            "Plotting labels to ProSeal/seals2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.002), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mProSeal/seals2\u001b[0m\n",
            "Starting training for 120 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      1/120      6.68G      1.936      11.12      1.355          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:37<00:00,  6.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:16<00:00,  9.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.715       0.65      0.674      0.242\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      2/120      8.22G      1.727      1.145      1.249          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:36<00:00,  6.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:16<00:00,  9.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.778      0.703      0.676      0.246\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      3/120      8.27G      1.647     0.9526      1.235          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:22<00:00,  7.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.902      0.768      0.829      0.356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      4/120      8.31G      1.631     0.9446      1.218          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00,  9.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.897      0.816      0.841      0.371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      5/120      8.34G      1.593     0.9104      1.198          0        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:22<00:00,  7.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.859      0.805      0.827      0.394\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      6/120      8.38G      1.553     0.8701      1.183          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:22<00:00,  7.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.886      0.758      0.817      0.377\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      7/120      8.42G      1.557     0.8572      1.195          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.916      0.832       0.88      0.424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      8/120      8.45G      1.528     0.8321      1.167          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00,  9.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185       0.88       0.83      0.868      0.398\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      9/120      8.49G      1.488     0.8101      1.149          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.878      0.818      0.845      0.396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     10/120      8.52G      1.472     0.7818      1.151          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.902      0.797       0.87      0.395\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     11/120      8.56G      1.457     0.7786      1.141          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.906      0.805      0.847      0.427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     12/120       8.6G      1.461     0.7683      1.138          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.872      0.827       0.86      0.434\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     13/120      8.63G      1.461     0.7639      1.145          0        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.918      0.805      0.855      0.442\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     14/120      8.67G      1.429     0.7501      1.134          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.924      0.843      0.885      0.438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     15/120      8.71G      1.414     0.7438      1.118          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:22<00:00,  7.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.902      0.847      0.871      0.432\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     16/120      8.74G        1.4     0.7341      1.117          0        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.883      0.857      0.876      0.425\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     17/120      8.78G      1.392      0.715      1.118          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.911      0.827      0.873      0.435\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     18/120      8.81G      1.372      0.716      1.107          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185       0.92      0.827      0.875      0.439\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     19/120      8.85G      1.363     0.6994      1.114          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.915      0.819      0.858      0.448\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     20/120      8.89G      1.347      0.678      1.099          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.903      0.827      0.859       0.45\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     21/120      8.92G      1.364     0.6883      1.109          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.936      0.822      0.874      0.457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     22/120      8.96G       1.33     0.6802      1.096          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185       0.93      0.827      0.864      0.465\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     23/120         9G      1.327     0.6607      1.101          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.938      0.824      0.875       0.47\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     24/120      9.03G      1.321     0.6591       1.09          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.938      0.822      0.872      0.467\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     25/120      9.07G      1.319     0.6637      1.093          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.934      0.827      0.881      0.469\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     26/120       9.1G      1.301     0.6554      1.085          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.925      0.822      0.874      0.475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     27/120      9.14G      1.291     0.6492      1.087          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.898      0.849      0.875      0.472\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     28/120      9.18G      1.285     0.6295      1.079          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.933      0.822      0.874      0.471\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     29/120      9.21G       1.27     0.6256      1.076          0        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.932      0.822      0.873      0.474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     30/120      9.25G      1.278     0.6313      1.088          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.936      0.822      0.872      0.475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     31/120      9.28G      1.265      0.616      1.081          0        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.945      0.834      0.887       0.48\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     32/120      9.32G      1.244     0.6112       1.07          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.944      0.838      0.887      0.483\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     33/120      9.36G      1.247     0.6093      1.077          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185       0.94      0.838      0.888      0.484\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     34/120      9.39G      1.223     0.5936      1.062          0        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.939      0.838      0.888      0.484\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     35/120      9.43G      1.229     0.5951      1.068          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.933      0.832      0.878      0.482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     36/120      9.46G      1.235     0.5997       1.07          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.935      0.832      0.878      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     37/120       9.5G       1.21     0.5826      1.053          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.936      0.832       0.88       0.48\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     38/120      9.54G      1.208     0.5888      1.063          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.908      0.852      0.882      0.486\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     39/120      9.57G      1.193     0.5695      1.058          0        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.908      0.855      0.886      0.483\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     40/120      9.61G      1.202     0.5827      1.055          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.918      0.859      0.891      0.484\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     41/120      9.65G      1.186     0.5701      1.054          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.924      0.859      0.892      0.485\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     42/120      9.68G      1.182     0.5702      1.057          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185       0.93      0.865      0.902      0.488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     43/120      9.72G      1.185     0.5618      1.055          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.932      0.865      0.904      0.486\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     44/120      9.75G      1.162     0.5719       1.04          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.921      0.882      0.912      0.488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     45/120      9.79G      1.156     0.5512      1.049          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.926      0.881      0.911      0.489\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     46/120      9.82G      1.146     0.5473      1.042          0        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.918      0.876      0.905      0.491\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     47/120      9.87G      1.149     0.5523      1.043          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.921      0.876      0.906      0.492\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     48/120       9.9G      1.147     0.5521      1.045          0        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.926      0.876      0.908      0.492\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     49/120      9.94G      1.123     0.5303      1.033          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.925      0.872      0.909      0.489\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     50/120      9.97G      1.126     0.5392      1.038          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.925      0.873      0.911      0.494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     51/120        10G      1.121     0.5272      1.037          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.924       0.87      0.905      0.494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     52/120        10G      1.105     0.5293      1.034          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.924       0.87      0.905      0.491\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     53/120      10.1G      1.111     0.5257      1.029          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.924       0.87      0.905      0.492\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     54/120      10.1G        1.1     0.5218      1.036          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.924       0.87      0.905       0.49\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     55/120      10.2G      1.113     0.5245       1.04          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.924       0.87      0.905      0.493\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     56/120      10.2G      1.096     0.5203      1.028          0        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.924       0.87      0.903      0.491\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     57/120      10.2G      1.066      0.509      1.026          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.925      0.864      0.902      0.491\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     58/120      10.3G      1.061     0.5088      1.023          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185       0.93      0.859      0.902      0.491\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     59/120      10.3G      1.078     0.5126      1.026          0        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.924      0.854      0.897       0.49\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     60/120      10.3G      1.069     0.4929      1.025          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:24<00:00,  7.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.924      0.854      0.896      0.485\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     61/120      10.4G       1.05     0.4881      1.017          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.923      0.854      0.897      0.488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     62/120      10.4G      1.049      0.494      1.016          0        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.923      0.854      0.897      0.488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     63/120      10.4G      1.049     0.4921      1.017          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [03:23<00:00,  7.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:15<00:00, 10.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.923      0.854      0.896      0.485\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 13 epochs. Best results observed at epoch 50, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=13) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "63 epochs completed in 3.846 hours.\n",
            "Optimizer stripped from ProSeal/seals2/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from ProSeal/seals2/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating ProSeal/seals2/weights/best.pt...\n",
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "Model summary (fused): 72 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 10.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.925      0.873      0.908      0.494\n",
            "Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mProSeal/seals2\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([0])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7979ee37d550>\n",
              "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
              "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.98387,     0.98387,     0.98387,\n",
              "            0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,\n",
              "            0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,\n",
              "            0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,\n",
              "            0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,\n",
              "            0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,\n",
              "            0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,\n",
              "            0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,\n",
              "            0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,     0.97468,\n",
              "            0.97468,     0.97468,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,\n",
              "            0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,\n",
              "            0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,\n",
              "            0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,\n",
              "            0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,\n",
              "            0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,\n",
              "            0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,\n",
              "            0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,\n",
              "            0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96552,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,\n",
              "            0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,\n",
              "            0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,\n",
              "            0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,\n",
              "            0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,\n",
              "            0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,\n",
              "            0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,\n",
              "            0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,\n",
              "            0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,\n",
              "            0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.96178,     0.95625,     0.95625,     0.95625,     0.95625,     0.95625,     0.95625,     0.95625,     0.95625,     0.95625,     0.95625,     0.95625,     0.93902,\n",
              "            0.93902,     0.93902,     0.93902,     0.93902,     0.93491,     0.93491,     0.93491,     0.93491,     0.93491,     0.93491,     0.93491,     0.93491,     0.93491,     0.93491,     0.93491,     0.93491,     0.93491,     0.93491,     0.93491,     0.93491,     0.93491,     0.93491,     0.93491,\n",
              "            0.93491,     0.93491,     0.93491,     0.92982,     0.92982,     0.92982,     0.92982,     0.92982,     0.92571,     0.92571,     0.92571,     0.92571,     0.92571,     0.92571,     0.92571,     0.92571,     0.92571,     0.92571,     0.92571,     0.92571,     0.92571,     0.92571,     0.92571,\n",
              "            0.92571,     0.90556,     0.90556,     0.90556,     0.90556,     0.90556,     0.90556,     0.86842,     0.86842,     0.86842,     0.86842,     0.86842,     0.86842,     0.86842,     0.86842,     0.86842,     0.86842,      0.8601,      0.8601,      0.8601,      0.8601,      0.8601,      0.8601,\n",
              "            0.85204,     0.85204,     0.85204,     0.85204,     0.85204,     0.81951,     0.81951,     0.81951,     0.81951,     0.81951,     0.81951,     0.76126,     0.76126,     0.76126,     0.76126,     0.76126,      0.7489,      0.7489,      0.7489,      0.7489,      0.7489,      0.7489,     0.60638,\n",
              "            0.60638,     0.60638,     0.60638,     0.60638,     0.55484,     0.55484,     0.55484,     0.55484,     0.55484,     0.44588,     0.44588,     0.44588,     0.44588,     0.44588,     0.44588,     0.33569,     0.33044,      0.3252,     0.31995,     0.31471,     0.30946,     0.30422,     0.29897,\n",
              "            0.29373,     0.28848,     0.28324,     0.27799,     0.27274,      0.2675,     0.26225,     0.25701,     0.25176,     0.24652,     0.24127,     0.23603,     0.23078,     0.22554,     0.22029,     0.21505,      0.2098,     0.20456,     0.19931,     0.19407,     0.18882,     0.18358,     0.17833,\n",
              "            0.17309,     0.16784,      0.1626,     0.15735,     0.15211,     0.14686,     0.14162,     0.13637,     0.13113,     0.12588,     0.12064,     0.11539,     0.11015,      0.1049,    0.099657,    0.094412,    0.089167,    0.083922,    0.078676,    0.073431,    0.068186,    0.062941,    0.057696,\n",
              "           0.052451,    0.047206,    0.041961,    0.036716,    0.031471,    0.026225,     0.02098,    0.015735,     0.01049,   0.0052451,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.49856,     0.49856,     0.59345,     0.64168,     0.67402,     0.69337,      0.7141,      0.7363,     0.74695,     0.76864,     0.78173,     0.78501,     0.79187,     0.79901,     0.80995,      0.8171,      0.8246,     0.82247,     0.82764,     0.82976,     0.82759,     0.83092,     0.83479,\n",
              "            0.83926,     0.84287,     0.84414,     0.84627,     0.84758,     0.84874,     0.84961,     0.85047,     0.85297,     0.85394,     0.85492,     0.85675,     0.85757,     0.85811,     0.85864,     0.85918,     0.86053,     0.85897,     0.86315,     0.86494,     0.86603,     0.86695,     0.86798,\n",
              "            0.86919,      0.8721,     0.87239,     0.87268,     0.87297,     0.87326,     0.87355,     0.87384,     0.87413,     0.87436,     0.87442,     0.87449,     0.87455,     0.87461,     0.87468,     0.87474,      0.8748,     0.87486,     0.87493,     0.87499,     0.87505,     0.87512,     0.87518,\n",
              "            0.87524,      0.8753,     0.87537,     0.87543,     0.87549,     0.87556,     0.87562,     0.87568,     0.87574,     0.87581,     0.87587,     0.87593,       0.876,     0.87606,     0.87612,     0.87618,     0.87625,     0.87631,     0.87637,     0.87643,      0.8765,     0.87656,     0.87662,\n",
              "            0.87583,      0.8747,     0.87374,     0.87425,     0.87477,     0.87529,     0.87581,     0.87687,     0.87823,       0.878,     0.87768,     0.87735,     0.87703,      0.8767,     0.87638,     0.87605,     0.87572,      0.8754,     0.87555,     0.87582,     0.87608,     0.87635,     0.87662,\n",
              "            0.87689,     0.87716,     0.87743,     0.87774,      0.8783,     0.87887,     0.87943,     0.87999,     0.87984,     0.87969,     0.87953,     0.87937,     0.87922,     0.87906,      0.8789,     0.87875,     0.87859,     0.87843,     0.87828,     0.87812,     0.87796,     0.87781,     0.87765,\n",
              "            0.87749,     0.87733,     0.87718,     0.87702,     0.87514,     0.87453,     0.87573,      0.8765,     0.87683,     0.87715,     0.87747,      0.8778,     0.87812,     0.87844,     0.87873,     0.87886,     0.87899,     0.87913,     0.87926,     0.87939,     0.87953,     0.87966,     0.87979,\n",
              "            0.87992,     0.88006,     0.88019,     0.88032,     0.88045,     0.88059,     0.88072,     0.88085,     0.88098,     0.88111,     0.88121,     0.88131,     0.88142,     0.88152,     0.88162,     0.88173,     0.88183,     0.88193,     0.88204,     0.88214,     0.88224,     0.88234,     0.88245,\n",
              "            0.88255,     0.88265,     0.88276,     0.88286,     0.88296,     0.88307,     0.88317,     0.88327,     0.88337,      0.8835,     0.88389,     0.88427,     0.88466,     0.88504,     0.88543,     0.88582,      0.8884,     0.88889,     0.88938,     0.88986,     0.89035,     0.89075,     0.89089,\n",
              "            0.89103,     0.89118,     0.89132,     0.89146,     0.89161,     0.89175,     0.89189,     0.89203,     0.89218,     0.89232,     0.89246,     0.89261,     0.89275,     0.89289,     0.89303,     0.89311,     0.89285,     0.89259,     0.89233,     0.89207,     0.89181,     0.89155,     0.89129,\n",
              "            0.89103,     0.89077,     0.89051,     0.89025,     0.89039,     0.89098,     0.89157,     0.89216,      0.8926,     0.89271,     0.89282,     0.89293,     0.89304,     0.89315,     0.89325,     0.89336,     0.89347,     0.89358,     0.89369,      0.8938,     0.89391,     0.89402,     0.89413,\n",
              "            0.89424,     0.89435,     0.89446,     0.89457,     0.89467,     0.89478,     0.89489,       0.895,     0.89753,     0.89832,     0.89911,     0.89989,     0.89997,     0.89994,      0.8999,     0.89987,     0.89983,      0.8998,     0.89976,     0.89973,     0.89969,     0.89966,     0.89962,\n",
              "            0.89959,     0.89955,     0.89952,     0.89948,     0.89945,     0.89941,     0.89938,     0.89934,     0.89931,     0.89927,     0.89924,      0.8992,     0.89917,     0.89913,      0.8991,     0.89906,     0.89903,     0.89899,     0.89896,     0.89892,     0.89889,     0.89886,     0.89882,\n",
              "            0.89879,     0.89875,     0.89872,     0.89868,     0.89865,     0.89861,     0.89858,     0.89854,     0.89851,     0.89847,     0.89844,      0.8984,     0.89837,     0.89833,      0.8983,     0.89826,     0.89823,     0.89819,     0.89816,     0.89812,     0.89809,     0.89805,     0.89802,\n",
              "            0.89798,     0.89795,     0.89791,     0.89788,     0.89784,     0.89781,     0.89777,     0.89774,      0.8977,     0.89767,     0.89763,      0.8976,     0.89756,     0.89753,     0.89749,     0.89746,     0.89742,     0.89739,     0.89735,     0.89732,     0.89728,     0.89725,     0.89721,\n",
              "            0.89718,     0.89714,     0.89711,     0.89707,     0.89704,       0.897,     0.89697,     0.89693,     0.89685,     0.89677,     0.89668,      0.8966,     0.89652,     0.89644,     0.89635,     0.89627,     0.89619,     0.89611,     0.89602,     0.89594,     0.89586,     0.89578,     0.89569,\n",
              "            0.89561,     0.89553,     0.89545,     0.89536,     0.89528,      0.8952,     0.89512,     0.89503,     0.89495,     0.89487,     0.89479,      0.8947,     0.89462,     0.89454,     0.89446,     0.89437,     0.89429,     0.89421,     0.89412,     0.89404,     0.89396,     0.89388,     0.89354,\n",
              "            0.89312,      0.8927,     0.89227,     0.89185,     0.89142,       0.891,     0.89079,     0.89087,     0.89096,     0.89104,     0.89112,     0.89121,     0.89129,     0.89137,     0.89145,     0.89154,     0.89162,      0.8917,     0.89179,     0.89187,     0.89195,     0.89203,     0.89212,\n",
              "             0.8922,     0.89228,     0.89237,     0.89245,     0.89253,     0.89261,      0.8927,     0.89278,     0.89286,     0.89294,     0.89303,     0.89311,     0.89319,     0.89268,     0.89015,     0.89021,     0.89027,     0.89033,     0.89039,     0.89044,      0.8905,     0.89056,     0.89062,\n",
              "            0.89068,     0.89073,     0.89079,     0.89085,     0.89091,     0.89097,     0.89102,     0.89108,     0.89114,      0.8912,     0.89126,     0.89131,     0.89137,     0.89143,     0.89149,     0.89154,      0.8916,     0.89166,     0.89172,     0.89178,     0.89183,     0.89189,     0.89195,\n",
              "            0.89201,     0.89207,     0.89212,     0.89218,     0.89224,      0.8923,     0.89235,     0.89241,     0.89247,     0.89253,     0.89259,     0.89264,      0.8924,     0.89208,     0.89176,     0.89144,     0.89112,     0.89079,     0.89047,     0.89015,     0.88983,     0.88952,     0.88947,\n",
              "            0.88943,     0.88938,     0.88934,     0.88929,     0.88924,      0.8892,     0.88915,     0.88911,     0.88906,     0.88902,     0.88897,     0.88893,     0.88888,     0.88883,     0.88879,     0.88874,      0.8887,     0.88865,     0.88861,     0.88856,     0.88852,     0.88847,     0.88843,\n",
              "            0.88838,     0.88833,     0.88829,     0.88824,      0.8882,     0.88815,     0.88811,     0.88806,     0.88802,     0.88797,     0.88792,     0.88788,     0.88783,     0.88779,     0.88774,      0.8877,     0.88765,     0.88761,     0.88756,     0.88751,     0.88747,     0.88742,     0.88738,\n",
              "            0.88733,     0.88729,     0.88724,      0.8872,     0.88715,      0.8871,     0.88706,     0.88701,     0.88697,     0.88692,     0.88688,     0.88683,     0.88678,     0.88674,     0.88669,     0.88665,      0.8866,     0.88656,     0.88651,     0.88647,     0.88642,     0.88637,     0.88386,\n",
              "            0.88313,     0.88305,     0.88297,     0.88289,     0.88281,     0.88273,     0.88265,     0.88257,     0.88249,     0.88241,     0.88233,     0.88225,     0.88217,     0.88209,     0.88201,     0.88193,     0.88185,     0.88177,     0.88169,     0.88161,     0.88153,     0.88145,     0.88137,\n",
              "            0.88129,     0.88121,     0.88114,     0.88106,     0.88098,      0.8809,     0.88082,     0.88074,     0.88066,     0.88058,      0.8805,     0.88042,     0.88034,     0.88026,     0.88018,      0.8801,     0.88002,     0.88037,     0.88085,     0.88132,     0.88179,     0.88225,     0.88245,\n",
              "            0.88228,     0.88211,     0.88194,     0.88178,     0.88161,     0.88144,     0.88127,      0.8811,     0.88093,     0.88076,     0.88059,     0.88043,     0.88026,     0.88009,     0.87992,     0.87975,     0.87958,     0.87941,     0.87973,     0.88077,     0.88181,     0.88311,     0.88439,\n",
              "            0.88445,     0.88451,     0.88457,     0.88462,     0.88468,     0.88474,     0.88479,     0.88485,     0.88491,     0.88497,     0.88502,     0.88508,     0.88514,      0.8852,     0.88525,     0.88531,     0.88537,     0.88542,     0.88548,     0.88554,      0.8856,     0.88565,     0.88571,\n",
              "            0.88577,     0.88582,     0.88588,     0.88594,       0.886,     0.88605,     0.88611,     0.88617,     0.88622,     0.88628,     0.88634,     0.88639,     0.88645,     0.88651,     0.88657,     0.88662,     0.88668,     0.88674,     0.88679,     0.88685,     0.88691,     0.88689,     0.88642,\n",
              "            0.88595,     0.88547,       0.885,     0.88452,     0.88405,     0.88304,     0.88081,     0.88087,     0.88135,     0.88183,     0.88231,     0.88279,     0.87958,     0.87918,     0.87878,     0.87838,     0.87799,     0.87759,     0.87719,     0.87679,     0.87629,     0.87532,     0.87435,\n",
              "            0.87338,      0.8724,     0.87143,     0.87045,     0.86947,     0.86849,     0.86751,     0.86652,     0.86538,     0.86423,     0.86308,     0.86239,     0.86169,       0.861,      0.8603,     0.85604,     0.85428,     0.84895,     0.84658,     0.84068,     0.83509,     0.83405,     0.83301,\n",
              "            0.83196,     0.83118,     0.83045,     0.82972,     0.82898,     0.82824,     0.82703,      0.8258,     0.82465,     0.82539,     0.82614,     0.82688,     0.82561,     0.81579,     0.81326,     0.81072,     0.80817,     0.80561,     0.80443,     0.80366,     0.80289,     0.80212,     0.80134,\n",
              "            0.79513,     0.79252,     0.78989,     0.78466,     0.78333,     0.78199,     0.78066,     0.77932,     0.77007,     0.76871,     0.76734,     0.76598,      0.7646,     0.76323,     0.74926,     0.74644,     0.74307,     0.73482,     0.73192,       0.729,     0.71306,     0.71006,     0.70705,\n",
              "            0.69055,     0.67363,     0.67044,     0.66252,     0.65435,     0.62506,     0.62163,     0.61312,     0.60963,     0.60613,      0.5959,     0.59607,     0.59248,     0.58234,     0.55963,       0.549,     0.54515,       0.524,     0.51413,     0.51008,     0.48167,     0.46484,      0.4605,\n",
              "            0.45613,     0.45174,     0.41958,     0.38661,     0.37474,     0.36988,     0.36486,     0.35923,     0.34689,     0.34182,     0.31956,     0.29836,      0.2609,     0.25529,     0.23877,     0.21575,     0.19097,     0.16719,     0.16486,     0.16253,     0.16019,     0.15374,     0.13683,\n",
              "            0.11085,    0.091668,    0.084918,    0.070021,    0.065884,    0.051523,    0.047307,    0.043072,    0.039823,    0.036777,    0.033722,    0.027504,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.33988,     0.33988,     0.43464,      0.4899,     0.52862,     0.55283,     0.58178,     0.61423,     0.62921,      0.6606,     0.68018,     0.68516,     0.69568,     0.70679,     0.72408,     0.73559,     0.74784,     0.74782,     0.75652,       0.761,     0.76019,     0.76582,     0.77243,\n",
              "            0.78011,     0.78638,      0.7886,     0.79232,     0.79461,     0.79665,     0.79818,     0.79972,     0.80414,     0.80587,     0.80761,      0.8109,     0.81236,     0.81332,     0.81429,     0.81525,     0.81768,     0.81927,     0.82692,     0.83021,     0.83222,     0.83392,     0.83583,\n",
              "            0.83808,     0.84351,     0.84405,      0.8446,     0.84514,     0.84568,     0.84622,     0.84676,     0.84731,     0.84774,     0.84786,     0.84798,      0.8481,     0.84822,     0.84834,     0.84846,     0.84857,     0.84869,     0.84881,     0.84893,     0.84905,     0.84917,     0.84928,\n",
              "             0.8494,     0.84952,     0.84964,     0.84976,     0.84988,     0.84999,     0.85011,     0.85023,     0.85035,     0.85047,     0.85059,     0.85071,     0.85082,     0.85094,     0.85106,     0.85118,      0.8513,     0.85142,     0.85153,     0.85165,     0.85177,     0.85189,     0.85201,\n",
              "            0.85183,     0.85154,     0.85138,     0.85237,     0.85335,     0.85434,     0.85532,     0.85735,     0.85995,     0.86003,     0.85995,     0.85987,     0.85979,     0.85971,     0.85963,     0.85955,     0.85947,     0.85939,     0.85979,     0.86031,     0.86083,     0.86135,     0.86187,\n",
              "            0.86239,     0.86291,     0.86343,     0.86402,     0.86512,     0.86622,     0.86731,     0.86841,     0.86838,     0.86835,     0.86831,     0.86828,     0.86824,      0.8682,     0.86817,     0.86813,     0.86809,     0.86806,     0.86802,     0.86798,     0.86795,     0.86791,     0.86787,\n",
              "            0.86784,      0.8678,     0.86776,     0.86773,     0.86729,     0.86807,     0.87045,     0.87197,     0.87261,     0.87325,     0.87389,     0.87453,     0.87517,     0.87582,     0.87639,     0.87665,     0.87692,     0.87718,     0.87745,     0.87771,     0.87798,     0.87824,      0.8785,\n",
              "            0.87877,     0.87903,      0.8793,     0.87956,     0.87983,     0.88009,     0.88035,     0.88062,     0.88088,     0.88113,     0.88134,     0.88155,     0.88175,     0.88196,     0.88217,     0.88237,     0.88258,     0.88279,     0.88299,      0.8832,     0.88341,     0.88361,     0.88382,\n",
              "            0.88403,     0.88423,     0.88444,     0.88465,     0.88485,     0.88506,     0.88527,     0.88547,     0.88568,     0.88593,     0.88671,     0.88749,     0.88827,     0.88904,     0.88982,      0.8906,     0.89585,     0.89684,     0.89783,     0.89882,     0.89981,     0.90063,     0.90092,\n",
              "            0.90121,      0.9015,      0.9018,     0.90209,     0.90238,     0.90268,     0.90297,     0.90326,     0.90356,     0.90385,     0.90414,     0.90443,     0.90473,     0.90502,     0.90531,     0.90555,      0.9055,     0.90546,     0.90541,     0.90537,     0.90532,     0.90528,     0.90523,\n",
              "            0.90519,     0.90514,      0.9051,     0.90505,      0.9056,     0.90683,     0.90806,     0.90928,     0.91019,     0.91041,     0.91064,     0.91087,      0.9111,     0.91133,     0.91155,     0.91178,     0.91201,     0.91224,     0.91247,     0.91269,     0.91292,     0.91315,     0.91338,\n",
              "             0.9136,     0.91383,     0.91406,     0.91429,     0.91452,     0.91474,     0.91497,      0.9152,     0.92051,     0.92216,     0.92382,     0.92548,     0.92571,     0.92571,      0.9257,      0.9257,     0.92569,     0.92569,     0.92568,     0.92568,     0.92567,     0.92567,     0.92566,\n",
              "            0.92566,     0.92565,     0.92565,     0.92564,     0.92564,     0.92563,     0.92563,     0.92562,     0.92562,     0.92561,     0.92561,      0.9256,      0.9256,     0.92559,     0.92559,     0.92558,     0.92558,     0.92557,     0.92557,     0.92556,     0.92556,     0.92555,     0.92555,\n",
              "            0.92554,     0.92554,     0.92554,     0.92553,     0.92553,     0.92552,     0.92552,     0.92551,     0.92551,      0.9255,      0.9255,     0.92549,     0.92549,     0.92548,     0.92548,     0.92547,     0.92547,     0.92546,     0.92546,     0.92545,     0.92545,     0.92544,     0.92544,\n",
              "            0.92543,     0.92543,     0.92542,     0.92542,     0.92541,     0.92541,      0.9254,      0.9254,     0.92539,     0.92539,     0.92538,     0.92538,     0.92537,     0.92537,     0.92536,     0.92536,     0.92536,     0.92535,     0.92535,     0.92534,     0.92534,     0.92533,     0.92533,\n",
              "            0.92532,     0.92532,     0.92531,     0.92531,      0.9253,      0.9253,     0.92529,     0.92529,     0.92528,     0.92526,     0.92525,     0.92524,     0.92523,     0.92522,     0.92521,     0.92519,     0.92518,     0.92517,     0.92516,     0.92515,     0.92514,     0.92512,     0.92511,\n",
              "             0.9251,     0.92509,     0.92508,     0.92507,     0.92506,     0.92504,     0.92503,     0.92502,     0.92501,       0.925,     0.92499,     0.92497,     0.92496,     0.92495,     0.92494,     0.92493,     0.92492,      0.9249,     0.92489,     0.92488,     0.92487,     0.92486,     0.92481,\n",
              "            0.92475,     0.92469,     0.92463,     0.92457,     0.92451,     0.92445,     0.92449,     0.92467,     0.92485,     0.92503,     0.92521,     0.92539,     0.92557,     0.92575,     0.92592,      0.9261,     0.92628,     0.92646,     0.92664,     0.92682,       0.927,     0.92718,     0.92735,\n",
              "            0.92753,     0.92771,     0.92789,     0.92807,     0.92825,     0.92843,     0.92861,     0.92878,     0.92896,     0.92914,     0.92932,      0.9295,     0.92968,     0.92975,     0.92944,     0.92956,     0.92969,     0.92982,     0.92994,     0.93007,      0.9302,     0.93032,     0.93045,\n",
              "            0.93058,      0.9307,     0.93083,     0.93096,     0.93108,     0.93121,     0.93134,     0.93146,     0.93159,     0.93172,     0.93184,     0.93197,      0.9321,     0.93222,     0.93235,     0.93248,      0.9326,     0.93273,     0.93286,     0.93298,     0.93311,     0.93324,     0.93336,\n",
              "            0.93349,     0.93362,     0.93374,     0.93387,       0.934,     0.93412,     0.93425,     0.93438,      0.9345,     0.93463,     0.93476,     0.93488,     0.93488,     0.93484,      0.9348,     0.93476,     0.93472,     0.93468,     0.93464,      0.9346,     0.93456,     0.93452,     0.93452,\n",
              "            0.93451,     0.93451,      0.9345,      0.9345,     0.93449,     0.93448,     0.93448,     0.93447,     0.93447,     0.93446,     0.93446,     0.93445,     0.93444,     0.93444,     0.93443,     0.93443,     0.93442,     0.93442,     0.93441,      0.9344,      0.9344,     0.93439,     0.93439,\n",
              "            0.93438,     0.93438,     0.93437,     0.93437,     0.93436,     0.93435,     0.93435,     0.93434,     0.93434,     0.93433,     0.93433,     0.93432,     0.93431,     0.93431,      0.9343,      0.9343,     0.93429,     0.93429,     0.93428,     0.93427,     0.93427,     0.93426,     0.93426,\n",
              "            0.93425,     0.93425,     0.93424,     0.93423,     0.93423,     0.93422,     0.93422,     0.93421,     0.93421,      0.9342,      0.9342,     0.93419,     0.93418,     0.93418,     0.93417,     0.93417,     0.93416,     0.93416,     0.93415,     0.93414,     0.93414,     0.93413,     0.93382,\n",
              "            0.93373,     0.93372,     0.93371,      0.9337,     0.93369,     0.93368,     0.93367,     0.93366,     0.93365,     0.93364,     0.93363,     0.93362,     0.93361,      0.9336,     0.93359,     0.93358,     0.93357,     0.93356,     0.93355,     0.93354,     0.93353,     0.93352,     0.93351,\n",
              "             0.9335,     0.93349,     0.93348,     0.93347,     0.93346,     0.93345,     0.93344,     0.93343,     0.93342,     0.93341,      0.9334,     0.93339,     0.93338,     0.93337,     0.93336,     0.93335,     0.93334,     0.93418,     0.93524,      0.9363,     0.93736,     0.93842,     0.93902,\n",
              "              0.939,     0.93898,     0.93896,     0.93894,     0.93892,      0.9389,     0.93888,     0.93886,     0.93884,     0.93882,      0.9388,     0.93878,     0.93876,     0.93874,     0.93872,      0.9387,     0.93868,     0.93866,     0.93961,     0.94199,     0.94436,     0.94735,     0.95031,\n",
              "            0.95044,     0.95058,     0.95071,     0.95084,     0.95097,     0.95111,     0.95124,     0.95137,      0.9515,     0.95164,     0.95177,      0.9519,     0.95203,     0.95217,      0.9523,     0.95243,     0.95256,     0.95269,     0.95283,     0.95296,     0.95309,     0.95322,     0.95336,\n",
              "            0.95349,     0.95362,     0.95375,     0.95389,     0.95402,     0.95415,     0.95428,     0.95442,     0.95455,     0.95468,     0.95481,     0.95494,     0.95508,     0.95521,     0.95534,     0.95547,     0.95561,     0.95574,     0.95587,       0.956,     0.95614,     0.95624,      0.9562,\n",
              "            0.95616,     0.95612,     0.95608,     0.95604,       0.956,     0.95592,     0.95573,     0.95666,     0.95779,     0.95892,     0.96006,     0.96119,     0.96152,     0.96149,     0.96146,     0.96143,      0.9614,     0.96137,     0.96134,     0.96131,     0.96128,      0.9612,     0.96113,\n",
              "            0.96106,     0.96098,     0.96091,     0.96083,     0.96076,     0.96068,     0.96061,     0.96053,     0.96044,     0.96035,     0.96026,     0.96021,     0.96016,      0.9601,     0.96005,     0.95971,     0.95957,     0.95915,     0.95896,     0.95848,     0.95802,     0.95793,     0.95785,\n",
              "            0.95776,     0.95769,     0.95763,     0.95757,     0.95751,     0.95745,     0.95735,     0.95724,     0.95723,     0.95924,     0.96126,     0.96328,     0.96392,      0.9632,     0.96302,     0.96283,     0.96264,     0.96245,     0.96236,      0.9623,     0.96224,     0.96219,     0.96213,\n",
              "            0.96165,     0.96145,     0.96125,     0.96084,     0.96073,     0.96063,     0.96052,     0.96041,     0.95966,     0.95955,     0.95944,     0.95933,     0.95921,      0.9591,     0.95792,     0.95768,     0.96177,     0.96484,     0.96463,     0.96441,     0.96321,     0.96298,     0.96274,\n",
              "            0.96142,     0.95999,     0.95972,     0.95902,     0.95829,     0.95552,     0.95517,     0.95431,     0.95395,     0.95359,     0.95807,     0.96378,     0.96348,     0.96915,     0.97321,     0.97251,     0.97225,     0.97075,     0.97002,     0.96971,     0.98333,     0.98255,     0.98234,\n",
              "            0.98213,     0.98191,     0.98015,     0.97805,     0.97721,     0.97685,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.93514,     0.93514,     0.93514,     0.92973,     0.92973,     0.92973,     0.92432,     0.91892,     0.91892,     0.91892,     0.91892,     0.91892,     0.91892,     0.91892,     0.91892,     0.91892,     0.91892,     0.91368,     0.91351,     0.91218,     0.90811,     0.90811,     0.90811,\n",
              "            0.90811,     0.90811,     0.90811,     0.90811,     0.90811,     0.90811,     0.90811,     0.90811,     0.90811,     0.90811,     0.90811,     0.90811,     0.90811,     0.90811,     0.90811,     0.90811,     0.90811,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,\n",
              "             0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,\n",
              "             0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,      0.9027,\n",
              "            0.90121,     0.89915,      0.8973,      0.8973,      0.8973,      0.8973,      0.8973,      0.8973,      0.8973,     0.89674,     0.89615,     0.89556,     0.89497,     0.89438,     0.89379,     0.89319,      0.8926,     0.89201,     0.89189,     0.89189,     0.89189,     0.89189,     0.89189,\n",
              "            0.89189,     0.89189,     0.89189,     0.89189,     0.89189,     0.89189,     0.89189,     0.89189,     0.89161,     0.89133,     0.89104,     0.89076,     0.89048,      0.8902,     0.88991,     0.88963,     0.88935,     0.88906,     0.88878,      0.8885,     0.88821,     0.88793,     0.88765,\n",
              "            0.88736,     0.88708,      0.8868,     0.88651,     0.88314,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,\n",
              "            0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,\n",
              "            0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,\n",
              "            0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,       0.881,     0.88054,     0.88008,     0.87961,     0.87915,     0.87869,     0.87823,     0.87777,\n",
              "            0.87731,     0.87684,     0.87638,     0.87592,     0.87568,     0.87568,     0.87568,     0.87568,     0.87568,     0.87568,     0.87568,     0.87568,     0.87568,     0.87568,     0.87568,     0.87568,     0.87568,     0.87568,     0.87568,     0.87568,     0.87568,     0.87568,     0.87568,\n",
              "            0.87568,     0.87568,     0.87568,     0.87568,     0.87568,     0.87568,     0.87568,     0.87568,     0.87568,     0.87568,     0.87568,     0.87568,     0.87562,     0.87556,      0.8755,     0.87544,     0.87538,     0.87531,     0.87525,     0.87519,     0.87513,     0.87507,     0.87501,\n",
              "            0.87495,     0.87488,     0.87482,     0.87476,      0.8747,     0.87464,     0.87458,     0.87451,     0.87445,     0.87439,     0.87433,     0.87427,     0.87421,     0.87415,     0.87408,     0.87402,     0.87396,      0.8739,     0.87384,     0.87378,     0.87371,     0.87365,     0.87359,\n",
              "            0.87353,     0.87347,     0.87341,     0.87334,     0.87328,     0.87322,     0.87316,      0.8731,     0.87304,     0.87298,     0.87291,     0.87285,     0.87279,     0.87273,     0.87267,     0.87261,     0.87254,     0.87248,     0.87242,     0.87236,      0.8723,     0.87224,     0.87218,\n",
              "            0.87211,     0.87205,     0.87199,     0.87193,     0.87187,     0.87181,     0.87174,     0.87168,     0.87162,     0.87156,      0.8715,     0.87144,     0.87137,     0.87131,     0.87125,     0.87119,     0.87113,     0.87107,     0.87101,     0.87094,     0.87088,     0.87082,     0.87076,\n",
              "             0.8707,     0.87064,     0.87057,     0.87051,     0.87045,     0.87039,     0.87033,     0.87026,     0.87012,     0.86997,     0.86983,     0.86968,     0.86954,     0.86939,     0.86925,      0.8691,     0.86896,     0.86881,     0.86867,     0.86852,     0.86838,     0.86823,     0.86809,\n",
              "            0.86794,      0.8678,     0.86765,     0.86751,     0.86736,     0.86722,     0.86708,     0.86693,     0.86679,     0.86664,      0.8665,     0.86635,     0.86621,     0.86606,     0.86592,     0.86577,     0.86563,     0.86548,     0.86534,     0.86519,     0.86505,      0.8649,     0.86432,\n",
              "            0.86358,     0.86284,      0.8621,     0.86136,     0.86062,     0.85988,     0.85946,     0.85946,     0.85946,     0.85946,     0.85946,     0.85946,     0.85946,     0.85946,     0.85946,     0.85946,     0.85946,     0.85946,     0.85946,     0.85946,     0.85946,     0.85946,     0.85946,\n",
              "            0.85946,     0.85946,     0.85946,     0.85946,     0.85946,     0.85946,     0.85946,     0.85946,     0.85946,     0.85946,     0.85946,     0.85946,     0.85946,     0.85846,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,\n",
              "            0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,\n",
              "            0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85362,     0.85306,     0.85251,     0.85195,      0.8514,     0.85084,     0.85029,     0.84974,     0.84918,     0.84865,     0.84857,\n",
              "            0.84849,     0.84841,     0.84833,     0.84826,     0.84818,      0.8481,     0.84802,     0.84794,     0.84787,     0.84779,     0.84771,     0.84763,     0.84755,     0.84748,      0.8474,     0.84732,     0.84724,     0.84716,     0.84709,     0.84701,     0.84693,     0.84685,     0.84677,\n",
              "            0.84669,     0.84662,     0.84654,     0.84646,     0.84638,      0.8463,     0.84623,     0.84615,     0.84607,     0.84599,     0.84591,     0.84584,     0.84576,     0.84568,      0.8456,     0.84552,     0.84545,     0.84537,     0.84529,     0.84521,     0.84513,     0.84506,     0.84498,\n",
              "             0.8449,     0.84482,     0.84474,     0.84467,     0.84459,     0.84451,     0.84443,     0.84435,     0.84428,      0.8442,     0.84412,     0.84404,     0.84396,     0.84389,     0.84381,     0.84373,     0.84365,     0.84357,      0.8435,     0.84342,     0.84334,     0.84326,     0.83898,\n",
              "            0.83773,      0.8376,     0.83746,     0.83733,     0.83719,     0.83705,     0.83692,     0.83678,     0.83665,     0.83651,     0.83638,     0.83624,     0.83611,     0.83597,     0.83584,      0.8357,     0.83557,     0.83543,      0.8353,     0.83516,     0.83503,     0.83489,     0.83476,\n",
              "            0.83462,     0.83449,     0.83435,     0.83422,     0.83408,     0.83395,     0.83381,     0.83368,     0.83354,     0.83341,     0.83327,     0.83314,       0.833,     0.83287,     0.83273,      0.8326,     0.83246,     0.83243,     0.83243,     0.83243,     0.83243,     0.83243,     0.83231,\n",
              "            0.83203,     0.83174,     0.83146,     0.83117,     0.83089,     0.83061,     0.83032,     0.83004,     0.82975,     0.82947,     0.82918,      0.8289,     0.82862,     0.82833,     0.82805,     0.82776,     0.82748,      0.8272,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,\n",
              "            0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,\n",
              "            0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82703,     0.82692,     0.82613,\n",
              "            0.82533,     0.82454,     0.82375,     0.82296,     0.82217,     0.82048,     0.81679,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,      0.8105,     0.80985,     0.80919,     0.80854,     0.80789,     0.80724,     0.80659,     0.80594,     0.80511,     0.80353,     0.80194,\n",
              "            0.80036,     0.79878,     0.79719,     0.79561,     0.79403,     0.79244,     0.79086,     0.78928,     0.78745,      0.7856,     0.78376,     0.78266,     0.78155,     0.78044,     0.77933,     0.77259,     0.76982,     0.76147,     0.75777,     0.74867,     0.74013,     0.73854,     0.73696,\n",
              "            0.73538,      0.7342,     0.73309,     0.73198,     0.73087,     0.72976,     0.72794,     0.72609,     0.72432,     0.72432,     0.72432,     0.72432,     0.72201,      0.7075,     0.70381,     0.70011,     0.69642,     0.69273,     0.69103,     0.68993,     0.68882,     0.68771,      0.6866,\n",
              "            0.67777,     0.67408,     0.67038,     0.66307,     0.66123,     0.65938,     0.65753,     0.65569,     0.64303,     0.64118,     0.63934,     0.63749,     0.63564,      0.6338,     0.61525,     0.61155,     0.60541,     0.59336,     0.58966,     0.58597,     0.56606,     0.56236,     0.55867,\n",
              "            0.53876,     0.51885,     0.51516,     0.50606,     0.49679,     0.46444,     0.46074,     0.45164,     0.44795,     0.44426,     0.43243,     0.43146,     0.42777,     0.41622,     0.39273,     0.38245,     0.37876,     0.35885,     0.34975,     0.34606,     0.31895,     0.30443,     0.30074,\n",
              "            0.29705,     0.29335,     0.26692,     0.24092,     0.23182,     0.22813,     0.22314,     0.21894,     0.20984,     0.20614,     0.19016,     0.17533,     0.15002,     0.14632,     0.13557,     0.12092,     0.10557,    0.091223,    0.089838,    0.088453,    0.087067,     0.08327,    0.073441,\n",
              "           0.058675,    0.048035,    0.044342,    0.036281,    0.034064,    0.026443,    0.024226,     0.02201,    0.020316,    0.018733,     0.01715,    0.013944,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
              "fitness: np.float64(0.5358654300647155)\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.49448])\n",
              "names: {0: 'seal'}\n",
              "nt_per_class: array([185])\n",
              "nt_per_image: array([170])\n",
              "results_dict: {'metrics/precision(B)': np.float64(0.9254864345279415), 'metrics/recall(B)': np.float64(0.87279082385689), 'metrics/mAP50(B)': np.float64(0.9083651721090481), 'metrics/mAP50-95(B)': np.float64(0.4944765698375675), 'fitness': np.float64(0.5358654300647155)}\n",
              "save_dir: PosixPath('ProSeal/seals2')\n",
              "speed: {'preprocess': 0.12739701259110892, 'inference': 0.7827937688840112, 'loss': 0.000190265387932308, 'postprocess': 0.2187287921665727}\n",
              "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
              "task: 'detect'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.train(\n",
        "    project=\"ProSeal\",\n",
        "    name=\"seals\",\n",
        "    data=\"/content/export_yolov8/data.yaml\",  # Aseg√∫rate de que data.yaml use rutas correctas para Colab\n",
        "    epochs=120,                                                # N√∫mero total de √©pocas (pasadas completas por el dataset de entrenamiento)\n",
        "    imgsz=640,                                                  # Tama√±o de la imagen (se reescala a 640x640)\n",
        "    batch=32,                                                   # N√∫mero de im√°genes por batch\n",
        "    lr0=0.0001,                                                 # Tasa de aprendizaje inicial. Un valor mayor hace que los pesos se actualicen m√°s r√°pido, pero puede inestabilizar el entrenamiento.\n",
        "    momentum=0.937,                                             # Momentum para el optimizador (por ejemplo, en SGD)endizaje y otros par√°metros (como el momentum) se ajustan gradualmente.    Esto ayuda a estabilizar el entrenamiento y a evitar que el modelo se desv√≠e demasiado al principio.\n",
        "    warmup_momentum=0.8,                                        # La fase de \"warmup\" es un per√≠odo inicial en el que la tasa de apr\n",
        "    optimizer=\"adamw\",                                          # Se usa AdamW (una variante de Adam que incorpora weight decay para evitar sobreajuste)\n",
        "    weight_decay=0.002,                                         # Penalizaci√≥n sobre los pesos para prevenir sobreajuste. Si es muy alto, pdificultar euede l aprendizaje; si es muy bajo, el modelo puede sobreajustarse.                                          # Se usa AdamW (una variante de Adam que incorpora weight decay para evitar sobreajuste)\n",
        "    #augment=False,                                             # Desactiva el data augmentation on the fly de YOLO##############  asi puedo hacer yo la data augmentation con las fotos con labels\n",
        "    half=True,                                                  # Activa precisi√≥n mixta (FP16) para GPU\n",
        "    workers=8,                                                  # N√∫mero de workers para el DataLoader\n",
        "    device='cuda' ,                                             # Fuerza el uso de GPU lo que acelera el entrenamiento\n",
        "    mosaic=1,                                                   # Desactivar si las im√°genes son muy homog√©neas, es un data augmentation process\n",
        "    #resume=True,                                               # PARA seguir entrenamiento donde lo dejaste\n",
        "    #validate=False                                             # para no hacer validaci√≥n a la vez que entrena\n",
        "    patience=13,                                                # epochs extra desde que converge para ver si aprende , si no aprende en 3 epochs m√°s, se para. si tras \"X\" epochs la m√©trica val/best_map_50 no mejora, se detiene el entrenamiento autom√°ticamente.\n",
        "    cos_lr=True,                                                # scheduler\n",
        "    plots=True,                                                 # generar gr√°ficas de plots de learning rate\n",
        "    #wandb=True,                                                # Activa integraci√≥n con W&B\n",
        "    #copy_paste=True,\n",
        "    dfl= 1.75,\n",
        "    warmup_epochs= 4,\n",
        "    lrf= 0.01,\n",
        "    flipud= 0.3,\n",
        "    degrees=10,\n",
        "    seed=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhY4ZXWY7I2S"
      },
      "source": [
        "## **5. Save the model**\n",
        "\n",
        "In my case, I save on Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBSWPatloIgl",
        "outputId": "a98780df-c106-44d2-f6eb-14a8ae3c042a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "seals2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "dest_folder = \"/content/drive/MyDrive/ProSeal/train\"\n",
        "!mkdir -p \"{dest_folder}\"                                                           #El comando mkdir -p crea esa carpeta (y cualquier subcarpeta necesaria) si no existe.\n",
        "\n",
        "# Copia la carpeta de resultados (ajusta el nombre seg√∫n el que se haya generado)\n",
        "!cp -r /content/ProSeal/seals2 \"{dest_folder}/\"   #copiar los reultados del modelo en drive\n",
        "\n",
        "# Comprueba que se copiaron los archivos (opcional)\n",
        "!ls \"{dest_folder}\"                                                                 #verifica que los archivos se han copiado correctamente\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3x7xqe9cdvB"
      },
      "source": [
        "# **6. Validation:**\n",
        "\n",
        "Assess the results with the validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLCZhUpz7x51"
      },
      "source": [
        "# 6.1 Validation in Ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlXCo9lAunRQ",
        "outputId": "1d8ccd8b-3346-41e4-b122-bbe2c3b95c8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "Model summary (fused): 72 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 828.5¬±477.0 MB/s, size: 46.1 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/export_yolov8/valid/labels.cache... 10008 images, 9838 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10008/10008 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 626/626 [00:19<00:00, 31.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.934      0.846      0.905        0.5\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "M√©tricas de validaci√≥n: ultralytics.utils.metrics.DetMetrics object with attributes:\n",
            "\n",
            "ap_class_index: array([0])\n",
            "box: ultralytics.utils.metrics.Metric object\n",
            "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x797f261ba750>\n",
            "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
            "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,        0.98,        0.98,        0.98,        0.98,        0.98,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,\n",
            "            0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,\n",
            "            0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,\n",
            "            0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,\n",
            "            0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,\n",
            "            0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,\n",
            "            0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,\n",
            "            0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,\n",
            "            0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97674,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,\n",
            "            0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,\n",
            "            0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,\n",
            "            0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,\n",
            "            0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,\n",
            "            0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,\n",
            "            0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,\n",
            "            0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,\n",
            "            0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,\n",
            "            0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,\n",
            "            0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,\n",
            "            0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,\n",
            "            0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,\n",
            "            0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,     0.97241,\n",
            "            0.97241,     0.97241,     0.97241,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,\n",
            "            0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,     0.96732,      0.9557,      0.9557,      0.9557,      0.9557,      0.9557,\n",
            "             0.9557,      0.9557,      0.9557,      0.9557,      0.9557,      0.9557,      0.9557,      0.9557,      0.9557,      0.9557,      0.9557,     0.93976,     0.93976,     0.93976,     0.93976,     0.93976,     0.93976,     0.93976,     0.93976,     0.93976,     0.93976,     0.93976,     0.93976,\n",
            "            0.93976,     0.93976,     0.93976,     0.93976,     0.93976,     0.93976,     0.93976,     0.93976,     0.93976,     0.93976,     0.93976,     0.93976,     0.93976,     0.93976,     0.93976,     0.93452,     0.93452,     0.93452,     0.93452,     0.93452,     0.87363,     0.87363,     0.87363,\n",
            "            0.87363,     0.87363,     0.87363,     0.87363,     0.87363,     0.87363,     0.87363,     0.87363,     0.87027,     0.87027,     0.87027,     0.87027,     0.87027,     0.87027,     0.87027,     0.87027,     0.87027,     0.87027,     0.87027,     0.86243,     0.86243,     0.86243,     0.86243,\n",
            "            0.86243,     0.86243,     0.86243,     0.86243,     0.86243,     0.86243,     0.86243,     0.84974,     0.84974,     0.84974,     0.84974,     0.84974,     0.78947,     0.78947,     0.78947,     0.78947,     0.78947,     0.74439,     0.74439,     0.74439,     0.74439,     0.74439,     0.74439,\n",
            "            0.62547,     0.62547,     0.62547,     0.62547,     0.62547,     0.62222,     0.62222,     0.62222,     0.62222,     0.62222,     0.62222,     0.60791,     0.60791,     0.60791,     0.60791,     0.60791,     0.55375,     0.55375,     0.55375,     0.55375,     0.55375,     0.55375,     0.49854,\n",
            "            0.49854,     0.49854,     0.49854,     0.49854,     0.49568,     0.49568,     0.49568,     0.49568,     0.49568,     0.46757,     0.46757,     0.46757,     0.46757,     0.46757,     0.46757,     0.38225,     0.37627,      0.3703,     0.36433,     0.35836,     0.35238,     0.34641,     0.34044,\n",
            "            0.33447,     0.32849,     0.32252,     0.31655,     0.31058,      0.3046,     0.29863,     0.29266,     0.28668,     0.28071,     0.27474,     0.26877,     0.26279,     0.25682,     0.25085,     0.24488,      0.2389,     0.23293,     0.22696,     0.22099,     0.21501,     0.20904,     0.20307,\n",
            "             0.1971,     0.19112,     0.18515,     0.17918,     0.17321,     0.16723,     0.16126,     0.15529,     0.14932,     0.14334,     0.13737,      0.1314,     0.12542,     0.11945,     0.11348,     0.10751,     0.10153,    0.095562,    0.089589,    0.083616,    0.077644,    0.071671,    0.065699,\n",
            "           0.059726,    0.053753,    0.047781,    0.041808,    0.035836,    0.029863,     0.02389,    0.017918,    0.011945,   0.0059726,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.54747,     0.54747,     0.62133,     0.65071,     0.67793,     0.69951,      0.7164,     0.72749,     0.73463,      0.7389,     0.74228,     0.75289,      0.7544,     0.75973,      0.7617,     0.76898,     0.77467,     0.78044,     0.78475,     0.78745,     0.78827,     0.78983,      0.7912,\n",
            "            0.79228,     0.79424,     0.79991,     0.80264,     0.80651,     0.81028,     0.81131,     0.81123,     0.81139,     0.81204,     0.81268,     0.81473,     0.81596,     0.81887,     0.82075,     0.82558,      0.8269,     0.82886,     0.83398,     0.83525,     0.83578,     0.83617,     0.83656,\n",
            "            0.83695,     0.83734,     0.83615,     0.83484,     0.83529,     0.83574,     0.83619,     0.83664,     0.83893,     0.83917,     0.83941,     0.83964,     0.83988,     0.84012,     0.84035,     0.84059,     0.84083,     0.84113,      0.8418,     0.84247,     0.84315,     0.84381,     0.84448,\n",
            "            0.84515,     0.84552,     0.84575,     0.84599,     0.84622,     0.84645,     0.84668,     0.84692,     0.84715,     0.84738,     0.84826,     0.84995,     0.85046,     0.85097,     0.85148,     0.85198,      0.8523,     0.85262,     0.85293,     0.85325,     0.85357,     0.85389,     0.85424,\n",
            "            0.85486,     0.85547,     0.85608,      0.8572,     0.85866,     0.85884,     0.85903,     0.85921,     0.85939,     0.85957,     0.85976,     0.85994,     0.86012,      0.8603,     0.86048,     0.86067,     0.86085,     0.86427,     0.86744,     0.86653,     0.86562,     0.86473,     0.86523,\n",
            "            0.86573,     0.86624,     0.86674,     0.86711,     0.86733,     0.86754,     0.86776,     0.86797,     0.86818,      0.8684,     0.86861,     0.86882,     0.86903,     0.86925,     0.87104,     0.87154,     0.87139,     0.87123,     0.87108,     0.87093,     0.87078,     0.87062,     0.87047,\n",
            "            0.87032,     0.87017,     0.87001,     0.86986,     0.86971,     0.86956,      0.8694,     0.86925,      0.8691,     0.86895,     0.86879,     0.86864,     0.86819,     0.86772,     0.86726,     0.86679,     0.86632,     0.86586,     0.86641,     0.86802,     0.86848,     0.86894,     0.86939,\n",
            "            0.86985,     0.87022,     0.86964,     0.86907,     0.86849,     0.86791,     0.86733,      0.8644,     0.86499,     0.86558,     0.86616,     0.86619,     0.86555,     0.86491,     0.86426,     0.86362,     0.86076,     0.86159,     0.86243,     0.86285,     0.86313,     0.86342,      0.8637,\n",
            "            0.86399,     0.86427,     0.86455,     0.86483,      0.8655,     0.86682,      0.8675,     0.86767,     0.86784,     0.86801,     0.86818,     0.86835,     0.86852,     0.86869,     0.86886,     0.86903,      0.8692,     0.86937,     0.86954,     0.86971,     0.87011,     0.87085,     0.87159,\n",
            "            0.87223,     0.87231,      0.8724,     0.87248,     0.87256,     0.87264,     0.87272,      0.8728,     0.87288,     0.87296,     0.87304,     0.87312,     0.87321,     0.87329,     0.87337,     0.87345,     0.87353,     0.87361,     0.87369,     0.87377,     0.87385,     0.87393,     0.87401,\n",
            "            0.87409,     0.87417,     0.87426,     0.87434,     0.87442,      0.8745,     0.87458,     0.87475,     0.87598,      0.8771,     0.87718,     0.87725,     0.87733,      0.8774,     0.87748,     0.87755,     0.87763,      0.8777,     0.87778,     0.87785,     0.87793,       0.878,     0.87808,\n",
            "            0.87815,     0.87823,      0.8783,     0.87838,     0.87845,     0.87853,      0.8786,     0.87868,     0.87875,     0.87883,      0.8789,     0.87898,     0.87905,     0.87913,      0.8792,     0.87928,     0.87935,     0.87943,      0.8795,     0.87962,     0.87984,     0.88006,     0.88028,\n",
            "            0.88049,     0.88071,     0.88093,     0.88115,     0.88136,     0.88158,      0.8818,     0.88201,     0.88205,     0.88209,     0.88212,     0.88216,     0.88219,     0.88222,     0.88226,     0.88229,     0.88232,     0.88236,     0.88239,     0.88243,     0.88246,     0.88249,     0.88253,\n",
            "            0.88256,     0.88259,     0.88263,     0.88266,     0.88269,     0.88273,     0.88276,      0.8828,     0.88283,     0.88286,      0.8829,     0.88293,     0.88296,       0.883,     0.88303,     0.88307,      0.8831,     0.88313,     0.88317,      0.8832,     0.88323,     0.88327,      0.8833,\n",
            "            0.88333,     0.88337,      0.8834,     0.88343,     0.88347,      0.8835,     0.88354,     0.88357,      0.8836,     0.88364,     0.88367,      0.8837,     0.88374,     0.88377,      0.8838,     0.88384,     0.88387,     0.88391,     0.88394,     0.88397,     0.88401,     0.88404,     0.88407,\n",
            "            0.88411,     0.88414,     0.88417,     0.88421,     0.88424,     0.88427,     0.88431,     0.88434,     0.88437,     0.88441,     0.88444,     0.88448,     0.88451,     0.88459,     0.88467,     0.88474,     0.88482,      0.8849,     0.88498,     0.88505,     0.88513,     0.88521,     0.88529,\n",
            "            0.88536,     0.88544,     0.88552,      0.8856,     0.88567,     0.88575,     0.88583,     0.88591,     0.88598,     0.88606,     0.88614,     0.88622,     0.88629,     0.88637,     0.88645,     0.88652,      0.8866,     0.88668,     0.88676,     0.88683,     0.88691,     0.88699,     0.88709,\n",
            "            0.88719,      0.8873,     0.88741,     0.88751,     0.88762,     0.88772,     0.88783,     0.88794,     0.88804,     0.88815,     0.88826,     0.88836,     0.88847,     0.88857,     0.88868,     0.88879,     0.88889,       0.889,      0.8891,     0.88921,     0.88931,     0.88942,     0.88951,\n",
            "            0.88944,     0.88937,     0.88929,     0.88922,     0.88915,     0.88908,       0.889,     0.88893,     0.88886,     0.88878,     0.88871,     0.88864,     0.88857,     0.88849,     0.88842,     0.88835,     0.88827,      0.8882,     0.88813,     0.88805,     0.88798,     0.88791,     0.88784,\n",
            "            0.88776,     0.88769,     0.88762,     0.88754,     0.88747,      0.8874,     0.88732,     0.88725,     0.88718,      0.8871,     0.88703,     0.88696,     0.88689,     0.88681,     0.88674,     0.88667,     0.88659,     0.88652,     0.88645,     0.88637,     0.88654,     0.88674,     0.88694,\n",
            "            0.88714,     0.88735,     0.88755,     0.88775,     0.88795,     0.88815,     0.88835,     0.88855,     0.88876,     0.88885,     0.88875,     0.88865,     0.88854,     0.88844,     0.88833,     0.88823,     0.88812,     0.88802,     0.88791,     0.88781,     0.88771,      0.8876,      0.8875,\n",
            "            0.88739,     0.88729,     0.88718,     0.88708,     0.88697,     0.88687,     0.88677,     0.88666,     0.88656,     0.88645,     0.88635,     0.88624,     0.88614,     0.88603,     0.88593,     0.88582,     0.88572,     0.88561,      0.8855,     0.88539,     0.88528,     0.88516,     0.88505,\n",
            "            0.88494,     0.88483,     0.88472,     0.88461,      0.8845,     0.88439,     0.88428,     0.88417,     0.88405,     0.88394,     0.88383,     0.88372,     0.88361,      0.8835,     0.88339,     0.88328,     0.88317,     0.88305,     0.88294,     0.88283,     0.88272,     0.88261,     0.88247,\n",
            "            0.88223,     0.88199,     0.88175,     0.88151,     0.88127,     0.88104,      0.8808,     0.88056,     0.88032,     0.88008,     0.87984,      0.8796,     0.87936,     0.87913,     0.87891,     0.87869,     0.87847,     0.87825,     0.87803,     0.87781,     0.87759,     0.87737,     0.87715,\n",
            "            0.87693,     0.87671,     0.87649,     0.87627,     0.87606,     0.87596,     0.87586,     0.87576,     0.87565,     0.87555,     0.87545,     0.87535,     0.87524,     0.87514,     0.87504,     0.87493,     0.87483,     0.87473,     0.87463,     0.87452,     0.87442,     0.87432,     0.87421,\n",
            "            0.87411,     0.87401,      0.8739,      0.8738,      0.8737,      0.8736,     0.87349,     0.87339,     0.87329,     0.87318,     0.87308,     0.87298,     0.87287,      0.8729,     0.87303,     0.87315,     0.87327,     0.87339,     0.87351,     0.87363,     0.87375,     0.87387,     0.87399,\n",
            "            0.87411,     0.87423,     0.87435,     0.87447,     0.87459,     0.87471,     0.87483,     0.87495,     0.87507,     0.87519,     0.87531,       0.876,     0.87709,     0.87794,     0.87809,     0.87823,     0.87837,     0.87851,     0.87866,      0.8788,     0.87894,     0.87908,     0.87922,\n",
            "            0.87937,     0.87951,     0.87965,     0.87979,     0.87993,     0.88008,     0.88022,     0.88036,      0.8804,     0.88011,     0.87982,     0.87953,     0.87924,     0.87895,     0.87866,     0.87837,     0.87808,     0.87779,      0.8775,     0.87721,     0.87708,     0.87695,     0.87683,\n",
            "            0.87671,     0.87659,     0.87647,     0.87634,     0.87622,      0.8761,     0.87598,     0.87586,     0.87573,     0.87561,     0.87549,     0.87537,     0.87524,     0.87512,       0.875,     0.87488,     0.87476,     0.87463,     0.87451,     0.87439,     0.87427,     0.87414,     0.87402,\n",
            "             0.8739,     0.87377,     0.87365,     0.87352,     0.87339,     0.87327,     0.87314,     0.87301,     0.87289,     0.87276,     0.87263,     0.87251,     0.87238,     0.87225,     0.87213,       0.872,     0.87187,     0.87174,     0.87162,     0.87149,     0.87136,     0.87124,     0.87111,\n",
            "            0.87098,     0.87086,     0.87073,      0.8706,     0.87087,     0.87119,     0.87151,     0.87183,     0.87214,     0.87246,     0.87278,     0.87309,     0.87324,     0.87334,     0.87344,     0.87354,     0.87364,     0.87374,     0.87384,     0.87394,     0.87404,     0.87414,     0.87424,\n",
            "            0.87434,     0.87444,     0.87454,     0.87464,     0.87474,     0.87484,     0.87494,     0.87504,     0.87514,     0.87524,     0.87534,     0.87544,     0.87554,     0.87564,     0.87566,     0.87228,     0.86998,     0.86853,     0.86766,     0.86679,     0.86591,     0.86552,     0.86532,\n",
            "            0.86512,     0.86492,     0.86471,     0.86451,     0.86431,      0.8641,      0.8639,      0.8637,     0.86349,     0.86329,     0.86309,     0.86288,     0.86268,     0.86247,     0.86221,     0.85961,      0.8567,     0.85414,     0.85199,     0.85369,     0.85249,     0.84966,     0.84731,\n",
            "            0.84171,     0.83806,     0.83557,     0.83372,     0.83023,     0.82904,     0.82825,     0.82747,     0.82668,     0.82561,     0.82365,     0.82031,     0.81023,     0.80619,     0.80334,      0.7949,     0.79059,     0.78812,     0.78603,      0.7836,     0.78049,     0.77838,     0.77447,\n",
            "            0.76789,     0.74945,     0.74101,     0.73705,      0.7302,       0.728,     0.72497,     0.72134,     0.71922,     0.71721,      0.7015,      0.6964,      0.6846,     0.68128,     0.66916,     0.65831,     0.65052,     0.64454,     0.62776,     0.61828,     0.61991,     0.59949,      0.5638,\n",
            "            0.53213,     0.50805,     0.49797,      0.4932,     0.48244,     0.47582,     0.46176,      0.4284,     0.41685,     0.38071,     0.37059,     0.34931,      0.3353,     0.29524,     0.27142,     0.23615,      0.2309,     0.21975,     0.21525,     0.20979,     0.20091,     0.18985,     0.17468,\n",
            "            0.16536,     0.13969,       0.132,     0.12913,     0.12673,     0.12433,     0.12192,     0.10725,     0.10117,    0.092003,    0.090012,    0.088017,    0.086018,    0.084014,    0.081031,     0.07682,    0.070587,    0.031457,    0.029733,    0.028006,    0.026275,    0.024542,    0.022805,\n",
            "           0.020683,    0.016884,     0.01307,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.38702,     0.38702,     0.46657,      0.5037,     0.53708,     0.56674,     0.58925,     0.60661,     0.61681,     0.62804,     0.63294,     0.64852,     0.65077,     0.65874,     0.66171,     0.67278,     0.68153,     0.69051,     0.69729,     0.70156,     0.70287,     0.70534,     0.70755,\n",
            "            0.70927,     0.71242,      0.7216,     0.72605,     0.73241,     0.73865,     0.74037,     0.74341,     0.74422,      0.7453,     0.74639,     0.74986,     0.75195,     0.75689,     0.76012,     0.76845,     0.77074,     0.77415,     0.78312,     0.78537,      0.7863,       0.787,     0.78769,\n",
            "            0.78839,     0.78908,     0.78899,     0.78888,     0.78969,     0.79049,     0.79129,     0.79209,     0.79622,     0.79665,     0.79708,      0.7975,     0.79793,     0.79836,     0.79878,     0.79921,     0.79964,     0.80019,     0.80141,     0.80263,     0.80384,     0.80506,     0.80628,\n",
            "            0.80749,     0.80817,      0.8086,     0.80902,     0.80945,     0.80987,      0.8103,     0.81073,     0.81115,     0.81158,      0.8132,      0.8163,     0.81725,      0.8182,     0.81914,     0.82006,     0.82065,     0.82124,     0.82183,     0.82242,     0.82301,      0.8236,     0.82427,\n",
            "            0.82541,     0.82655,      0.8277,     0.82978,     0.83253,     0.83287,     0.83321,     0.83356,      0.8339,     0.83425,     0.83459,     0.83493,     0.83528,     0.83562,     0.83596,     0.83631,     0.83665,     0.84314,     0.84967,     0.84943,     0.84919,     0.84897,     0.84994,\n",
            "            0.85091,     0.85189,     0.85286,     0.85358,       0.854,     0.85441,     0.85483,     0.85524,     0.85566,     0.85607,     0.85648,      0.8569,     0.85731,     0.85773,     0.86123,      0.8624,     0.86237,     0.86233,     0.86229,     0.86226,     0.86222,     0.86218,     0.86215,\n",
            "            0.86211,     0.86207,     0.86204,       0.862,     0.86196,     0.86193,     0.86189,     0.86185,     0.86181,     0.86178,     0.86174,      0.8617,     0.86159,     0.86148,     0.86137,     0.86125,     0.86114,     0.86103,     0.86258,     0.86578,     0.86669,     0.86761,     0.86852,\n",
            "            0.86944,     0.87026,     0.87013,     0.86999,     0.86986,     0.86973,     0.86959,     0.86939,     0.87059,     0.87178,     0.87297,     0.87356,     0.87342,     0.87327,     0.87313,     0.87298,     0.87321,     0.87494,     0.87667,     0.87754,     0.87812,     0.87871,      0.8793,\n",
            "            0.87989,     0.88047,     0.88106,     0.88165,     0.88303,     0.88578,      0.8872,     0.88756,     0.88792,     0.88827,     0.88863,     0.88899,     0.88934,      0.8897,     0.89005,     0.89041,     0.89077,     0.89112,     0.89148,     0.89184,     0.89269,     0.89425,     0.89581,\n",
            "            0.89717,     0.89734,     0.89751,     0.89768,     0.89785,     0.89803,      0.8982,     0.89837,     0.89854,     0.89871,     0.89888,     0.89905,     0.89923,      0.8994,     0.89957,     0.89974,     0.89991,     0.90008,     0.90025,     0.90043,      0.9006,     0.90077,     0.90094,\n",
            "            0.90111,     0.90128,     0.90146,     0.90163,      0.9018,     0.90197,     0.90214,     0.90252,     0.90513,     0.90753,     0.90769,     0.90785,     0.90801,     0.90817,     0.90833,     0.90849,     0.90866,     0.90882,     0.90898,     0.90914,      0.9093,     0.90946,     0.90962,\n",
            "            0.90978,     0.90994,     0.91011,     0.91027,     0.91043,     0.91059,     0.91075,     0.91091,     0.91107,     0.91123,     0.91139,     0.91155,     0.91172,     0.91188,     0.91204,      0.9122,     0.91236,     0.91252,     0.91268,     0.91294,     0.91341,     0.91388,     0.91435,\n",
            "            0.91482,     0.91529,     0.91576,     0.91623,      0.9167,     0.91717,     0.91764,     0.91811,      0.9182,     0.91827,     0.91834,     0.91842,     0.91849,     0.91856,     0.91864,     0.91871,     0.91878,     0.91886,     0.91893,       0.919,     0.91908,     0.91915,     0.91922,\n",
            "            0.91929,     0.91937,     0.91944,     0.91951,     0.91959,     0.91966,     0.91973,     0.91981,     0.91988,     0.91995,     0.92003,      0.9201,     0.92017,     0.92024,     0.92032,     0.92039,     0.92046,     0.92054,     0.92061,     0.92068,     0.92076,     0.92083,      0.9209,\n",
            "            0.92098,     0.92105,     0.92112,     0.92119,     0.92127,     0.92134,     0.92141,     0.92149,     0.92156,     0.92163,     0.92171,     0.92178,     0.92185,     0.92193,       0.922,     0.92207,     0.92215,     0.92222,     0.92229,     0.92236,     0.92244,     0.92251,     0.92258,\n",
            "            0.92266,     0.92273,      0.9228,     0.92288,     0.92295,     0.92302,      0.9231,     0.92317,     0.92324,     0.92331,     0.92339,     0.92346,     0.92354,     0.92371,     0.92388,     0.92405,     0.92422,     0.92439,     0.92455,     0.92472,     0.92489,     0.92506,     0.92523,\n",
            "             0.9254,     0.92557,     0.92574,     0.92591,     0.92608,     0.92625,     0.92642,     0.92659,     0.92675,     0.92692,     0.92709,     0.92726,     0.92743,      0.9276,     0.92777,     0.92794,     0.92811,     0.92828,     0.92845,     0.92862,     0.92879,     0.92895,     0.92917,\n",
            "            0.92941,     0.92964,     0.92987,     0.93011,     0.93034,     0.93057,     0.93081,     0.93104,     0.93127,     0.93151,     0.93174,     0.93197,     0.93221,     0.93244,     0.93267,     0.93291,     0.93314,     0.93337,     0.93361,     0.93384,     0.93407,     0.93431,     0.93452,\n",
            "            0.93451,     0.93451,      0.9345,     0.93449,     0.93448,     0.93447,     0.93446,     0.93445,     0.93444,     0.93443,     0.93442,     0.93441,     0.93441,      0.9344,     0.93439,     0.93438,     0.93437,     0.93436,     0.93435,     0.93434,     0.93433,     0.93432,     0.93431,\n",
            "            0.93431,      0.9343,     0.93429,     0.93428,     0.93427,     0.93426,     0.93425,     0.93424,     0.93423,     0.93422,     0.93421,     0.93421,      0.9342,     0.93419,     0.93418,     0.93417,     0.93416,     0.93415,     0.93414,     0.93413,     0.93452,     0.93497,     0.93542,\n",
            "            0.93587,     0.93632,     0.93677,     0.93722,     0.93766,     0.93811,     0.93856,     0.93901,     0.93946,     0.93976,     0.93974,     0.93973,     0.93972,     0.93971,     0.93969,     0.93968,     0.93967,     0.93966,     0.93965,     0.93963,     0.93962,     0.93961,      0.9396,\n",
            "            0.93959,     0.93957,     0.93956,     0.93955,     0.93954,     0.93953,     0.93951,      0.9395,     0.93949,     0.93948,     0.93947,     0.93945,     0.93944,     0.93943,     0.93942,     0.93941,     0.93939,     0.93938,     0.93937,     0.93936,     0.93934,     0.93933,     0.93932,\n",
            "             0.9393,     0.93929,     0.93928,     0.93927,     0.93925,     0.93924,     0.93923,     0.93921,      0.9392,     0.93919,     0.93918,     0.93916,     0.93915,     0.93914,     0.93912,     0.93911,      0.9391,     0.93909,     0.93907,     0.93906,     0.93905,     0.93903,     0.93902,\n",
            "            0.93899,     0.93896,     0.93893,     0.93891,     0.93888,     0.93885,     0.93882,      0.9388,     0.93877,     0.93874,     0.93871,     0.93868,     0.93866,     0.93863,      0.9386,     0.93858,     0.93855,     0.93853,      0.9385,     0.93847,     0.93845,     0.93842,      0.9384,\n",
            "            0.93837,     0.93835,     0.93832,     0.93829,     0.93827,     0.93826,     0.93825,     0.93823,     0.93822,     0.93821,      0.9382,     0.93818,     0.93817,     0.93816,     0.93815,     0.93814,     0.93812,     0.93811,      0.9381,     0.93809,     0.93808,     0.93806,     0.93805,\n",
            "            0.93804,     0.93803,     0.93801,       0.938,     0.93799,     0.93798,     0.93797,     0.93795,     0.93794,     0.93793,     0.93792,     0.93791,     0.93789,     0.93806,     0.93833,     0.93861,     0.93889,     0.93917,     0.93945,     0.93973,     0.94001,     0.94029,     0.94056,\n",
            "            0.94084,     0.94112,      0.9414,     0.94168,     0.94196,     0.94224,     0.94252,      0.9428,     0.94307,     0.94335,     0.94363,     0.94523,     0.94779,     0.94977,     0.95011,     0.95044,     0.95077,     0.95111,     0.95144,     0.95177,     0.95211,     0.95244,     0.95277,\n",
            "            0.95311,     0.95344,     0.95378,     0.95411,     0.95444,     0.95478,     0.95511,     0.95544,     0.95569,     0.95567,     0.95564,     0.95562,     0.95559,     0.95557,     0.95554,     0.95552,     0.95549,     0.95547,     0.95544,     0.95542,      0.9554,     0.95539,     0.95538,\n",
            "            0.95537,     0.95536,     0.95535,     0.95534,     0.95533,     0.95532,     0.95531,      0.9553,     0.95529,     0.95528,     0.95527,     0.95526,     0.95524,     0.95523,     0.95522,     0.95521,      0.9552,     0.95519,     0.95518,     0.95517,     0.95516,     0.95515,     0.95514,\n",
            "            0.95513,     0.95512,     0.95511,     0.95509,     0.95508,     0.95507,     0.95506,     0.95505,     0.95504,     0.95503,     0.95502,     0.95501,       0.955,     0.95498,     0.95497,     0.95496,     0.95495,     0.95494,     0.95493,     0.95492,     0.95491,      0.9549,     0.95488,\n",
            "            0.95487,     0.95486,     0.95485,     0.95484,     0.95552,     0.95629,     0.95705,     0.95782,     0.95859,     0.95935,     0.96012,     0.96088,     0.96123,     0.96148,     0.96172,     0.96196,     0.96221,     0.96245,     0.96269,     0.96294,     0.96318,     0.96343,     0.96367,\n",
            "            0.96391,     0.96416,      0.9644,     0.96464,     0.96489,     0.96513,     0.96538,     0.96562,     0.96586,     0.96611,     0.96635,     0.96659,     0.96684,     0.96708,     0.96732,      0.9671,     0.96695,     0.96685,      0.9668,     0.96674,     0.96668,     0.96666,     0.96664,\n",
            "            0.96663,     0.96662,      0.9666,     0.96659,     0.96658,     0.96656,     0.96655,     0.96654,     0.96652,     0.96651,      0.9665,     0.96648,     0.96647,     0.96646,     0.96644,     0.96627,     0.96607,      0.9659,     0.96583,      0.9702,      0.9723,     0.97214,     0.97201,\n",
            "             0.9717,     0.97149,     0.97135,     0.97125,     0.97104,     0.97097,     0.97093,     0.97088,     0.97084,     0.97077,     0.97066,     0.97046,     0.96986,     0.96961,     0.96944,     0.96891,     0.96864,     0.96848,     0.96835,     0.96819,     0.96799,     0.96785,     0.96759,\n",
            "            0.96716,     0.96589,     0.96529,       0.965,      0.9645,     0.96686,      0.9727,     0.97249,     0.97237,     0.97225,     0.97131,     0.97099,     0.97025,     0.97004,     0.96924,      0.9685,     0.96796,     0.96753,     0.96629,     0.96864,     0.97667,     0.97562,     0.97348,\n",
            "            0.97134,     0.96955,     0.96875,     0.96836,     0.96745,     0.96687,      0.9656,     0.96225,     0.97816,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
            "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.93514,     0.93514,     0.92973,     0.91892,     0.91892,     0.91351,     0.91351,     0.90853,     0.90811,      0.8973,      0.8973,      0.8973,      0.8973,      0.8973,      0.8973,      0.8973,      0.8973,      0.8973,      0.8973,      0.8973,      0.8973,      0.8973,      0.8973,\n",
            "             0.8973,      0.8973,      0.8973,      0.8973,      0.8973,      0.8973,      0.8973,     0.89266,     0.89189,     0.89189,     0.89189,     0.89189,     0.89189,     0.89189,     0.89189,     0.89189,     0.89189,     0.89189,     0.89189,     0.89189,     0.89189,     0.89189,     0.89189,\n",
            "            0.89189,     0.89189,      0.8893,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,\n",
            "            0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,\n",
            "            0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88649,     0.88596,     0.88433,      0.8827,     0.88108,     0.88108,\n",
            "            0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88108,     0.88087,     0.88059,     0.88032,     0.88005,     0.87978,      0.8795,     0.87923,     0.87896,\n",
            "            0.87869,     0.87841,     0.87814,     0.87787,      0.8776,     0.87732,     0.87705,     0.87678,     0.87651,     0.87623,     0.87596,     0.87569,     0.87489,     0.87406,     0.87323,      0.8724,     0.87157,     0.87074,     0.87027,     0.87027,     0.87027,     0.87027,     0.87027,\n",
            "            0.87027,     0.87018,     0.86916,     0.86814,     0.86712,     0.86611,     0.86509,     0.85946,     0.85946,     0.85946,     0.85946,     0.85895,     0.85783,     0.85671,     0.85558,     0.85446,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,\n",
            "            0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,\n",
            "            0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,\n",
            "            0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,\n",
            "            0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,\n",
            "            0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,\n",
            "            0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,\n",
            "            0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,\n",
            "            0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,\n",
            "            0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,\n",
            "            0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84865,     0.84864,\n",
            "            0.84851,     0.84839,     0.84826,     0.84814,     0.84801,     0.84789,     0.84776,     0.84764,     0.84751,     0.84739,     0.84726,     0.84714,     0.84701,     0.84689,     0.84676,     0.84664,     0.84651,     0.84639,     0.84626,     0.84614,     0.84601,     0.84589,     0.84576,\n",
            "            0.84564,     0.84551,     0.84539,     0.84526,     0.84514,     0.84501,     0.84489,     0.84476,     0.84464,     0.84451,     0.84439,     0.84426,     0.84414,     0.84401,     0.84389,     0.84376,     0.84363,     0.84351,     0.84338,     0.84326,     0.84324,     0.84324,     0.84324,\n",
            "            0.84324,     0.84324,     0.84324,     0.84324,     0.84324,     0.84324,     0.84324,     0.84324,     0.84324,     0.84318,     0.84301,     0.84283,     0.84265,     0.84247,     0.84229,     0.84212,     0.84194,     0.84176,     0.84158,      0.8414,     0.84123,     0.84105,     0.84087,\n",
            "            0.84069,     0.84051,     0.84034,     0.84016,     0.83998,      0.8398,     0.83962,     0.83945,     0.83927,     0.83909,     0.83891,     0.83873,     0.83856,     0.83838,      0.8382,     0.83802,     0.83785,     0.83766,     0.83747,     0.83728,     0.83709,     0.83691,     0.83672,\n",
            "            0.83653,     0.83634,     0.83615,     0.83597,     0.83578,     0.83559,      0.8354,     0.83521,     0.83502,     0.83484,     0.83465,     0.83446,     0.83427,     0.83408,      0.8339,     0.83371,     0.83352,     0.83333,     0.83314,     0.83296,     0.83277,     0.83258,     0.83235,\n",
            "            0.83194,     0.83154,     0.83114,     0.83073,     0.83033,     0.82993,     0.82952,     0.82912,     0.82872,     0.82832,     0.82791,     0.82751,     0.82711,     0.82673,     0.82636,     0.82599,     0.82562,     0.82525,     0.82488,     0.82452,     0.82415,     0.82378,     0.82341,\n",
            "            0.82304,     0.82267,      0.8223,     0.82193,     0.82159,     0.82142,     0.82125,     0.82108,     0.82091,     0.82074,     0.82057,      0.8204,     0.82022,     0.82005,     0.81988,     0.81971,     0.81954,     0.81937,      0.8192,     0.81903,     0.81885,     0.81868,     0.81851,\n",
            "            0.81834,     0.81817,       0.818,     0.81783,     0.81766,     0.81748,     0.81731,     0.81714,     0.81697,      0.8168,     0.81663,     0.81646,     0.81628,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,\n",
            "            0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,\n",
            "            0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,     0.81622,      0.8161,     0.81562,     0.81514,     0.81466,     0.81418,     0.81371,     0.81323,     0.81275,     0.81227,     0.81179,     0.81131,     0.81083,     0.81062,     0.81042,     0.81022,\n",
            "            0.81002,     0.80982,     0.80962,     0.80942,     0.80921,     0.80901,     0.80881,     0.80861,     0.80841,     0.80821,     0.80801,     0.80781,     0.80761,     0.80741,     0.80721,     0.80701,     0.80681,     0.80661,     0.80641,      0.8062,       0.806,      0.8058,      0.8056,\n",
            "             0.8054,     0.80519,     0.80499,     0.80478,     0.80457,     0.80437,     0.80416,     0.80395,     0.80375,     0.80354,     0.80333,     0.80313,     0.80292,     0.80271,      0.8025,      0.8023,     0.80209,     0.80188,     0.80168,     0.80147,     0.80126,     0.80106,     0.80085,\n",
            "            0.80064,     0.80044,     0.80023,     0.80002,         0.8,         0.8,         0.8,         0.8,         0.8,         0.8,         0.8,         0.8,         0.8,         0.8,         0.8,         0.8,         0.8,         0.8,         0.8,         0.8,         0.8,         0.8,         0.8,\n",
            "                0.8,         0.8,         0.8,         0.8,         0.8,         0.8,         0.8,         0.8,         0.8,         0.8,         0.8,         0.8,         0.8,         0.8,     0.79988,     0.79439,     0.79068,     0.78836,     0.78696,     0.78557,     0.78417,     0.78355,     0.78323,\n",
            "             0.7829,     0.78258,     0.78225,     0.78193,     0.78161,     0.78128,     0.78096,     0.78064,     0.78031,     0.77999,     0.77967,     0.77934,     0.77902,     0.77869,     0.77828,     0.77416,     0.76957,     0.76556,     0.76216,     0.76216,     0.75896,     0.75459,     0.75096,\n",
            "            0.74239,     0.73686,      0.7331,     0.73032,     0.72508,     0.72331,     0.72214,     0.72097,      0.7198,     0.71822,     0.71532,      0.7104,     0.69572,     0.68991,     0.68583,     0.67388,     0.66783,     0.66439,     0.66148,     0.65813,     0.65384,     0.65095,     0.64562,\n",
            "            0.63671,     0.61226,      0.6013,     0.59621,     0.58748,     0.58378,     0.57781,     0.57329,     0.57066,     0.56816,     0.54899,     0.54287,     0.52889,       0.525,     0.51097,     0.49861,     0.48987,     0.48322,     0.46489,     0.45405,     0.45405,     0.43268,     0.39681,\n",
            "            0.36644,     0.34421,     0.33511,     0.33085,     0.32134,     0.31556,     0.30343,     0.27553,     0.26486,     0.23511,     0.22744,     0.21161,     0.20142,     0.17319,     0.15702,     0.13388,     0.13052,     0.12344,      0.1206,     0.11719,     0.11167,     0.10488,    0.095699,\n",
            "           0.090133,    0.075092,    0.070662,    0.069023,    0.067655,    0.066286,    0.064918,    0.056665,    0.053279,     0.04822,    0.047127,    0.046034,    0.044942,    0.043849,    0.042227,    0.039945,    0.036585,     0.01598,    0.015091,    0.014202,    0.013312,    0.012423,    0.011534,\n",
            "           0.010449,   0.0085138,   0.0065782,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
            "fitness: np.float64(0.540694010098636)\n",
            "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
            "maps: array([    0.50017])\n",
            "names: {0: 'seal'}\n",
            "nt_per_class: array([185])\n",
            "nt_per_image: array([170])\n",
            "results_dict: {'metrics/precision(B)': np.float64(0.9342962752287708), 'metrics/recall(B)': np.float64(0.8455116942596518), 'metrics/mAP50(B)': np.float64(0.9054142506351766), 'metrics/mAP50-95(B)': np.float64(0.5001695389279093), 'fitness': np.float64(0.540694010098636)}\n",
            "save_dir: PosixPath('runs/detect/val')\n",
            "speed: {'preprocess': 0.15902948271075754, 'inference': 1.2028455749411904, 'loss': 0.0007069575363627702, 'postprocess': 0.2468937549966038}\n",
            "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
            "task: 'detect'\n",
            "\n",
            "=== VALIDACI√ìN POR CLASE ===\n",
            "seal: mAP50-95 = 0.5002\n"
          ]
        }
      ],
      "source": [
        "# Cargar el modelo entrenado (ajusta la ruta seg√∫n corresponda)\n",
        "model = YOLO(\"/content/ProSeal/seals2/weights/best.pt\")\n",
        "\n",
        "# Ejecutar validaci√≥n especificando el archivo de datos y los umbrales deseados\n",
        "metrics = model.val(data=\"/content/export_yolov8/data.yaml\", save_txt=True,)\n",
        "\n",
        "# Mostrar las m√©tricas obtenidas en la validaci√≥n\n",
        "print(\"M√©tricas de validaci√≥n:\", metrics)\n",
        "\n",
        "\n",
        "names = {0: 'seal'}  # Define tus clases aqu√≠\n",
        "class_maps = metrics.maps  # metrics.maps es un array, no se llama como funci√≥n\n",
        "\n",
        "print(\"\\n=== VALIDACI√ìN POR CLASE ===\")\n",
        "for i, (cls_map, name) in enumerate(zip(class_maps, names.values())):\n",
        "    print(f\"{name}: mAP50-95 = {cls_map:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEjVzGnHccPI"
      },
      "source": [
        "# 6.2 Validation in Ultralytics with graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "id": "G1avrWu4ZLif",
        "outputId": "9f52e267-82d3-4b81-f554-66680057cdd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "Model summary (fused): 72 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 822.2¬±129.2 MB/s, size: 53.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/export_yolov8/valid/labels.cache... 10008 images, 9838 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10008/10008 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 626/626 [00:19<00:00, 32.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.934      0.846      0.905        0.5\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val96\u001b[0m\n",
            "\n",
            "üìä M√©tricas de validaci√≥n:\n",
            "‚úîÔ∏è Precision:     0.9343\n",
            "‚úîÔ∏è Recall:        0.8455\n",
            "‚úîÔ∏è F1-score:      0.8877\n",
            "‚úîÔ∏è mAP@0.5:       0.9054\n",
            "‚úîÔ∏è mAP@0.5:0.95:  0.5002\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìÑ CSV guardado en: /content/metricas_val/metricas_validacion_conf__iou_.csv\n",
            "üñºÔ∏è Gr√°fico guardado en: /content/metricas_val/metricas_conf__iou_.png\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# === CONFIGURACI√ìN ===\n",
        "model_path = \"/content/best_coseno_z_25.pt\"\n",
        "data_yaml = \"/content/export_yolov8/data.yaml\"\n",
        "OUTPUT_DIR = \"/content/metricas_val\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# === Cargar modelo ===\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# === Ejecutar validaci√≥n ===\n",
        "metrics = model.val(data=data_yaml, save_txt=True)\n",
        "\n",
        "# === Extraer m√©tricas ===\n",
        "precision = metrics.box.mp\n",
        "recall = metrics.box.mr\n",
        "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "map50 = metrics.box.map50\n",
        "map5095 = metrics.box.map\n",
        "\n",
        "# === Mostrar m√©tricas por consola ===\n",
        "print(\"\\nüìä M√©tricas de validaci√≥n:\")\n",
        "print(f\"‚úîÔ∏è Precision:     {precision:.4f}\")\n",
        "print(f\"‚úîÔ∏è Recall:        {recall:.4f}\")\n",
        "print(f\"‚úîÔ∏è F1-score:      {f1:.4f}\")\n",
        "print(f\"‚úîÔ∏è mAP@0.5:       {map50:.4f}\")\n",
        "print(f\"‚úîÔ∏è mAP@0.5:0.95:  {map5095:.4f}\")\n",
        "\n",
        "# === Graficar ===\n",
        "metric_names = [\"Precision\", \"Recall\", \"F1-score\", \"mAP@0.5\", \"mAP@0.5:0.95\"]\n",
        "metric_values = [precision, recall, f1, map50, map5095]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(metric_names, metric_values, color='skyblue')\n",
        "plt.ylim(0, 1.05)\n",
        "plt.title(f\"YOLOv8 validation metrics\")\n",
        "plt.ylabel(\"Valor\")\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plot_path = os.path.join(OUTPUT_DIR, f\"metricas_conf__iou_.png\")\n",
        "plt.savefig(plot_path)\n",
        "plt.show()\n",
        "\n",
        "# === Exportar CSV ===\n",
        "csv_path = os.path.join(OUTPUT_DIR, f\"metricas_validacion_conf__iou_.csv\")\n",
        "df_metrics = pd.DataFrame({\n",
        "    \"M√©trica\": metric_names,\n",
        "    \"Valor\": metric_values\n",
        "})\n",
        "df_metrics.to_csv(csv_path, index=False)\n",
        "print(f\"\\nüìÑ CSV guardado en: {csv_path}\")\n",
        "print(f\"üñºÔ∏è Gr√°fico guardado en: {plot_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vQP5PQKZPRA"
      },
      "source": [
        "# 6.3 Best confidence for inference based on F1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Hpn1JSVh10J-",
        "outputId": "585a4a31-2f2d-437b-f0ca-cd361564aa76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "Model summary (fused): 72 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 790.8¬±376.4 MB/s, size: 65.5 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/export_yolov8/valid/labels.cache... 10008 images, 9838 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10008/10008 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 626/626 [00:19<00:00, 32.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.934      0.843      0.897      0.542\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val6\u001b[0m\n",
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 776.2¬±413.2 MB/s, size: 39.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/export_yolov8/valid/labels.cache... 10008 images, 9838 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10008/10008 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 626/626 [00:19<00:00, 32.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.926      0.873      0.919      0.539\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val7\u001b[0m\n",
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 675.1¬±175.5 MB/s, size: 42.1 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/export_yolov8/valid/labels.cache... 10008 images, 9838 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10008/10008 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 626/626 [00:19<00:00, 32.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.926      0.873      0.918       0.54\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val8\u001b[0m\n",
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 513.1¬±218.7 MB/s, size: 39.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/export_yolov8/valid/labels.cache... 10008 images, 9838 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10008/10008 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 626/626 [00:19<00:00, 32.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.926      0.873      0.911      0.541\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val9\u001b[0m\n",
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 995.7¬±242.8 MB/s, size: 71.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/export_yolov8/valid/labels.cache... 10008 images, 9838 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10008/10008 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 626/626 [00:18<00:00, 33.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.926      0.873      0.912      0.542\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val10\u001b[0m\n",
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 786.1¬±522.3 MB/s, size: 39.7 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/export_yolov8/valid/labels.cache... 10008 images, 9838 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10008/10008 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 626/626 [00:19<00:00, 32.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.926      0.874      0.911      0.544\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val11\u001b[0m\n",
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 896.6¬±302.9 MB/s, size: 53.7 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/export_yolov8/valid/labels.cache... 10008 images, 9838 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10008/10008 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 626/626 [00:18<00:00, 33.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.925       0.87      0.909      0.544\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val12\u001b[0m\n",
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 937.0¬±564.8 MB/s, size: 49.9 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/export_yolov8/valid/labels.cache... 10008 images, 9838 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10008/10008 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 626/626 [00:19<00:00, 32.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.925       0.87      0.909      0.544\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val13\u001b[0m\n",
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 771.4¬±349.8 MB/s, size: 51.6 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/export_yolov8/valid/labels.cache... 10008 images, 9838 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10008/10008 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 626/626 [00:19<00:00, 32.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185       0.93      0.859      0.904      0.543\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val14\u001b[0m\n",
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 966.5¬±526.8 MB/s, size: 55.6 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/export_yolov8/valid/labels.cache... 10008 images, 9838 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10008/10008 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 626/626 [00:19<00:00, 32.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.935      0.854      0.902      0.541\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val15\u001b[0m\n",
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 829.4¬±266.1 MB/s, size: 55.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/export_yolov8/valid/labels.cache... 10008 images, 9838 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10008/10008 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 626/626 [00:19<00:00, 32.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.934      0.843      0.897      0.542\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val16\u001b[0m\n",
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 806.4¬±213.8 MB/s, size: 42.0 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/export_yolov8/valid/labels.cache... 10008 images, 9838 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10008/10008 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 626/626 [00:19<00:00, 32.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.951      0.827      0.894       0.54\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val17\u001b[0m\n",
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 349.0¬±197.1 MB/s, size: 27.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/export_yolov8/valid/labels.cache... 10008 images, 9838 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10008/10008 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 626/626 [00:19<00:00, 32.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.952      0.827       0.89      0.537\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val18\u001b[0m\n",
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 507.6¬±71.4 MB/s, size: 29.3 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/export_yolov8/valid/labels.cache... 10008 images, 9838 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10008/10008 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 626/626 [00:18<00:00, 33.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.956      0.827      0.891      0.539\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val19\u001b[0m\n",
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 815.5¬±393.0 MB/s, size: 37.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/export_yolov8/valid/labels.cache... 10008 images, 9838 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10008/10008 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 626/626 [00:18<00:00, 33.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185       0.96      0.784      0.871      0.532\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val20\u001b[0m\n",
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1086.9¬±510.6 MB/s, size: 62.7 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/export_yolov8/valid/labels.cache... 10008 images, 9838 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10008/10008 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 626/626 [00:18<00:00, 33.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185      0.959      0.632      0.797      0.503\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val21\u001b[0m\n",
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 680.4¬±308.7 MB/s, size: 37.0 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/export_yolov8/valid/labels.cache... 10008 images, 9838 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10008/10008 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 626/626 [00:18<00:00, 33.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185          1     0.0865      0.543      0.397\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val22\u001b[0m\n",
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 727.0¬±264.7 MB/s, size: 60.9 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/export_yolov8/valid/labels.cache... 10008 images, 9838 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10008/10008 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 626/626 [00:18<00:00, 33.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185          0          0          0          0\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val23\u001b[0m\n",
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 955.5¬±333.4 MB/s, size: 70.7 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/export_yolov8/valid/labels.cache... 10008 images, 9838 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10008/10008 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 626/626 [00:18<00:00, 33.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185          0          0          0          0\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val24\u001b[0m\n",
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 664.5¬±376.0 MB/s, size: 39.3 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/export_yolov8/valid/labels.cache... 10008 images, 9838 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10008/10008 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 626/626 [00:18<00:00, 33.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10008        185          0          0          0          0\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val25\u001b[0m\n",
            "üìÑ Comparaci√≥n guardada en: /content/threshold_analysis_val/val_threshold_comparison.txt\n",
            "üìù Markdown guardado en: /content/threshold_analysis_val/val_threshold_comparison.md\n",
            "üìà Gr√°fico guardado en: /content/threshold_analysis_val/val_threshold_comparison.png\n",
            "üìä Curva guardada en: /content/threshold_analysis_val/f1_precision_recall_vs_conf.png\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === 1. Cargar modelo y dataset ===\n",
        "model = YOLO(\"/content/ProSeal/seals2/weights/best.pt\")\n",
        "dataset_yaml = \"/content/export_yolov8/data.yaml\"\n",
        "\n",
        "# === 2. Configurar rutas de guardado ===\n",
        "val_results_dir = \"/content/threshold_analysis_val\"\n",
        "os.makedirs(val_results_dir, exist_ok=True)\n",
        "\n",
        "# === 3. Evaluar baseline (conf=0.50) ===\n",
        "res_05 = model.val(data=dataset_yaml, split=\"val\", conf=0.5, iou=0.5, verbose=False)\n",
        "p_05, r_05, map50_05, map95_05 = res_05.box.mean_results()\n",
        "f1_05 = 2 * p_05 * r_05 / (p_05 + r_05) if (p_05 + r_05) > 0 else 0\n",
        "\n",
        "# === 4. Buscar best_conf_global (0.05 a 0.95) ===\n",
        "conf_values = [round(i * 0.05, 2) for i in range(1, 20)]\n",
        "f1s_all, p_all, r_all, m50_all, m95_all = [], [], [], [], []\n",
        "\n",
        "for conf in conf_values:\n",
        "    res = model.val(data=dataset_yaml, split=\"val\", conf=conf, iou=0.5, verbose=False)\n",
        "    p, r, m50, m95 = res.box.mean_results()\n",
        "    f1 = 2 * p * r / (p + r) if (p + r) > 0 else 0\n",
        "    f1s_all.append(f1)\n",
        "    p_all.append(p)\n",
        "    r_all.append(r)\n",
        "    m50_all.append(m50)\n",
        "    m95_all.append(m95)\n",
        "\n",
        "best_idx       = int(np.argmax(f1s_all))\n",
        "best_conf_global = conf_values[best_idx]\n",
        "p_best, r_best, map50_best, map95_best, f1_best = (\n",
        "    p_all[best_idx],\n",
        "    r_all[best_idx],\n",
        "    m50_all[best_idx],\n",
        "    m95_all[best_idx],\n",
        "    f1s_all[best_idx]\n",
        ")\n",
        "\n",
        "# === 5. Buscar best_conf_high (solo conf > 0.5) ===\n",
        "high_start       = conf_values.index(0.55)\n",
        "conf_values_high = conf_values[high_start:]\n",
        "f1s_high         = f1s_all[high_start:]\n",
        "p_high           = p_all[high_start:]\n",
        "r_high           = r_all[high_start:]\n",
        "m50_high         = m50_all[high_start:]\n",
        "m95_high         = m95_all[high_start:]\n",
        "\n",
        "best_high_idx      = int(np.argmax(f1s_high))\n",
        "best_conf_high     = conf_values_high[best_high_idx]\n",
        "p_high_best        = p_high[best_high_idx]\n",
        "r_high_best        = r_high[best_high_idx]\n",
        "map50_high_best    = m50_high[best_high_idx]\n",
        "map95_high_best    = m95_high[best_high_idx]\n",
        "f1_high_best       = f1s_high[best_high_idx]\n",
        "\n",
        "# === 6. Crear tabla comparativa ===\n",
        "comp_data = {\n",
        "    \"M√©trica\": [\"Precision\", \"Recall\", \"F1-score\", \"mAP@0.5\", \"mAP@0.5:0.95\"],\n",
        "    \"conf=0.50\": [p_05, r_05, f1_05, map50_05, map95_05],\n",
        "    f\"conf={best_conf_global:.2f}\": [p_best, r_best, f1_best, map50_best, map95_best],\n",
        "    f\"conf>{0.50} (mejor={best_conf_high:.2f})\": [p_high_best, r_high_best, f1_high_best, map50_high_best, map95_high_best]\n",
        "}\n",
        "df_val_comp = pd.DataFrame(comp_data)\n",
        "\n",
        "# === 7. Guardar .txt ===\n",
        "txt_path = os.path.join(val_results_dir, \"val_threshold_comparison.txt\")\n",
        "with open(txt_path, \"w\") as f:\n",
        "    f.write(\"=== COMPARACI√ìN DE 3 THRESHOLDS EN VALIDACI√ìN ===\\n\")\n",
        "    f.write(f\"{'M√©trica':<15} | {'conf=0.50':^12} | {'√ìptimo global':^16} | {'√ìptimo > 0.5':^18}\\n\")\n",
        "    f.write(\"-\" * 65 + \"\\n\")\n",
        "    for i in range(len(df_val_comp)):\n",
        "        m = df_val_comp.loc[i, \"M√©trica\"]\n",
        "        v1 = df_val_comp.loc[i, \"conf=0.50\"]\n",
        "        v2 = df_val_comp.loc[i, f\"conf={best_conf_global:.2f}\"]\n",
        "        v3 = df_val_comp.loc[i, f\"conf>{0.50} (mejor={best_conf_high:.2f})\"]\n",
        "        f.write(f\"{m:<15} | {v1:.4f}      | {v2:.4f}           | {v3:.4f}\\n\")\n",
        "print(f\"üìÑ Comparaci√≥n guardada en: {txt_path}\")\n",
        "\n",
        "# === 8. Guardar .csv ===\n",
        "csv_path = os.path.join(val_results_dir, \"val_threshold_comparison.csv\")\n",
        "df_val_comp.to_csv(csv_path, index=False)\n",
        "\n",
        "# === 9. Guardar .md (Markdown) ===\n",
        "md_path = os.path.join(val_results_dir, \"val_threshold_comparison.md\")\n",
        "with open(md_path, \"w\") as f:\n",
        "    f.write(f\"| M√©trica       | conf=0.50 | √ìptimo global ({best_conf_global:.2f}) | √ìptimo>0.5 ({best_conf_high:.2f}) |\\n\")\n",
        "    f.write(f\"|---------------|-----------|----------------------|-------------------------|\\n\")\n",
        "    for i in range(len(df_val_comp)):\n",
        "        m  = df_val_comp.loc[i, \"M√©trica\"]\n",
        "        v1 = df_val_comp.loc[i, \"conf=0.50\"]\n",
        "        v2 = df_val_comp.loc[i, f\"conf={best_conf_global:.2f}\"]\n",
        "        v3 = df_val_comp.loc[i, f\"conf>{0.50} (mejor={best_conf_high:.2f})\"]\n",
        "        f.write(f\"| {m:<13} | {v1:.4f}     | {v2:.4f}               | {v3:.4f}                  |\\n\")\n",
        "print(f\"üìù Markdown guardado en: {md_path}\")\n",
        "\n",
        "# === 10. Gr√°fico de barras ===\n",
        "labels = df_val_comp[\"M√©trica\"]\n",
        "x = np.arange(len(labels))\n",
        "width = 0.25\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.bar(x - width, df_val_comp[\"conf=0.50\"], width, label=\"conf=0.50\")\n",
        "ax.bar(x, df_val_comp[f\"conf={best_conf_global:.2f}\"], width, label=f\"√ìptimo ({best_conf_global:.2f})\")\n",
        "ax.bar(x + width, df_val_comp[f\"conf>{0.50} (mejor={best_conf_high:.2f})\"], width,\n",
        "       label=f\"√ìptimo>0.5 ({best_conf_high:.2f})\")\n",
        "ax.set_ylabel(\"Valor M√©trico\")\n",
        "ax.set_title(\"Comparaci√≥n de Thresholds en Validaci√≥n\")\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "ax.grid(axis=\"y\")\n",
        "fig.tight_layout()\n",
        "plot_path = os.path.join(val_results_dir, \"val_threshold_comparison.png\")\n",
        "plt.savefig(plot_path)\n",
        "# plt.show()  # opcional\n",
        "print(f\"üìà Gr√°fico guardado en: {plot_path}\")\n",
        "\n",
        "# === 11. Curva F1 vs Confidence ===\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(conf_values, f1s_all, marker='o', label='F1 score')\n",
        "plt.plot(conf_values, p_all,    marker='x', linestyle='--', label='Precision')\n",
        "plt.plot(conf_values, r_all,    marker='s', linestyle='-.', label='Recall')\n",
        "plt.axvline(best_conf_global, linestyle='--', color='red',\n",
        "            label=f'Mejor F1 = {best_conf_global:.2f}')\n",
        "plt.xlabel('Confidence Threshold')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Precision, Recall y F1 vs Confidence Threshold')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "curve_path = os.path.join(val_results_dir, \"f1_precision_recall_vs_conf.png\")\n",
        "plt.savefig(curve_path)\n",
        "# plt.show()  # opcional\n",
        "print(f\"üìä Curva guardada en: {curve_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWT3WkO3caz3"
      },
      "source": [
        "# 6.4 Save the validation results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eP30tHWQ4QDB",
        "outputId": "3934abff-d1e1-4df1-9b39-eee722ad71c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define la carpeta de destino en Google Drive\n",
        "dest_folder = \"/content/drive/MyDrive/ProSeal/val/general\"\n",
        "!mkdir -p \"{dest_folder}\"                                                           #El comando mkdir -p crea esa carpeta (y cualquier subcarpeta necesaria) si no existe.\n",
        "\n",
        "# Copia la carpeta de resultados (ajusta el nombre seg√∫n el que se haya generado)\n",
        "!cp -r /content/runs/detect/val \"{dest_folder}/\"   #copiar los reultados del modelo en drive\n",
        "\n",
        "\n",
        "# Comprueba que se copiaron los archivos (opcional)\n",
        "!ls \"{dest_folder}\"                                                                 #verifica que los archivos se han copiado correctamente\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zev1Iya2cYot"
      },
      "source": [
        "# **7. Evaluation test in Ultralytics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9QBBNLn-SCY"
      },
      "source": [
        "# 7.1 Evaluate using the ultralytics function in your test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuDPannc5HnY",
        "outputId": "a56d1ba1-899e-41fa-9743-18ceaecb1700"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.174 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "Model summary (fused): 72 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 797.0¬±237.0 MB/s, size: 75.6 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/export_yolov8/test/labels.cache... 10007 images, 9837 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10007/10007 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 626/626 [00:19<00:00, 31.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      10007        192      0.944      0.839      0.906      0.542\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val30\u001b[0m\n",
            "mAP50:      0.9059\n",
            "mAP50-95:   0.5415\n",
            "Precisi√≥n:  0.9440\n",
            "Recall:     0.8385\n",
            "\n",
            "=== TEST POR CLASE ===\n",
            "seal: mAP50-95 = 0.5415\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# 1. Cargar el modelo entrenado\n",
        "model = YOLO(\"/content/ProSeal/seals2/weights/best.pt\")\n",
        "\n",
        "# 2. Ejecutar la evaluaci√≥n sobre el conjunto de test\n",
        "dataset_yaml = \"/content/export_yolov8/data.yaml\"\n",
        "\n",
        "results = model.val(data=dataset_yaml, split=\"test\", save_txt=True, )\n",
        "\n",
        "# 3. Mostrar las m√©tricas principales\n",
        "metrics = results.box  # M√©tricas de bounding boxes\n",
        "\n",
        "print(f\"mAP50:      {metrics.map50:.4f}\")\n",
        "print(f\"mAP50-95:   {metrics.map:.4f}\")\n",
        "print(f\"Precisi√≥n:  {metrics.mp:.4f}\")\n",
        "print(f\"Recall:     {metrics.mr:.4f}\")\n",
        "\n",
        "# === TEST POR CLASE ===\n",
        "# Definir el diccionario de nombres de clase (ajusta seg√∫n corresponda)\n",
        "names = {0:  'seal'}\n",
        "# results.box.maps es un array con el mAP (mAP@0.5:0.95) por cada clase\n",
        "class_maps = metrics.maps\n",
        "\n",
        "print(\"\\n=== TEST POR CLASE ===\")\n",
        "for cls_map, name in zip(class_maps, names.values()):\n",
        "    print(f\"{name}: mAP50-95 = {cls_map:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8Zj0eOa-GlE"
      },
      "source": [
        "# 7.2 Save test results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTP8yzIo-GNd"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define la carpeta de destino en Google Drive\n",
        "dest_folder = \"/content/drive/MyDrive/ProSeal/test\"\n",
        "!mkdir -p \"{dest_folder}\"                                                           #El comando mkdir -p crea esa carpeta (y cualquier subcarpeta necesaria) si no existe.\n",
        "\n",
        "# Copia la carpeta de resultados (ajusta el nombre seg√∫n el que se haya generado)\n",
        "!cp -r /content/runs/detect/val22 \"{dest_folder}/\"   #copiar los reultados del modelo en drive\n",
        "\n",
        "\n",
        "# Comprueba que se copiaron los archivos (opcional)\n",
        "!ls \"{dest_folder}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
