{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzgkaC8xMFyH"
      },
      "source": [
        "# **INFERENCE PROCESS FOR NEW IMAGES**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nKoOOIgVQ0x"
      },
      "source": [
        "# **1. Connect to Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAKq52lJVeIx",
        "outputId": "057e1b62-984a-4c94-fef1-746576c31869"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Import folder with images in order to run inference over them**\n",
        "\n",
        "Import the model file"
      ],
      "metadata": {
        "id": "sHmzHRON1bJN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrgkDcNKWUvH"
      },
      "outputs": [],
      "source": [
        "################################IMPORTAR EL dataset entero a colab UNA VEZ TIENES LA ESTRUCTURA  ####################################################\n",
        "####################################################################################\n",
        "\n",
        "\n",
        "# Copiar el archivo data.yaml desde Drive a la ruta deseada en Colab\n",
        "!cp -r \"/content/drive/MyDrive/images\" \"/content/dickson_23\"\n",
        "#\"/content/dataset/lote_4\"\n",
        "\n",
        "# Verificar que se copi√≥ correctamente\n",
        "!ls -l \"/content/dickson_23\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Install Ultralytics**"
      ],
      "metadata": {
        "id": "vEkU0DLw1rMv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQhdlblSbskC",
        "outputId": "881c4bc5-8d03-410e-bfee-a77e15fb51bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.160 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete ‚úÖ (8 CPUs, 51.0 GB RAM, 51.3/235.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "#0. En Colab, primero instala los paquetes y monta tu Drive:  Instalar las librer√≠as necesarias\n",
        "!pip install ultralytics wandb  # Esto instalar√° ultralytics y wandb (torch y torchvision generalmente ya vienen instalados en Colab)\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5r0lYbXx0IX"
      },
      "source": [
        "# **4. Inference process over the imported folder**\n",
        "\n",
        "This code divides images in tiles, run the inference, merged the images back and divides them based on confidence prediction\n",
        "\n",
        "Tiles size and overlap is customizable.\n",
        "\n",
        "The input directory (folder with images) has to be indicated.\n",
        "\n",
        "The model directory file has to be imported and indicated.\n",
        "\n",
        "Class number and names are customizable\n",
        "\n",
        "IoU and confidence values are customizables.\n",
        "\n",
        "\n",
        "\n",
        "- The output gives:\n",
        "1. Folder with all images with annotations\n",
        "2. Folder with negative images\n",
        "3. Folder with positive images\n",
        "\n",
        "  3.1 Subfolder with images positives (confidence > 0.8)\n",
        "\n",
        "  3.2 Subfolder with images positives (confidence < 0.8 and > 0.5)\n",
        "\n",
        "  3.3 Subfolder with images positives (confidence < 0.5 )\n",
        "\n",
        "  \n",
        "  The presence of one single prrediction > the confidence indicated includes all images inside that subfolder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DD6druvmpv5H",
        "outputId": "f8a352f2-4969-43da-9993-a671d4a4490d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resumen y estad√≠sticas guardadas en: /content/dickson_23/resultados/detections_summary.xlsx\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "\n",
        "# ====================\n",
        "# Par√°metros Globales\n",
        "# ====================\n",
        "TILE_SIZE = 640           # Tama√±o de cada tile en p√≠xeles\n",
        "OVERLAP = 128             # Solapamiento entre tiles en p√≠xeles\n",
        "STEP = TILE_SIZE - OVERLAP  # Paso entre tiles\n",
        "\n",
        "# Rutas (modifica estas rutas seg√∫n tu estructura)\n",
        "INPUT_DIR = \"/content/dickson_23\"              # Directorio con im√°genes completas (2025)\n",
        "OUTPUT_DIR = \"/content/dickson_23/resultados\"  # Carpeta principal de resultados\n",
        "# Nota: No se guardar√°n los tiles en disco para ahorrar espacio.\n",
        "ANNOTATED_DIR = os.path.join(OUTPUT_DIR, \"annotated_full\")  # Im√°genes completas anotadas\n",
        "\n",
        "# Carpetas para separar im√°genes positivas y negativas\n",
        "POSITIVAS_SEALS_DIR = os.path.join(OUTPUT_DIR, \"positivas\", \"seals\")\n",
        "NEGATIVAS_DIR = os.path.join(OUTPUT_DIR, \"negativas\")\n",
        "\n",
        "# Subcarpetas en positivos (para seals) seg√∫n el rango de score\n",
        "SEALS_SCORE_SUBFOLDERS = [\"low_score_<0.5\", \"medium_score_0.5-0.8\", \"high_score_>0.8\"]\n",
        "\n",
        "def create_directories():\n",
        "    \"\"\"Crea todas las carpetas necesarias para el pipeline (solo para la clase seal).\"\"\"\n",
        "    folders = [ANNOTATED_DIR, POSITIVAS_SEALS_DIR, NEGATIVAS_DIR]\n",
        "    for folder in folders:\n",
        "        os.makedirs(folder, exist_ok=True)\n",
        "    for sub in SEALS_SCORE_SUBFOLDERS:\n",
        "        os.makedirs(os.path.join(POSITIVAS_SEALS_DIR, sub), exist_ok=True)\n",
        "\n",
        "EXCEL_OUTPUT = os.path.join(OUTPUT_DIR, \"detections_summary.xlsx\")\n",
        "\n",
        "# Diccionario de clases: solo se trabaja con \"seal\"\n",
        "# Se asume que el modelo devuelve detecciones con clase 1 para seal.\n",
        "CLASS_NAMES = {0: 'seal'}\n",
        "\n",
        "# Par√°metros para inferencia\n",
        "INFERENCE_CONF = 0.25\n",
        "INFERENCE_IOU = 0.5\n",
        "\n",
        "# Modelo: Ajusta la ruta a tus pesos entrenados\n",
        "MODEL_PATH = \"/content/bestmaxi_80_20_coseno.pt\"\n",
        "\n",
        "# ====================\n",
        "# Funciones Auxiliares\n",
        "# ====================\n",
        "\n",
        "def compute_iou(box1, box2):\n",
        "    \"\"\"Calcula el IoU entre dos cajas [x1, y1, x2, y2].\"\"\"\n",
        "    x1 = max(box1[0], box2[0])\n",
        "    y1 = max(box1[1], box2[1])\n",
        "    x2 = min(box1[2], box2[2])\n",
        "    y2 = min(box1[3], box2[3])\n",
        "    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
        "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "    union = area1 + area2 - inter_area + 1e-6\n",
        "    return inter_area / union\n",
        "\n",
        "def nms_global(detections, iou_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Aplica Non-Maximum Suppression (NMS) a una lista de detecciones.\n",
        "    Cada detecci√≥n es una tupla (cls, x1, y1, x2, y2, conf).\n",
        "    \"\"\"\n",
        "    if not detections:\n",
        "        return []\n",
        "    detections = np.array(detections)\n",
        "    final_detections = []\n",
        "    for cls in np.unique(detections[:, 0]):\n",
        "        # Solo se trabajar√° la clase \"seal\" (se asume que es 1)\n",
        "        if int(cls) != 0:\n",
        "            continue\n",
        "        mask = detections[:, 0] == cls\n",
        "        d_cls = detections[mask]\n",
        "        order = d_cls[:, 5].argsort()[::-1]\n",
        "        d_cls = d_cls[order]\n",
        "        while len(d_cls) > 0:\n",
        "            best = d_cls[0]\n",
        "            final_detections.append(best)\n",
        "            if len(d_cls) == 1:\n",
        "                break\n",
        "            rest = d_cls[1:]\n",
        "            ious = np.array([compute_iou(best[1:5], box[1:5]) for box in rest])\n",
        "            keep = np.where(ious < iou_threshold)[0]\n",
        "            d_cls = rest[keep]\n",
        "    return final_detections\n",
        "\n",
        "def get_tiles(image):\n",
        "    \"\"\"\n",
        "    Divide la imagen en tiles, devolviendo una lista de tuplas:\n",
        "    (tile, (offset_x, offset_y)).\n",
        "    \"\"\"\n",
        "    tiles = []\n",
        "    h, w = image.shape[:2]\n",
        "    for y in range(0, h, STEP):\n",
        "        for x in range(0, w, STEP):\n",
        "            tile = image[y:min(y + TILE_SIZE, h), x:min(x + TILE_SIZE, w)]\n",
        "            tile_h, tile_w = tile.shape[:2]\n",
        "            if tile_h < TILE_SIZE or tile_w < TILE_SIZE:\n",
        "                padded = np.zeros((TILE_SIZE, TILE_SIZE, 3), dtype=tile.dtype)\n",
        "                padded[:tile_h, :tile_w] = tile\n",
        "                tile = padded\n",
        "            tiles.append((tile, (x, y)))\n",
        "    return tiles\n",
        "\n",
        "def process_tile_inference(tile, offset, model):\n",
        "    \"\"\"\n",
        "    Realiza inferencia en un tile y convierte las coordenadas al sistema de la imagen original.\n",
        "    Devuelve una lista de detecciones en formato (cls, x1, y1, x2, y2, conf).\n",
        "    Solo se conservan las detecciones de \"seal\" (clase 1).\n",
        "    \"\"\"\n",
        "    detections = []\n",
        "    results_tile = model.predict(source=tile, conf=INFERENCE_CONF, iou=INFERENCE_IOU, verbose=False)\n",
        "    if not results_tile:\n",
        "        return detections\n",
        "    pred = results_tile[0]\n",
        "    boxes = pred.boxes\n",
        "    if boxes is None or boxes.shape[0] == 0:\n",
        "        return detections\n",
        "    preds = boxes.data.cpu().numpy()  # Formato: [x1, y1, x2, y2, conf, cls]\n",
        "    for row in preds:\n",
        "        x1_tile, y1_tile, x2_tile, y2_tile, conf, cls = row\n",
        "        # Solo conservar detecciones de \"seal\" (clase 1)\n",
        "        if int(cls) != 0:\n",
        "            continue\n",
        "        x1 = x1_tile + offset[0]\n",
        "        y1 = y1_tile + offset[1]\n",
        "        x2 = x2_tile + offset[0]\n",
        "        y2 = y2_tile + offset[1]\n",
        "        detections.append((int(cls), x1, y1, x2, y2, conf))\n",
        "    return detections\n",
        "\n",
        "def process_image(image_path, model):\n",
        "    \"\"\"\n",
        "    Procesa una imagen completa:\n",
        "      - Divide la imagen en tiles y ejecuta inferencia en cada tile.\n",
        "      - Reconstruye las detecciones en coordenadas originales.\n",
        "      - Aplica NMS global.\n",
        "      - Dibuja las detecciones (bounding boxes y labels) en la imagen anotada.\n",
        "      - Clasifica la imagen como positiva si se detecta al menos una caja (seal).\n",
        "      - Guarda la imagen anotada (con las etiquetas) en la carpeta de positivos de seals,\n",
        "        utilizando subcarpetas de acuerdo a un rango de score.\n",
        "      - Retorna un resumen, la imagen anotada y la lista de detecciones filtradas.\n",
        "    \"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        return None, None, []\n",
        "    orig_h, orig_w = image.shape[:2]\n",
        "    annotated_img = image.copy()\n",
        "    all_detections = []\n",
        "\n",
        "    # Obtener tiles (no se guardan en disco)\n",
        "    tiles = get_tiles(image)\n",
        "    for tile, offset in tiles:\n",
        "        detections = process_tile_inference(tile, offset, model)\n",
        "        all_detections.extend(detections)\n",
        "\n",
        "    # Aplicar NMS global\n",
        "    detections_filtered = nms_global(all_detections, iou_threshold=0.5)\n",
        "\n",
        "    # Dibujar las detecciones en la imagen anotada\n",
        "    for det in detections_filtered:\n",
        "        cls, x1, y1, x2, y2, conf = det\n",
        "        cv2.rectangle(annotated_img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)  # rojo\n",
        "        label = f\"{CLASS_NAMES.get(cls, str(cls))}:{conf:.2f}\"\n",
        "        cv2.putText(annotated_img, label, (int(x1), int(y1)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)  # rojo\n",
        "\n",
        "    # Clasificaci√≥n: se considera la imagen positiva si hay detecciones\n",
        "    if len(detections_filtered) == 0:\n",
        "        pos_flag = 0\n",
        "        neg_flag = 1\n",
        "    else:\n",
        "        pos_flag = 1\n",
        "        neg_flag = 0\n",
        "\n",
        "    # Para im√°genes positivas, calculamos el promedio de score y guardamos la imagen anotada\n",
        "   # Para im√°genes positivas, clasificamos seg√∫n la m√°xima confianza\n",
        "    if pos_flag:\n",
        "        max_score = np.max([d[5] for d in detections_filtered])\n",
        "\n",
        "        if max_score < 0.5:\n",
        "            score_folder = \"low_score_<0.5\"\n",
        "        elif max_score <= 0.8:\n",
        "            score_folder = \"medium_score_0.5-0.8\"\n",
        "        else:\n",
        "            score_folder = \"high_score_>0.8\"\n",
        "\n",
        "        # Ruta de carpeta anotada\n",
        "        annotated_target_dir = os.path.join(POSITIVAS_SEALS_DIR, score_folder)\n",
        "        os.makedirs(annotated_target_dir, exist_ok=True)\n",
        "        cv2.imwrite(os.path.join(annotated_target_dir, os.path.basename(image_path)), annotated_img)\n",
        "\n",
        "        # Ruta de carpeta con originales (sin labels)\n",
        "        originals_target_dir = os.path.join(POSITIVAS_SEALS_DIR, score_folder + \"_originales\")\n",
        "        os.makedirs(originals_target_dir, exist_ok=True)\n",
        "        shutil.copy2(image_path, os.path.join(originals_target_dir, os.path.basename(image_path)))\n",
        "\n",
        "        # Tambi√©n guardamos en annotated_full (como antes)\n",
        "        cv2.imwrite(os.path.join(ANNOTATED_DIR, os.path.basename(image_path)), annotated_img)\n",
        "\n",
        "    else:\n",
        "        shutil.copy2(image_path, os.path.join(NEGATIVAS_DIR, os.path.basename(image_path)))\n",
        "\n",
        "    # Resumen: s√≥lo se cuenta la detecci√≥n de \"seal\"\n",
        "    rec = {\"imagen\": os.path.basename(image_path), \"positive\": pos_flag, \"negative\": neg_flag, \"seal\": len(detections_filtered)}\n",
        "    rec[\"total_detecciones\"] = len(detections_filtered)\n",
        "\n",
        "    return rec, annotated_img, detections_filtered\n",
        "\n",
        "def process_all_images(model):\n",
        "    \"\"\"Procesa todas las im√°genes en INPUT_DIR y acumula res√∫menes y detecciones.\"\"\"\n",
        "    all_summary = []\n",
        "    global_detections = []\n",
        "    num_images = 0\n",
        "    for img_file in os.listdir(INPUT_DIR):\n",
        "        if not img_file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "            continue\n",
        "        num_images += 1\n",
        "        img_path = os.path.join(INPUT_DIR, img_file)\n",
        "        rec, annotated_img, detections_filtered = process_image(img_path, model)\n",
        "        if rec is not None:\n",
        "            all_summary.append(rec)\n",
        "            global_detections.extend(detections_filtered)\n",
        "            cv2.imwrite(os.path.join(ANNOTATED_DIR, img_file), annotated_img)\n",
        "    return all_summary, global_detections, num_images\n",
        "\n",
        "def compute_global_statistics(global_detections, num_images):\n",
        "    \"\"\"Calcula estad√≠sticas globales a partir de las detecciones acumuladas.\"\"\"\n",
        "    stats = {}\n",
        "    total_det = len(global_detections)\n",
        "    stats[\"total_detecciones\"] = total_det\n",
        "    stats[\"promedio_detecciones_por_imagen\"] = total_det / num_images if num_images > 0 else 0\n",
        "    if total_det > 0:\n",
        "        confs = [d[5] for d in global_detections]\n",
        "        stats[\"conf_mean\"] = np.mean(confs)\n",
        "        stats[\"conf_median\"] = np.median(confs)\n",
        "        stats[\"conf_std\"] = np.std(confs)\n",
        "    else:\n",
        "        stats[\"conf_mean\"] = stats[\"conf_median\"] = stats[\"conf_std\"] = 0\n",
        "    return stats\n",
        "\n",
        "def compute_class_statistics(global_detections):\n",
        "    \"\"\"Calcula estad√≠sticas para la clase 'seal'.\"\"\"\n",
        "    class_stats = {}\n",
        "    dets = [d for d in global_detections if d[0] == 0]\n",
        "    if dets:\n",
        "        confs = [d[5] for d in dets]\n",
        "        areas = [(d[3]-d[1])*(d[4]-d[2]) for d in dets]\n",
        "        class_stats[\"seal\"] = {\n",
        "            \"num_detecciones\": len(dets),\n",
        "            \"conf_mean\": np.mean(confs),\n",
        "            \"conf_median\": np.median(confs),\n",
        "            \"conf_std\": np.std(confs),\n",
        "            \"area_mean\": np.mean(areas),\n",
        "            \"area_median\": np.median(areas),\n",
        "            \"area_std\": np.std(areas)\n",
        "        }\n",
        "    else:\n",
        "        class_stats[\"seal\"] = {\n",
        "            \"num_detecciones\": 0,\n",
        "            \"conf_mean\": 0,\n",
        "            \"conf_median\": 0,\n",
        "            \"conf_std\": 0,\n",
        "            \"area_mean\": 0,\n",
        "            \"area_median\": 0,\n",
        "            \"area_std\": 0\n",
        "        }\n",
        "    return class_stats\n",
        "\n",
        "def save_excel_summary(summary_records, global_stats, class_stats):\n",
        "    \"\"\"\n",
        "    Exporta tres hojas a un √∫nico archivo Excel:\n",
        "      - \"Resumen por Imagen\": una fila por imagen + una fila TOTAL.\n",
        "      - \"Estad√≠sticas Globales\": estad√≠sticas globales.\n",
        "      - \"Estad√≠sticas por Clase\": estad√≠sticas detalladas para la clase 'seal'.\n",
        "    Se utiliza pd.concat para agregar la fila TOTAL.\n",
        "    \"\"\"\n",
        "    df_images = pd.DataFrame(summary_records)\n",
        "    totals = {\"imagen\": \"TOTAL\"}\n",
        "    for col in df_images.columns:\n",
        "        if col != \"imagen\":\n",
        "            if pd.api.types.is_numeric_dtype(df_images[col]):\n",
        "                totals[col] = df_images[col].sum()\n",
        "            else:\n",
        "                totals[col] = \"\"\n",
        "    df_images = pd.concat([df_images, pd.DataFrame([totals])], ignore_index=True)\n",
        "\n",
        "    df_global = pd.DataFrame([global_stats])\n",
        "\n",
        "    rows = []\n",
        "    for cls_name, stats in class_stats.items():\n",
        "        row = {\"clase\": cls_name}\n",
        "        row.update(stats)\n",
        "        rows.append(row)\n",
        "    df_class = pd.DataFrame(rows)\n",
        "\n",
        "    with pd.ExcelWriter(EXCEL_OUTPUT) as writer:\n",
        "        df_images.to_excel(writer, sheet_name=\"Resumen por Imagen\", index=False)\n",
        "        df_global.to_excel(writer, sheet_name=\"Estad√≠sticas Globales\", index=False)\n",
        "        df_class.to_excel(writer, sheet_name=\"Estad√≠sticas por Clase\", index=False)\n",
        "    print(\"Resumen y estad√≠sticas guardadas en:\", EXCEL_OUTPUT)\n",
        "\n",
        "def run_pipeline():\n",
        "    create_directories()\n",
        "    model = YOLO(MODEL_PATH)\n",
        "    summary_records, global_detections, num_images = process_all_images(model)\n",
        "    global_stats = compute_global_statistics(global_detections, num_images)\n",
        "    class_stats = compute_class_statistics(global_detections)\n",
        "    save_excel_summary(summary_records, global_stats, class_stats)\n",
        "\n",
        "# Ejecutar el pipeline completo\n",
        "run_pipeline()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Save the results into a folder in Google Drive**"
      ],
      "metadata": {
        "id": "wKRTknO04eMM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PNj35AChi5p",
        "outputId": "e68d00c7-4504-4e58-8ce6-7a9d05d9c8a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resultados\n"
          ]
        }
      ],
      "source": [
        "# 10. Guardar los resultados del experimento\n",
        "\n",
        "# Define la carpeta de destino en Google Drive\n",
        "dest_folder = \"/content/drive/MyDrive/Dickson_23\"\n",
        "!mkdir -p \"{dest_folder}\"  # El comando mkdir -p crea esa carpeta (y cualquier subcarpeta necesaria) si no existe.\n",
        "\n",
        "# Copia la carpeta de resultados (ajusta el nombre seg√∫n el que se haya generado)\n",
        "!cp -r \"/content/dickson_23/resultados\" \"{dest_folder}/\"  # Copiar los resultados del modelo en drive\n",
        "\n",
        "# Comprueba que se copiaron los archivos (opcional)\n",
        "!ls \"{dest_folder}\"\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}